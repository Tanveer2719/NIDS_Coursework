{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12493033,"sourceType":"datasetVersion","datasetId":7883909}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Tanveer2719/NIDS_Coursework.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:26.526810Z","iopub.execute_input":"2025-07-18T09:29:26.527401Z","iopub.status.idle":"2025-07-18T09:29:27.098284Z","shell.execute_reply.started":"2025-07-18T09:29:26.527377Z","shell.execute_reply":"2025-07-18T09:29:27.097223Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'NIDS_Coursework'...\nremote: Enumerating objects: 115, done.\u001b[K\nremote: Counting objects: 100% (115/115), done.\u001b[K\nremote: Compressing objects: 100% (78/78), done.\u001b[K\nremote: Total 115 (delta 38), reused 111 (delta 34), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (115/115), 139.96 KiB | 2.00 MiB/s, done.\nResolving deltas: 100% (38/38), done.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%cd /kaggle/working/NIDS_Coursework/My_Code\n!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:27.100262Z","iopub.execute_input":"2025-07-18T09:29:27.100567Z","iopub.status.idle":"2025-07-18T09:29:27.273460Z","shell.execute_reply.started":"2025-07-18T09:29:27.100543Z","shell.execute_reply":"2025-07-18T09:29:27.272244Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/NIDS_Coursework/My_Code\nclassification.py    main.ipynb       preprocess.py  record_level_embedding.py\nfeatureSelection.py  NIDS_Coursework  __pycache__    transformer.py\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%rm -r __pycache__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:27.274843Z","iopub.execute_input":"2025-07-18T09:29:27.275184Z","iopub.status.idle":"2025-07-18T09:29:27.457500Z","shell.execute_reply.started":"2025-07-18T09:29:27.275152Z","shell.execute_reply":"2025-07-18T09:29:27.456539Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!git pull origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:27.459890Z","iopub.execute_input":"2025-07-18T09:29:27.460177Z","iopub.status.idle":"2025-07-18T09:29:27.872287Z","shell.execute_reply.started":"2025-07-18T09:29:27.460151Z","shell.execute_reply":"2025-07-18T09:29:27.871368Z"}},"outputs":[{"name":"stdout","text":"From https://github.com/Tanveer2719/NIDS_Coursework\n * branch            main       -> FETCH_HEAD\nAlready up to date.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npath = \"/kaggle/input/unsw-nb-15/UNSW-NB15_combined.csv\"\n\ndf = pd.read_csv(path)\n\nprint(df.shape)\ndf = df.drop(columns=['id', 'label'])\nprint(df.shape)\n\nprint(f\"ğŸ§¾ Unique class labels: {df['attack_cat'].unique()}\")\ndf['label'] = df['attack_cat'].apply(lambda x: 0 if x == 'Normal' else 1)\n\nprint(f'Unique values for label {df[\"label\"].unique()}')\n\ndf = df.drop(columns=[\"attack_cat\"])\nprint(f'new shape{df.shape}')\n\nprint(df.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:27.873697Z","iopub.execute_input":"2025-07-18T09:29:27.874042Z","iopub.status.idle":"2025-07-18T09:29:29.008503Z","shell.execute_reply.started":"2025-07-18T09:29:27.874006Z","shell.execute_reply":"2025-07-18T09:29:29.007633Z"}},"outputs":[{"name":"stdout","text":"(257673, 45)\n(257673, 43)\nğŸ§¾ Unique class labels: ['Normal' 'Backdoor' 'Analysis' 'Fuzzers' 'Shellcode' 'Reconnaissance'\n 'Exploits' 'DoS' 'Worms' 'Generic']\nUnique values for label [0 1]\nnew shape(257673, 43)\ndur                  float64\nproto                 object\nservice               object\nstate                 object\nspkts                  int64\ndpkts                  int64\nsbytes                 int64\ndbytes                 int64\nrate                 float64\nsttl                   int64\ndttl                   int64\nsload                float64\ndload                float64\nsloss                  int64\ndloss                  int64\nsinpkt               float64\ndinpkt               float64\nsjit                 float64\ndjit                 float64\nswin                   int64\nstcpb                  int64\ndtcpb                  int64\ndwin                   int64\ntcprtt               float64\nsynack               float64\nackdat               float64\nsmean                  int64\ndmean                  int64\ntrans_depth            int64\nresponse_body_len      int64\nct_srv_src             int64\nct_state_ttl           int64\nct_dst_ltm             int64\nct_src_dport_ltm       int64\nct_dst_sport_ltm       int64\nct_dst_src_ltm         int64\nis_ftp_login           int64\nct_ftp_cmd             int64\nct_flw_http_mthd       int64\nct_src_ltm             int64\nct_srv_dst             int64\nis_sm_ips_ports        int64\nlabel                  int64\ndtype: object\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# perform preprocessing\n\nfrom preprocess import Preprocess\n\n# separate the features and labels so that the labesl are not encoded\nlabels = df['label']\nfeatures = df.drop(columns=['label'])\n\npp = Preprocess()\nprocessed_features = pp.fit_transform_df_auto(df = features,n_categorical_levels=32, expected_categorical_format='onehot')\n\nprint(processed_features.shape)\nprocessed_features.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:29.009460Z","iopub.execute_input":"2025-07-18T09:29:29.009760Z","iopub.status.idle":"2025-07-18T09:29:30.350651Z","shell.execute_reply.started":"2025-07-18T09:29:29.009741Z","shell.execute_reply":"2025-07-18T09:29:30.349972Z"}},"outputs":[{"name":"stdout","text":"Encoding the 32 levels for proto\nEncoding the 13 levels for service\nEncoding the 11 levels for state\n(257673, 95)\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n0  0.027889  0.193225  0.172921  0.331292  0.312312  0.312595  0.997874   \n1  0.121803  0.284598  0.393619  0.398471  0.645181  0.316704  0.747160   \n2  0.234590  0.224248  0.304405  0.353884  0.574953  0.196832  0.747160   \n3  0.239956  0.267974  0.275582  0.388675  0.402879  0.194440  0.747160   \n4  0.090294  0.248312  0.209072  0.378428  0.339064  0.256038  0.999294   \n\n       dttl     sload     dload  ...  state_2  state_3  state_4  state_5  \\\n0  1.000000  0.424562  0.534539  ...    False    False    False    False   \n1  0.998579  0.401347  0.775718  ...    False    False    False    False   \n2  0.998579  0.326962  0.650937  ...    False    False    False    False   \n3  0.998579  0.351625  0.479722  ...    False    False    False    False   \n4  0.998579  0.402218  0.489854  ...    False    False    False    False   \n\n   state_6  state_7  state_8  state_9  state_10  state_11  \n0    False    False    False    False     False     False  \n1    False    False    False    False     False     False  \n2    False    False    False    False     False     False  \n3    False    False    False    False     False     False  \n4    False    False    False    False     False     False  \n\n[5 rows x 95 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dur</th>\n      <th>spkts</th>\n      <th>dpkts</th>\n      <th>sbytes</th>\n      <th>dbytes</th>\n      <th>rate</th>\n      <th>sttl</th>\n      <th>dttl</th>\n      <th>sload</th>\n      <th>dload</th>\n      <th>...</th>\n      <th>state_2</th>\n      <th>state_3</th>\n      <th>state_4</th>\n      <th>state_5</th>\n      <th>state_6</th>\n      <th>state_7</th>\n      <th>state_8</th>\n      <th>state_9</th>\n      <th>state_10</th>\n      <th>state_11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.027889</td>\n      <td>0.193225</td>\n      <td>0.172921</td>\n      <td>0.331292</td>\n      <td>0.312312</td>\n      <td>0.312595</td>\n      <td>0.997874</td>\n      <td>1.000000</td>\n      <td>0.424562</td>\n      <td>0.534539</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.121803</td>\n      <td>0.284598</td>\n      <td>0.393619</td>\n      <td>0.398471</td>\n      <td>0.645181</td>\n      <td>0.316704</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.401347</td>\n      <td>0.775718</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.234590</td>\n      <td>0.224248</td>\n      <td>0.304405</td>\n      <td>0.353884</td>\n      <td>0.574953</td>\n      <td>0.196832</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.326962</td>\n      <td>0.650937</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.239956</td>\n      <td>0.267974</td>\n      <td>0.275582</td>\n      <td>0.388675</td>\n      <td>0.402879</td>\n      <td>0.194440</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.351625</td>\n      <td>0.479722</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.090294</td>\n      <td>0.248312</td>\n      <td>0.209072</td>\n      <td>0.378428</td>\n      <td>0.339064</td>\n      <td>0.256038</td>\n      <td>0.999294</td>\n      <td>0.998579</td>\n      <td>0.402218</td>\n      <td>0.489854</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 95 columns</p>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# concat the features and the labels\nprocessed_full_df = pd.concat([processed_features, labels], axis=1)\nprocessed_full_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:36.234263Z","iopub.execute_input":"2025-07-18T09:29:36.234570Z","iopub.status.idle":"2025-07-18T09:29:36.275706Z","shell.execute_reply.started":"2025-07-18T09:29:36.234550Z","shell.execute_reply":"2025-07-18T09:29:36.275097Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n0  0.027889  0.193225  0.172921  0.331292  0.312312  0.312595  0.997874   \n1  0.121803  0.284598  0.393619  0.398471  0.645181  0.316704  0.747160   \n2  0.234590  0.224248  0.304405  0.353884  0.574953  0.196832  0.747160   \n3  0.239956  0.267974  0.275582  0.388675  0.402879  0.194440  0.747160   \n4  0.090294  0.248312  0.209072  0.378428  0.339064  0.256038  0.999294   \n\n       dttl     sload     dload  ...  state_3  state_4  state_5  state_6  \\\n0  1.000000  0.424562  0.534539  ...    False    False    False    False   \n1  0.998579  0.401347  0.775718  ...    False    False    False    False   \n2  0.998579  0.326962  0.650937  ...    False    False    False    False   \n3  0.998579  0.351625  0.479722  ...    False    False    False    False   \n4  0.998579  0.402218  0.489854  ...    False    False    False    False   \n\n   state_7  state_8  state_9  state_10  state_11  label  \n0    False    False    False     False     False      0  \n1    False    False    False     False     False      0  \n2    False    False    False     False     False      0  \n3    False    False    False     False     False      0  \n4    False    False    False     False     False      0  \n\n[5 rows x 96 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dur</th>\n      <th>spkts</th>\n      <th>dpkts</th>\n      <th>sbytes</th>\n      <th>dbytes</th>\n      <th>rate</th>\n      <th>sttl</th>\n      <th>dttl</th>\n      <th>sload</th>\n      <th>dload</th>\n      <th>...</th>\n      <th>state_3</th>\n      <th>state_4</th>\n      <th>state_5</th>\n      <th>state_6</th>\n      <th>state_7</th>\n      <th>state_8</th>\n      <th>state_9</th>\n      <th>state_10</th>\n      <th>state_11</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.027889</td>\n      <td>0.193225</td>\n      <td>0.172921</td>\n      <td>0.331292</td>\n      <td>0.312312</td>\n      <td>0.312595</td>\n      <td>0.997874</td>\n      <td>1.000000</td>\n      <td>0.424562</td>\n      <td>0.534539</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.121803</td>\n      <td>0.284598</td>\n      <td>0.393619</td>\n      <td>0.398471</td>\n      <td>0.645181</td>\n      <td>0.316704</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.401347</td>\n      <td>0.775718</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.234590</td>\n      <td>0.224248</td>\n      <td>0.304405</td>\n      <td>0.353884</td>\n      <td>0.574953</td>\n      <td>0.196832</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.326962</td>\n      <td>0.650937</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.239956</td>\n      <td>0.267974</td>\n      <td>0.275582</td>\n      <td>0.388675</td>\n      <td>0.402879</td>\n      <td>0.194440</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.351625</td>\n      <td>0.479722</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.090294</td>\n      <td>0.248312</td>\n      <td>0.209072</td>\n      <td>0.378428</td>\n      <td>0.339064</td>\n      <td>0.256038</td>\n      <td>0.999294</td>\n      <td>0.998579</td>\n      <td>0.402218</td>\n      <td>0.489854</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 96 columns</p>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from featureSelection import PSOFeatureSelector\n\npso = PSOFeatureSelector()\nselected_mask, selected_feature = pso.run_pso(df=processed_full_df, target_column='label', verbose=True)\n\nselected_feature","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T03:09:28.655931Z","iopub.execute_input":"2025-07-18T03:09:28.656333Z","iopub.status.idle":"2025-07-18T07:31:44.560835Z","shell.execute_reply.started":"2025-07-18T03:09:28.656308Z","shell.execute_reply":"2025-07-18T07:31:44.559636Z"}},"outputs":[{"name":"stdout","text":"\n=== Iteration 1/10 ===\nParticle 1/20: Score = 0.8844  --> New personal best! Previous: -inf\n*** New global best score found: 0.8844 (Particle 1) ***\nParticle 2/20: Score = 0.8875  --> New personal best! Previous: -inf\n*** New global best score found: 0.8875 (Particle 2) ***\nParticle 3/20: Score = 0.8805  --> New personal best! Previous: -inf\nParticle 4/20: Score = 0.8887  --> New personal best! Previous: -inf\n*** New global best score found: 0.8887 (Particle 4) ***\nParticle 5/20: Score = 0.8886  --> New personal best! Previous: -inf\nParticle 6/20: Score = 0.8775  --> New personal best! Previous: -inf\nParticle 7/20: Score = 0.8768  --> New personal best! Previous: -inf\nParticle 8/20: Score = 0.8846  --> New personal best! Previous: -inf\nParticle 9/20: Score = 0.8861  --> New personal best! Previous: -inf\nParticle 10/20: Score = 0.8857  --> New personal best! Previous: -inf\nParticle 11/20: Score = 0.8850  --> New personal best! Previous: -inf\nParticle 12/20: Score = 0.8947  --> New personal best! Previous: -inf\n*** New global best score found: 0.8947 (Particle 12) ***\nParticle 13/20: Score = 0.8659  --> New personal best! Previous: -inf\nParticle 14/20: Score = 0.8766  --> New personal best! Previous: -inf\nParticle 15/20: Score = 0.8837  --> New personal best! Previous: -inf\nParticle 16/20: Score = 0.8876  --> New personal best! Previous: -inf\nParticle 17/20: Score = 0.8938  --> New personal best! Previous: -inf\nParticle 18/20: Score = 0.8921  --> New personal best! Previous: -inf\nParticle 19/20: Score = 0.8873  --> New personal best! Previous: -inf\nParticle 20/20: Score = 0.8633  --> New personal best! Previous: -inf\nAfter iteration 1, global best score: 0.8947\n\n=== Iteration 2/10 ===\nParticle 1/20: Score = 0.8852  --> New personal best! Previous: 0.8844\nParticle 2/20: Score = 0.8929  --> New personal best! Previous: 0.8875\nParticle 3/20: Score = 0.8880  --> New personal best! Previous: 0.8805\nParticle 4/20: Score = 0.8890  --> New personal best! Previous: 0.8887\nParticle 5/20: Score = 0.8919  --> New personal best! Previous: 0.8886\nParticle 6/20: Score = 0.8919  --> New personal best! Previous: 0.8775\nParticle 7/20: Score = 0.8902  --> New personal best! Previous: 0.8768\nParticle 8/20: Score = 0.8714\nParticle 9/20: Score = 0.8707\nParticle 10/20: Score = 0.8867  --> New personal best! Previous: 0.8857\nParticle 11/20: Score = 0.8947  --> New personal best! Previous: 0.8850\n*** New global best score found: 0.8947 (Particle 11) ***\nParticle 12/20: Score = 0.8840\nParticle 13/20: Score = 0.8857  --> New personal best! Previous: 0.8659\nParticle 14/20: Score = 0.8908  --> New personal best! Previous: 0.8766\nParticle 15/20: Score = 0.8891  --> New personal best! Previous: 0.8837\nParticle 16/20: Score = 0.8935  --> New personal best! Previous: 0.8876\nParticle 17/20: Score = 0.8850\nParticle 18/20: Score = 0.8868\nParticle 19/20: Score = 0.8908  --> New personal best! Previous: 0.8873\nParticle 20/20: Score = 0.8893  --> New personal best! Previous: 0.8633\nAfter iteration 2, global best score: 0.8947\n\n=== Iteration 3/10 ===\nParticle 1/20: Score = 0.8878  --> New personal best! Previous: 0.8852\nParticle 2/20: Score = 0.8879\nParticle 3/20: Score = 0.8820\nParticle 4/20: Score = 0.8876\nParticle 5/20: Score = 0.8925  --> New personal best! Previous: 0.8919\nParticle 7/20: Score = 0.8898\nParticle 8/20: Score = 0.8879  --> New personal best! Previous: 0.8846\nParticle 9/20: Score = 0.8874  --> New personal best! Previous: 0.8861\nParticle 10/20: Score = 0.8854\nParticle 11/20: Score = 0.8936\nParticle 12/20: Score = 0.8919\nParticle 13/20: Score = 0.8887  --> New personal best! Previous: 0.8857\nParticle 14/20: Score = 0.8892\nParticle 15/20: Score = 0.8844\nParticle 16/20: Score = 0.8781\nParticle 17/20: Score = 0.8917\nParticle 18/20: Score = 0.8900\nParticle 19/20: Score = 0.8865\nParticle 20/20: Score = 0.8919  --> New personal best! Previous: 0.8893\nAfter iteration 3, global best score: 0.8947\n\n=== Iteration 4/10 ===\nParticle 1/20: Score = 0.8937  --> New personal best! Previous: 0.8878\nParticle 2/20: Score = 0.8878\nParticle 3/20: Score = 0.8871\nParticle 4/20: Score = 0.8846\nParticle 5/20: Score = 0.8859\nParticle 6/20: Score = 0.8864\nParticle 7/20: Score = 0.8869\nParticle 8/20: Score = 0.8836\nParticle 9/20: Score = 0.8951  --> New personal best! Previous: 0.8874\n*** New global best score found: 0.8951 (Particle 9) ***\nParticle 10/20: Score = 0.8861\nParticle 11/20: Score = 0.8891\nParticle 12/20: Score = 0.8831\nParticle 13/20: Score = 0.8895  --> New personal best! Previous: 0.8887\nParticle 14/20: Score = 0.8895\nParticle 15/20: Score = 0.8911  --> New personal best! Previous: 0.8891\nParticle 16/20: Score = 0.8856\nParticle 17/20: Score = 0.8849\nParticle 18/20: Score = 0.8900\nParticle 19/20: Score = 0.8952  --> New personal best! Previous: 0.8908\n*** New global best score found: 0.8952 (Particle 19) ***\nParticle 20/20: Score = 0.8907\nAfter iteration 4, global best score: 0.8952\n\n=== Iteration 5/10 ===\nParticle 1/20: Score = 0.8892\nParticle 2/20: Score = 0.8839\nParticle 3/20: Score = 0.8927  --> New personal best! Previous: 0.8880\nParticle 4/20: Score = 0.8868\nParticle 5/20: Score = 0.8753\nParticle 6/20: Score = 0.8907\nParticle 7/20: Score = 0.8911  --> New personal best! Previous: 0.8902\nParticle 8/20: Score = 0.8896  --> New personal best! Previous: 0.8879\nParticle 9/20: Score = 0.8897\nParticle 10/20: Score = 0.8814\nParticle 11/20: Score = 0.8917\nParticle 12/20: Score = 0.8903\nParticle 13/20: Score = 0.8959  --> New personal best! Previous: 0.8895\n*** New global best score found: 0.8959 (Particle 13) ***\nParticle 14/20: Score = 0.8936  --> New personal best! Previous: 0.8908\nParticle 15/20: Score = 0.8917  --> New personal best! Previous: 0.8911\nParticle 16/20: Score = 0.8896\nParticle 17/20: Score = 0.8869\nParticle 18/20: Score = 0.8819\nParticle 19/20: Score = 0.8764\nParticle 20/20: Score = 0.8800\nAfter iteration 5, global best score: 0.8959\n\n=== Iteration 6/10 ===\nParticle 1/20: Score = 0.8918\nParticle 2/20: Score = 0.8927\nParticle 3/20: Score = 0.8924\nParticle 4/20: Score = 0.8940  --> New personal best! Previous: 0.8890\nParticle 5/20: Score = 0.8871\nParticle 6/20: Score = 0.8917\nParticle 7/20: Score = 0.8772\nParticle 8/20: Score = 0.8658\nParticle 9/20: Score = 0.8914\nParticle 10/20: Score = 0.8908  --> New personal best! Previous: 0.8867\nParticle 11/20: Score = 0.8924\nParticle 12/20: Score = 0.8869\nParticle 13/20: Score = 0.8915\nParticle 14/20: Score = 0.8852\nParticle 16/20: Score = 0.8870\nParticle 17/20: Score = 0.8966  --> New personal best! Previous: 0.8938\n*** New global best score found: 0.8966 (Particle 17) ***\nParticle 18/20: Score = 0.8582\nParticle 19/20: Score = 0.8890\nParticle 20/20: Score = 0.8927  --> New personal best! Previous: 0.8919\nAfter iteration 6, global best score: 0.8966\n\n=== Iteration 7/10 ===\nParticle 1/20: Score = 0.8895\nParticle 2/20: Score = 0.8867\nParticle 3/20: Score = 0.8841\nParticle 4/20: Score = 0.8860\nParticle 5/20: Score = 0.8915\nParticle 6/20: Score = 0.8921  --> New personal best! Previous: 0.8919\nParticle 7/20: Score = 0.8908\nParticle 8/20: Score = 0.8931  --> New personal best! Previous: 0.8896\nParticle 9/20: Score = 0.8965  --> New personal best! Previous: 0.8951\nParticle 10/20: Score = 0.8943  --> New personal best! Previous: 0.8908\nParticle 11/20: Score = 0.8897\nParticle 12/20: Score = 0.8917\nParticle 13/20: Score = 0.8894\nParticle 14/20: Score = 0.8951  --> New personal best! Previous: 0.8936\nParticle 15/20: Score = 0.8944  --> New personal best! Previous: 0.8920\nParticle 16/20: Score = 0.8926\nParticle 17/20: Score = 0.8915\nParticle 18/20: Score = 0.8838\nParticle 19/20: Score = 0.8948\nParticle 20/20: Score = 0.8890\nAfter iteration 7, global best score: 0.8966\n\n=== Iteration 8/10 ===\nParticle 1/20: Score = 0.8883\nParticle 2/20: Score = 0.8937  --> New personal best! Previous: 0.8929\nParticle 3/20: Score = 0.8870\nParticle 4/20: Score = 0.8923\nParticle 5/20: Score = 0.8895\nParticle 6/20: Score = 0.8899\nParticle 7/20: Score = 0.8957  --> New personal best! Previous: 0.8911\nParticle 8/20: Score = 0.8917\nParticle 9/20: Score = 0.8849\nParticle 12/20: Score = 0.8917\nParticle 13/20: Score = 0.8870\nParticle 14/20: Score = 0.8924\nParticle 15/20: Score = 0.8939\nParticle 16/20: Score = 0.8885\nParticle 17/20: Score = 0.8875\nParticle 18/20: Score = 0.8932  --> New personal best! Previous: 0.8921\nParticle 19/20: Score = 0.8946\nParticle 20/20: Score = 0.8952  --> New personal best! Previous: 0.8927\nAfter iteration 8, global best score: 0.8966\n\n=== Iteration 9/10 ===\nParticle 1/20: Score = 0.8967  --> New personal best! Previous: 0.8937\n*** New global best score found: 0.8967 (Particle 1) ***\nParticle 2/20: Score = 0.8931\nParticle 3/20: Score = 0.8941  --> New personal best! Previous: 0.8927\nParticle 4/20: Score = 0.8906\nParticle 5/20: Score = 0.8920\nParticle 6/20: Score = 0.8879\nParticle 7/20: Score = 0.8892\nParticle 8/20: Score = 0.8914\nParticle 9/20: Score = 0.8929\nParticle 10/20: Score = 0.8898\nParticle 11/20: Score = 0.8915\nParticle 12/20: Score = 0.8763\nParticle 13/20: Score = 0.8953\nParticle 14/20: Score = 0.8848\nParticle 15/20: Score = 0.8854\nParticle 16/20: Score = 0.8919\nParticle 17/20: Score = 0.8864\nParticle 18/20: Score = 0.8900\nParticle 19/20: Score = 0.8910\nParticle 20/20: Score = 0.8874\nAfter iteration 9, global best score: 0.8967\n\n=== Iteration 10/10 ===\nParticle 1/20: Score = 0.8944\nParticle 2/20: Score = 0.8950  --> New personal best! Previous: 0.8937\nParticle 3/20: Score = 0.8908\nParticle 4/20: Score = 0.8938\nParticle 5/20: Score = 0.8854\nParticle 6/20: Score = 0.8938  --> New personal best! Previous: 0.8921\nParticle 7/20: Score = 0.8842\nParticle 8/20: Score = 0.8941  --> New personal best! Previous: 0.8931\nParticle 9/20: Score = 0.8928\nParticle 10/20: Score = 0.8887\nParticle 11/20: Score = 0.8867\nParticle 12/20: Score = 0.8949  --> New personal best! Previous: 0.8947\nParticle 13/20: Score = 0.8909\nParticle 14/20: Score = 0.8809\nParticle 15/20: Score = 0.8919\nParticle 16/20: Score = 0.8909\nParticle 17/20: Score = 0.8881\nParticle 18/20: Score = 0.8905\nParticle 19/20: Score = 0.8789\nParticle 20/20: Score = 0.8912\nAfter iteration 10, global best score: 0.8967\n\nâœ… Selected 52 features out of 95\nSelected features: ['sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'dinpkt', 'sjit', 'swin', 'dtcpb', 'synack', 'smean', 'dmean', 'response_body_len', 'ct_state_ttl', 'ct_src_dport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'proto_1', 'proto_2', 'proto_3', 'proto_4', 'proto_7', 'proto_10', 'proto_11', 'proto_12', 'proto_13', 'proto_14', 'proto_17', 'proto_19', 'proto_22', 'proto_24', 'proto_26', 'proto_27', 'proto_28', 'proto_29', 'proto_30', 'service_1', 'service_7', 'service_11', 'state_1', 'state_3', 'state_5', 'state_6', 'state_7', 'state_8', 'state_9', 'state_11']\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Index(['sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss',\n       'dloss', 'dinpkt', 'sjit', 'swin', 'dtcpb', 'synack', 'smean', 'dmean',\n       'response_body_len', 'ct_state_ttl', 'ct_src_dport_ltm',\n       'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'proto_1', 'proto_2',\n       'proto_3', 'proto_4', 'proto_7', 'proto_10', 'proto_11', 'proto_12',\n       'proto_13', 'proto_14', 'proto_17', 'proto_19', 'proto_22', 'proto_24',\n       'proto_26', 'proto_27', 'proto_28', 'proto_29', 'proto_30', 'service_1',\n       'service_7', 'service_11', 'state_1', 'state_3', 'state_5', 'state_6',\n       'state_7', 'state_8', 'state_9', 'state_11'],\n      dtype='object')"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"columns_to_keep = ['sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss',\n       'dloss', 'dinpkt', 'sjit', 'swin', 'dtcpb', 'synack', 'smean', 'dmean',\n       'response_body_len', 'ct_state_ttl', 'ct_src_dport_ltm',\n       'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'proto_1', 'proto_2',\n       'proto_3', 'proto_4', 'proto_7', 'proto_10', 'proto_11', 'proto_12',\n       'proto_13', 'proto_14', 'proto_17', 'proto_19', 'proto_22', 'proto_24',\n       'proto_26', 'proto_27', 'proto_28', 'proto_29', 'proto_30', 'service_1',\n       'service_7', 'service_11', 'state_1', 'state_3', 'state_5', 'state_6',\n       'state_7', 'state_8', 'state_9', 'state_11']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:44.953114Z","iopub.execute_input":"2025-07-18T09:29:44.953444Z","iopub.status.idle":"2025-07-18T09:29:44.957849Z","shell.execute_reply.started":"2025-07-18T09:29:44.953421Z","shell.execute_reply":"2025-07-18T09:29:44.957286Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df_selected = processed_full_df[columns_to_keep].copy()\ndf_selected.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:45.008456Z","iopub.execute_input":"2025-07-18T09:29:45.008840Z","iopub.status.idle":"2025-07-18T09:29:45.055076Z","shell.execute_reply.started":"2025-07-18T09:29:45.008825Z","shell.execute_reply":"2025-07-18T09:29:45.054390Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(257673, 52)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"df_selected.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:45.056164Z","iopub.execute_input":"2025-07-18T09:29:45.056458Z","iopub.status.idle":"2025-07-18T09:29:45.063080Z","shell.execute_reply.started":"2025-07-18T09:29:45.056441Z","shell.execute_reply":"2025-07-18T09:29:45.062503Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"sbytes               float64\ndbytes               float64\nrate                 float64\nsttl                 float64\ndttl                 float64\nsload                float64\ndload                float64\nsloss                float64\ndloss                float64\ndinpkt               float64\nsjit                 float64\nswin                 float64\ndtcpb                float64\nsynack               float64\nsmean                float64\ndmean                float64\nresponse_body_len    float64\nct_state_ttl         float64\nct_src_dport_ltm     float64\nct_dst_src_ltm       float64\nis_ftp_login         float64\nct_ftp_cmd           float64\nproto_1                 bool\nproto_2                 bool\nproto_3                 bool\nproto_4                 bool\nproto_7                 bool\nproto_10                bool\nproto_11                bool\nproto_12                bool\nproto_13                bool\nproto_14                bool\nproto_17                bool\nproto_19                bool\nproto_22                bool\nproto_24                bool\nproto_26                bool\nproto_27                bool\nproto_28                bool\nproto_29                bool\nproto_30                bool\nservice_1               bool\nservice_7               bool\nservice_11              bool\nstate_1                 bool\nstate_3                 bool\nstate_5                 bool\nstate_6                 bool\nstate_7                 bool\nstate_8                 bool\nstate_9                 bool\nstate_11                bool\ndtype: object"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"from record_level_embedding import RecordLevelEmbedder\nnumerical_columns = [\n   'sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','dinpkt','sjit','swin','dtcpb','synack','smean','dmean','response_body_len',\n    'ct_state_ttl', 'ct_src_dport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd']\n\nembedder = RecordLevelEmbedder(selected_df = df_selected, numerical_columns = numerical_columns, embed_dimension= 64)\n\nembedded_df = embedder.transform_to_df()\n\nembedded_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:29:45.064043Z","iopub.execute_input":"2025-07-18T09:29:45.064353Z","iopub.status.idle":"2025-07-18T09:30:09.435533Z","shell.execute_reply.started":"2025-07-18T09:29:45.064306Z","shell.execute_reply":"2025-07-18T09:30:09.434761Z"}},"outputs":[{"name":"stdout","text":"[INFO] Initializing RecordLevelEmbedder...\n[INFO] Detecting categorical blocks...\n[INFO] Detected 3 categorical blocks:\n   - proto: 19 columns\n   - service: 3 columns\n   - state: 8 columns\n[INFO] Embedder initialized with embedding dimension 64.\n[INFO] Building Keras embedding model...\n   - Adding numerical input: sbytes\n   - Adding numerical input: dbytes\n   - Adding numerical input: rate\n   - Adding numerical input: sttl\n   - Adding numerical input: dttl\n   - Adding numerical input: sload\n   - Adding numerical input: dload\n   - Adding numerical input: sloss\n   - Adding numerical input: dloss\n   - Adding numerical input: dinpkt\n   - Adding numerical input: sjit\n   - Adding numerical input: swin\n   - Adding numerical input: dtcpb\n   - Adding numerical input: synack\n   - Adding numerical input: smean\n   - Adding numerical input: dmean\n   - Adding numerical input: response_body_len\n   - Adding numerical input: ct_state_ttl\n   - Adding numerical input: ct_src_dport_ltm\n   - Adding numerical input: ct_dst_src_ltm\n   - Adding numerical input: is_ftp_login\n   - Adding numerical input: ct_ftp_cmd\n   - Adding categorical block input: proto (19 columns)\n   - Adding categorical block input: service (3 columns)\n   - Adding categorical block input: state (8 columns)\n[INFO] Concatenating 25 inputs and applying Dense projection to dimension 64.\n[INFO] Projection complete. Output embedding shape: (64,)\n[INFO] Model build complete.\n[INFO] Preparing inputs for embedding. Number of rows: 257673\n   - Prepared numerical input: sbytes\n   - Prepared numerical input: dbytes\n   - Prepared numerical input: rate\n   - Prepared numerical input: sttl\n   - Prepared numerical input: dttl\n   - Prepared numerical input: sload\n   - Prepared numerical input: dload\n   - Prepared numerical input: sloss\n   - Prepared numerical input: dloss\n   - Prepared numerical input: dinpkt\n   - Prepared numerical input: sjit\n   - Prepared numerical input: swin\n   - Prepared numerical input: dtcpb\n   - Prepared numerical input: synack\n   - Prepared numerical input: smean\n   - Prepared numerical input: dmean\n   - Prepared numerical input: response_body_len\n   - Prepared numerical input: ct_state_ttl\n   - Prepared numerical input: ct_src_dport_ltm\n   - Prepared numerical input: ct_dst_src_ltm\n   - Prepared numerical input: is_ftp_login\n   - Prepared numerical input: ct_ftp_cmd\n   - Prepared categorical block input: proto\n   - Prepared categorical block input: service\n   - Prepared categorical block input: state\n[INFO] Performing embedding inference...\n\u001b[1m8053/8053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step\n[INFO] Embedding complete. Output shape: (257673, 64)\n[INFO] Embedding DataFrame ready.\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n0 -0.517890  0.389708 -0.415776 -0.193178 -0.362159 -1.079117 -0.427850   \n1 -0.453383  0.531504 -0.554560 -0.151107 -0.499106 -1.101279 -0.460603   \n2 -0.480481  0.504831 -0.611274 -0.271098 -0.473030 -1.139839 -0.440460   \n3 -0.620863  0.227751 -0.532981 -0.274855 -0.182096 -1.074285 -0.512655   \n4 -0.463144  0.468762 -0.545000 -0.453566 -0.373296 -1.260049 -0.640231   \n\n    embed_7   embed_8   embed_9  ...  embed_54  embed_55  embed_56  embed_57  \\\n0  0.026337  0.457210 -0.185582  ... -0.952518 -0.375622  0.786778 -0.470167   \n1  0.119242  0.436695 -0.125054  ... -0.987737 -0.320164  0.839663 -0.477795   \n2  0.070507  0.603166 -0.147639  ... -0.867667 -0.207396  0.809151 -0.415374   \n3 -0.034567  0.326234 -0.111355  ... -0.802008 -0.384400  0.786532 -0.275384   \n4 -0.148146  0.617678 -0.034824  ... -0.749090 -0.124910  0.788831 -0.410715   \n\n   embed_58  embed_59  embed_60  embed_61  embed_62  embed_63  \n0 -0.101331  0.896281 -0.312254 -0.316843  0.504701  0.143516  \n1 -0.246207  0.857436 -0.321194 -0.438306  0.614095  0.057004  \n2 -0.182325  1.026290 -0.350676 -0.419966  0.647681  0.095222  \n3  0.070809  0.650666 -0.218445 -0.501259  0.539020 -0.070217  \n4 -0.103532  1.169846 -0.310665 -0.436652  0.452920  0.204747  \n\n[5 rows x 64 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embed_0</th>\n      <th>embed_1</th>\n      <th>embed_2</th>\n      <th>embed_3</th>\n      <th>embed_4</th>\n      <th>embed_5</th>\n      <th>embed_6</th>\n      <th>embed_7</th>\n      <th>embed_8</th>\n      <th>embed_9</th>\n      <th>...</th>\n      <th>embed_54</th>\n      <th>embed_55</th>\n      <th>embed_56</th>\n      <th>embed_57</th>\n      <th>embed_58</th>\n      <th>embed_59</th>\n      <th>embed_60</th>\n      <th>embed_61</th>\n      <th>embed_62</th>\n      <th>embed_63</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.517890</td>\n      <td>0.389708</td>\n      <td>-0.415776</td>\n      <td>-0.193178</td>\n      <td>-0.362159</td>\n      <td>-1.079117</td>\n      <td>-0.427850</td>\n      <td>0.026337</td>\n      <td>0.457210</td>\n      <td>-0.185582</td>\n      <td>...</td>\n      <td>-0.952518</td>\n      <td>-0.375622</td>\n      <td>0.786778</td>\n      <td>-0.470167</td>\n      <td>-0.101331</td>\n      <td>0.896281</td>\n      <td>-0.312254</td>\n      <td>-0.316843</td>\n      <td>0.504701</td>\n      <td>0.143516</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.453383</td>\n      <td>0.531504</td>\n      <td>-0.554560</td>\n      <td>-0.151107</td>\n      <td>-0.499106</td>\n      <td>-1.101279</td>\n      <td>-0.460603</td>\n      <td>0.119242</td>\n      <td>0.436695</td>\n      <td>-0.125054</td>\n      <td>...</td>\n      <td>-0.987737</td>\n      <td>-0.320164</td>\n      <td>0.839663</td>\n      <td>-0.477795</td>\n      <td>-0.246207</td>\n      <td>0.857436</td>\n      <td>-0.321194</td>\n      <td>-0.438306</td>\n      <td>0.614095</td>\n      <td>0.057004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.480481</td>\n      <td>0.504831</td>\n      <td>-0.611274</td>\n      <td>-0.271098</td>\n      <td>-0.473030</td>\n      <td>-1.139839</td>\n      <td>-0.440460</td>\n      <td>0.070507</td>\n      <td>0.603166</td>\n      <td>-0.147639</td>\n      <td>...</td>\n      <td>-0.867667</td>\n      <td>-0.207396</td>\n      <td>0.809151</td>\n      <td>-0.415374</td>\n      <td>-0.182325</td>\n      <td>1.026290</td>\n      <td>-0.350676</td>\n      <td>-0.419966</td>\n      <td>0.647681</td>\n      <td>0.095222</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.620863</td>\n      <td>0.227751</td>\n      <td>-0.532981</td>\n      <td>-0.274855</td>\n      <td>-0.182096</td>\n      <td>-1.074285</td>\n      <td>-0.512655</td>\n      <td>-0.034567</td>\n      <td>0.326234</td>\n      <td>-0.111355</td>\n      <td>...</td>\n      <td>-0.802008</td>\n      <td>-0.384400</td>\n      <td>0.786532</td>\n      <td>-0.275384</td>\n      <td>0.070809</td>\n      <td>0.650666</td>\n      <td>-0.218445</td>\n      <td>-0.501259</td>\n      <td>0.539020</td>\n      <td>-0.070217</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.463144</td>\n      <td>0.468762</td>\n      <td>-0.545000</td>\n      <td>-0.453566</td>\n      <td>-0.373296</td>\n      <td>-1.260049</td>\n      <td>-0.640231</td>\n      <td>-0.148146</td>\n      <td>0.617678</td>\n      <td>-0.034824</td>\n      <td>...</td>\n      <td>-0.749090</td>\n      <td>-0.124910</td>\n      <td>0.788831</td>\n      <td>-0.410715</td>\n      <td>-0.103532</td>\n      <td>1.169846</td>\n      <td>-0.310665</td>\n      <td>-0.436652</td>\n      <td>0.452920</td>\n      <td>0.204747</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 64 columns</p>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Binary classification\nimport numpy as np\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\n\n\nprint(processed_full_df['label'].unique())\n\nbinary_target = (processed_full_df['label'] != 0).astype(int).values\nunique, counts = np.unique(binary_target, return_counts=True)\nprint(\"Classes and their counts:\")\nfor cls, cnt in zip(unique, counts):\n    print(f\"Class {cls}: {cnt}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:30:09.437164Z","iopub.execute_input":"2025-07-18T09:30:09.437445Z","iopub.status.idle":"2025-07-18T09:30:09.448156Z","shell.execute_reply.started":"2025-07-18T09:30:09.437427Z","shell.execute_reply":"2025-07-18T09:30:09.447360Z"}},"outputs":[{"name":"stdout","text":"[0 1]\nClasses and their counts:\nClass 0: 93000\nClass 1: 164673\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom transformer import BasicTransformer\nfrom classification import LastTokenClassificationHead\nfrom sklearn.model_selection import train_test_split\n\n\n\n# input data\nX_embed = embedded_df.values                   # shape: (num_samples, embed_dim)\nX_embed_seq = tf.expand_dims(X_embed, axis=1)  # shape: (batch_size, 1, embed_dim)\n\ninput_layer = Input(shape=(1, X_embed.shape[1]), name=\"record_input\")\n\n# Create transformer\ntransformer = BasicTransformer(\n    n_layers=2,\n    internal_size=128,\n    n_heads=4,\n    verbose=True  # See progress!\n)\n\n\nx = transformer.apply(input_layer, training=True)\n\n\n# Create head\nclassification_head = LastTokenClassificationHead()\n\n# Pool last token\nx = classification_head.apply(x)\n\n#  Add MLP head  \nfor i, layer_size in enumerate([128]):\n    x = Dense(layer_size, activation=\"relu\", name=f\"classification_mlp_{i}_{layer_size}\")(x)\n    x = Dropout(0.1)(x)\n\n#  output layer for binary classification\noutput_layer = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(x)\n\n# Build model  \nmodel = Model(inputs=input_layer, outputs=output_layer)\nmodel.summary()\n\n# Compile model \nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n    jit_compile=True\n)\n\n# split data\n\nX_np = X_embed_seq.numpy() if hasattr(X_embed_seq, 'numpy') else np.array(X_embed_seq)\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_np, binary_target, test_size=0.2, random_state=42, stratify=binary_target\n)\n\n# Train\nmodel.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=20,\n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:30:09.448933Z","iopub.execute_input":"2025-07-18T09:30:09.449136Z","iopub.status.idle":"2025-07-18T09:39:33.445284Z","shell.execute_reply.started":"2025-07-18T09:30:09.449121Z","shell.execute_reply":"2025-07-18T09:39:33.444537Z"}},"outputs":[{"name":"stdout","text":"[BasicTransformer] Applying Encoder Block 1/2\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[BasicTransformer] Applying Encoder Block 2/2\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[BasicTransformer] Final output shape: (None, 1, 64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ record_input (\u001b[38;5;33mInputLayer\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_0_transformer_encoder     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚       \u001b[38;5;34m149,504\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_1_transformer_encoder     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚       \u001b[38;5;34m149,504\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ slice_last (\u001b[38;5;33mLambda\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ classification_mlp_0_128        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m8,320\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mDense\u001b[0m)                         â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ binary_output (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ record_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_0_transformer_encoder     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">149,504</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_1_transformer_encoder     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">149,504</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ slice_last (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ classification_mlp_0_128        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m307,457\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,457</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m307,457\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,457</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/20\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8965 - loss: 0.2058[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.2058 - val_accuracy: 0.9183 - val_loss: 0.1694\nEpoch 2/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.1756 - val_accuracy: 0.9157 - val_loss: 0.1727\nEpoch 3/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9150 - loss: 0.1696 - val_accuracy: 0.9219 - val_loss: 0.1628\nEpoch 4/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.1654 - val_accuracy: 0.9245 - val_loss: 0.1553\nEpoch 5/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.1606 - val_accuracy: 0.9259 - val_loss: 0.1523\nEpoch 6/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9221 - loss: 0.1573 - val_accuracy: 0.9215 - val_loss: 0.1592\nEpoch 7/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.1568 - val_accuracy: 0.9277 - val_loss: 0.1542\nEpoch 8/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.1535 - val_accuracy: 0.9247 - val_loss: 0.1477\nEpoch 9/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.1513 - val_accuracy: 0.9052 - val_loss: 0.1714\nEpoch 10/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.1490 - val_accuracy: 0.9287 - val_loss: 0.1420\nEpoch 11/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.1475 - val_accuracy: 0.9264 - val_loss: 0.1464\nEpoch 12/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.1453 - val_accuracy: 0.9248 - val_loss: 0.1539\nEpoch 13/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.1445 - val_accuracy: 0.9320 - val_loss: 0.1376\nEpoch 14/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.1458 - val_accuracy: 0.9278 - val_loss: 0.1407\nEpoch 15/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.1420 - val_accuracy: 0.9316 - val_loss: 0.1412\nEpoch 16/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.9295 - loss: 0.1414 - val_accuracy: 0.9320 - val_loss: 0.1367\nEpoch 17/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.1400 - val_accuracy: 0.9320 - val_loss: 0.1386\nEpoch 18/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.1475 - val_accuracy: 0.9256 - val_loss: 0.1450\nEpoch 19/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.1408 - val_accuracy: 0.9327 - val_loss: 0.1351\nEpoch 20/20\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.1396 - val_accuracy: 0.9323 - val_loss: 0.1364\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7911e2596350>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# evaluate the model\nresults = model.evaluate(X_val, y_val)\nprint(f\"Validation loss: {results[0]:.4f}, Validation accuracy: {results[1]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:39:33.446226Z","iopub.execute_input":"2025-07-18T09:39:33.446466Z","iopub.status.idle":"2025-07-18T09:39:37.247783Z","shell.execute_reply.started":"2025-07-18T09:39:33.446449Z","shell.execute_reply":"2025-07-18T09:39:37.247210Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1611/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.1361\nValidation loss: 0.1364, Validation accuracy: 0.9323\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from sklearn.metrics import f1_score, confusion_matrix\nimport numpy as np\n\n# Predict probabilities\ny_pred_prob = model.predict(X_val)\ny_pred = (y_pred_prob >= 0.5).astype(int).flatten()\n\n# F1\nf1 = f1_score(y_val, y_pred)\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Confusion matrix\ncm = confusion_matrix(y_val, y_pred, labels=[0, 1])\nprint(\"Confusion Matrix:\\n\", cm)\n\nif cm.shape == (2, 2):\n    tn, fp, fn, tp = cm.ravel()\n    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n    print(f\"Detection Rate (Recall): {detection_rate:.4f}\")\n    print(f\"False Alarm Rate: {false_alarm_rate:.4f}\")\nelse:\n    print(\"Confusion matrix does not contain both classes!\")\n    print(\"Check your labels: y_val:\", np.unique(y_val), \" y_pred:\", np.unique(y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T09:53:45.094430Z","iopub.execute_input":"2025-07-18T09:53:45.094708Z","iopub.status.idle":"2025-07-18T09:53:48.123606Z","shell.execute_reply.started":"2025-07-18T09:53:45.094690Z","shell.execute_reply":"2025-07-18T09:53:48.122948Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1611/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nF1 Score: 0.9469\nConfusion Matrix:\n [[16905  1695]\n [ 1795 31140]]\nDetection Rate (Recall): 0.9455\nFalse Alarm Rate: 0.0911\n","output_type":"stream"}],"execution_count":31}]}