{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12493033,"sourceType":"datasetVersion","datasetId":7883909}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Tanveer2719/NIDS_Coursework.git\n%cd /kaggle/working/NIDS_Coursework/My_Code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:08:59.029469Z","iopub.execute_input":"2025-07-19T05:08:59.029709Z","iopub.status.idle":"2025-07-19T05:08:59.665178Z","shell.execute_reply.started":"2025-07-19T05:08:59.029680Z","shell.execute_reply":"2025-07-19T05:08:59.664021Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'NIDS_Coursework'...\nremote: Enumerating objects: 147, done.\u001b[K\nremote: Counting objects: 100% (147/147), done.\u001b[K\nremote: Compressing objects: 100% (97/97), done.\u001b[K\nremote: Total 147 (delta 58), reused 136 (delta 47), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (147/147), 176.08 KiB | 6.29 MiB/s, done.\nResolving deltas: 100% (58/58), done.\n/kaggle/working/NIDS_Coursework/My_Code\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npath = \"/kaggle/input/unsw-nb-15/UNSW-NB15_combined.csv\"\n\ndf = pd.read_csv(path)\n\nprint(df.shape)\ndf = df.drop(columns=['id', 'label'])\nprint(df.shape)\n\nprint(f\"ğŸ§¾ Unique class labels: {df['attack_cat'].unique()}\")\ndf['label'] = df['attack_cat'].apply(lambda x: 0 if x == 'Normal' else 1)\n\nprint(f'Unique values for label {df[\"label\"].unique()}')\n\ndf = df.drop(columns=[\"attack_cat\"])\nprint(f'new shape{df.shape}')\n\nprint(df.dtypes)\n\n\n# --------------------------- perform preprocessing--------------\n\nfrom preprocess import Preprocess\n\n# separate the features and labels so that the labesl are not encoded\nlabels = df['label']\nfeatures = df.drop(columns=['label'])\n\npp = Preprocess()\nprocessed_features = pp.fit_transform_df_auto(df = features,n_categorical_levels=32, expected_categorical_format='onehot')\n\nprint(processed_features.shape)\n\n# concat the features and the labels\nprocessed_full_df = pd.concat([processed_features, labels], axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:08:59.667187Z","iopub.execute_input":"2025-07-19T05:08:59.667433Z","iopub.status.idle":"2025-07-19T05:09:06.009957Z","shell.execute_reply.started":"2025-07-19T05:08:59.667409Z","shell.execute_reply":"2025-07-19T05:09:06.009145Z"}},"outputs":[{"name":"stdout","text":"(257673, 45)\n(257673, 43)\nğŸ§¾ Unique class labels: ['Normal' 'Backdoor' 'Analysis' 'Fuzzers' 'Shellcode' 'Reconnaissance'\n 'Exploits' 'DoS' 'Worms' 'Generic']\nUnique values for label [0 1]\nnew shape(257673, 43)\ndur                  float64\nproto                 object\nservice               object\nstate                 object\nspkts                  int64\ndpkts                  int64\nsbytes                 int64\ndbytes                 int64\nrate                 float64\nsttl                   int64\ndttl                   int64\nsload                float64\ndload                float64\nsloss                  int64\ndloss                  int64\nsinpkt               float64\ndinpkt               float64\nsjit                 float64\ndjit                 float64\nswin                   int64\nstcpb                  int64\ndtcpb                  int64\ndwin                   int64\ntcprtt               float64\nsynack               float64\nackdat               float64\nsmean                  int64\ndmean                  int64\ntrans_depth            int64\nresponse_body_len      int64\nct_srv_src             int64\nct_state_ttl           int64\nct_dst_ltm             int64\nct_src_dport_ltm       int64\nct_dst_sport_ltm       int64\nct_dst_src_ltm         int64\nis_ftp_login           int64\nct_ftp_cmd             int64\nct_flw_http_mthd       int64\nct_src_ltm             int64\nct_srv_dst             int64\nis_sm_ips_ports        int64\nlabel                  int64\ndtype: object\nEncoding the 32 levels for proto\nEncoding the 13 levels for service\nEncoding the 11 levels for state\n(257673, 95)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Filter out categorical one-hot encoded columns\nnumerical_columns = [col for col in processed_full_df \n                     if not (col.startswith(\"proto_\") or \n                             col.startswith(\"service_\") or \n                             col.startswith(\"state_\") or\n                             col == 'label')]\n\nnumerical_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:09:06.010936Z","iopub.execute_input":"2025-07-19T05:09:06.011467Z","iopub.status.idle":"2025-07-19T05:09:06.019805Z","shell.execute_reply.started":"2025-07-19T05:09:06.011435Z","shell.execute_reply":"2025-07-19T05:09:06.018998Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['dur',\n 'spkts',\n 'dpkts',\n 'sbytes',\n 'dbytes',\n 'rate',\n 'sttl',\n 'dttl',\n 'sload',\n 'dload',\n 'sloss',\n 'dloss',\n 'sinpkt',\n 'dinpkt',\n 'sjit',\n 'djit',\n 'swin',\n 'stcpb',\n 'dtcpb',\n 'dwin',\n 'tcprtt',\n 'synack',\n 'ackdat',\n 'smean',\n 'dmean',\n 'trans_depth',\n 'response_body_len',\n 'ct_srv_src',\n 'ct_state_ttl',\n 'ct_dst_ltm',\n 'ct_src_dport_ltm',\n 'ct_dst_sport_ltm',\n 'ct_dst_src_ltm',\n 'is_ftp_login',\n 'ct_ftp_cmd',\n 'ct_flw_http_mthd',\n 'ct_src_ltm',\n 'ct_srv_dst',\n 'is_sm_ips_ports']"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"target = processed_full_df['label']\nfeatures = processed_full_df.drop(columns=['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:09:06.020870Z","iopub.execute_input":"2025-07-19T05:09:06.021184Z","iopub.status.idle":"2025-07-19T05:09:06.071544Z","shell.execute_reply.started":"2025-07-19T05:09:06.021158Z","shell.execute_reply":"2025-07-19T05:09:06.070770Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from record_level_embedding import RecordLevelEmbedder\n\nembedder = RecordLevelEmbedder(selected_df = features, numerical_columns = numerical_columns, embed_dimension= 64)\n\nembedded_df = embedder.transform_to_df()\nembedded_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:09:06.072381Z","iopub.execute_input":"2025-07-19T05:09:06.072666Z","iopub.status.idle":"2025-07-19T05:09:54.852246Z","shell.execute_reply.started":"2025-07-19T05:09:06.072642Z","shell.execute_reply":"2025-07-19T05:09:54.851261Z"}},"outputs":[{"name":"stderr","text":"2025-07-19 05:09:07.557773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752901747.738439      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752901747.789847      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Initializing RecordLevelEmbedder...\n[INFO] Detecting categorical blocks...\n[INFO] Detected 3 categorical blocks:\n   - proto: 32 columns\n   - service: 13 columns\n   - state: 11 columns\n[INFO] Embedder initialized with embedding dimension 64.\n[INFO] Building Keras embedding model...\n   - Adding numerical input: dur\n   - Adding numerical input: spkts\n   - Adding numerical input: dpkts\n   - Adding numerical input: sbytes\n   - Adding numerical input: dbytes\n   - Adding numerical input: rate\n   - Adding numerical input: sttl\n   - Adding numerical input: dttl\n   - Adding numerical input: sload\n   - Adding numerical input: dload\n   - Adding numerical input: sloss\n   - Adding numerical input: dloss\n   - Adding numerical input: sinpkt\n   - Adding numerical input: dinpkt\n   - Adding numerical input: sjit\n   - Adding numerical input: djit\n   - Adding numerical input: swin\n   - Adding numerical input: stcpb\n   - Adding numerical input: dtcpb\n   - Adding numerical input: dwin\n   - Adding numerical input: tcprtt\n   - Adding numerical input: synack\n   - Adding numerical input: ackdat\n   - Adding numerical input: smean\n   - Adding numerical input: dmean\n   - Adding numerical input: trans_depth\n   - Adding numerical input: response_body_len\n   - Adding numerical input: ct_srv_src\n   - Adding numerical input: ct_state_ttl\n   - Adding numerical input: ct_dst_ltm\n   - Adding numerical input: ct_src_dport_ltm\n   - Adding numerical input: ct_dst_sport_ltm\n   - Adding numerical input: ct_dst_src_ltm\n   - Adding numerical input: is_ftp_login\n   - Adding numerical input: ct_ftp_cmd\n   - Adding numerical input: ct_flw_http_mthd\n   - Adding numerical input: ct_src_ltm\n   - Adding numerical input: ct_srv_dst\n   - Adding numerical input: is_sm_ips_ports\n   - Adding categorical block input: proto (32 columns)\n   - Adding categorical block input: service (13 columns)\n   - Adding categorical block input: state (11 columns)\n[INFO] Concatenating 42 inputs and applying Dense projection to dimension 64.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752901760.022552      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1752901760.023262      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Projection complete. Output embedding shape: (64,)\n[INFO] Model build complete.\n[INFO] Preparing inputs for embedding. Number of rows: 257673\n   - Prepared numerical input: dur\n   - Prepared numerical input: spkts\n   - Prepared numerical input: dpkts\n   - Prepared numerical input: sbytes\n   - Prepared numerical input: dbytes\n   - Prepared numerical input: rate\n   - Prepared numerical input: sttl\n   - Prepared numerical input: dttl\n   - Prepared numerical input: sload\n   - Prepared numerical input: dload\n   - Prepared numerical input: sloss\n   - Prepared numerical input: dloss\n   - Prepared numerical input: sinpkt\n   - Prepared numerical input: dinpkt\n   - Prepared numerical input: sjit\n   - Prepared numerical input: djit\n   - Prepared numerical input: swin\n   - Prepared numerical input: stcpb\n   - Prepared numerical input: dtcpb\n   - Prepared numerical input: dwin\n   - Prepared numerical input: tcprtt\n   - Prepared numerical input: synack\n   - Prepared numerical input: ackdat\n   - Prepared numerical input: smean\n   - Prepared numerical input: dmean\n   - Prepared numerical input: trans_depth\n   - Prepared numerical input: response_body_len\n   - Prepared numerical input: ct_srv_src\n   - Prepared numerical input: ct_state_ttl\n   - Prepared numerical input: ct_dst_ltm\n   - Prepared numerical input: ct_src_dport_ltm\n   - Prepared numerical input: ct_dst_sport_ltm\n   - Prepared numerical input: ct_dst_src_ltm\n   - Prepared numerical input: is_ftp_login\n   - Prepared numerical input: ct_ftp_cmd\n   - Prepared numerical input: ct_flw_http_mthd\n   - Prepared numerical input: ct_src_ltm\n   - Prepared numerical input: ct_srv_dst\n   - Prepared numerical input: is_sm_ips_ports\n   - Prepared categorical block input: proto\n   - Prepared categorical block input: service\n   - Prepared categorical block input: state\n[INFO] Performing embedding inference...\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752901761.889115     110 service.cc:148] XLA service 0x7a4a100151a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752901761.889699     110 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752901761.889720     110 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752901761.925987     110 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  48/8053\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m26s\u001b[0m 3ms/step    ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752901762.241530     110 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8053/8053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step\n[INFO] Embedding complete. Output shape: (257673, 64)\n[INFO] Embedding DataFrame ready.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n0  0.310413  0.606933  0.216994  0.209848 -0.005488 -0.271681 -0.333853   \n1  0.282402  0.776553  0.296450  0.394691  0.046037 -0.187800 -0.300264   \n2  0.232624  0.700284  0.260850  0.293666 -0.051036 -0.153891 -0.266284   \n3  0.261392  0.286974  0.145569  0.205778 -0.128228 -0.277861 -0.341288   \n4  0.248244  0.677931  0.501866  0.329943 -0.000823 -0.202213 -0.535481   \n\n    embed_7   embed_8   embed_9  ...  embed_54  embed_55  embed_56  embed_57  \\\n0 -0.330938  0.481963 -0.687171  ...  0.192107 -0.535439  0.373295 -0.330445   \n1 -0.263211  0.335799 -0.959045  ...  0.135620 -0.380019  0.334632 -0.384081   \n2 -0.240626  0.408849 -0.953547  ...  0.241028 -0.360370  0.366388 -0.284664   \n3 -0.291409  0.296473 -0.753489  ...  0.078866 -0.124185  0.254482  0.005507   \n4 -0.107309  0.520295 -0.815006  ...  0.293317 -0.477410  0.389562 -0.311417   \n\n   embed_58  embed_59  embed_60  embed_61  embed_62  embed_63  \n0 -0.463618  0.424192  0.361674  0.424921  0.164630  0.737256  \n1 -0.555736  0.426563  0.237625  0.639073 -0.098954  0.587958  \n2 -0.448081  0.471061  0.212841  0.721930  0.067219  0.642024  \n3 -0.426664  0.325082  0.253101  0.321117  0.064124  0.720249  \n4 -0.178327  0.591610  0.041477  0.770275  0.053063  0.560986  \n\n[5 rows x 64 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embed_0</th>\n      <th>embed_1</th>\n      <th>embed_2</th>\n      <th>embed_3</th>\n      <th>embed_4</th>\n      <th>embed_5</th>\n      <th>embed_6</th>\n      <th>embed_7</th>\n      <th>embed_8</th>\n      <th>embed_9</th>\n      <th>...</th>\n      <th>embed_54</th>\n      <th>embed_55</th>\n      <th>embed_56</th>\n      <th>embed_57</th>\n      <th>embed_58</th>\n      <th>embed_59</th>\n      <th>embed_60</th>\n      <th>embed_61</th>\n      <th>embed_62</th>\n      <th>embed_63</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.310413</td>\n      <td>0.606933</td>\n      <td>0.216994</td>\n      <td>0.209848</td>\n      <td>-0.005488</td>\n      <td>-0.271681</td>\n      <td>-0.333853</td>\n      <td>-0.330938</td>\n      <td>0.481963</td>\n      <td>-0.687171</td>\n      <td>...</td>\n      <td>0.192107</td>\n      <td>-0.535439</td>\n      <td>0.373295</td>\n      <td>-0.330445</td>\n      <td>-0.463618</td>\n      <td>0.424192</td>\n      <td>0.361674</td>\n      <td>0.424921</td>\n      <td>0.164630</td>\n      <td>0.737256</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.282402</td>\n      <td>0.776553</td>\n      <td>0.296450</td>\n      <td>0.394691</td>\n      <td>0.046037</td>\n      <td>-0.187800</td>\n      <td>-0.300264</td>\n      <td>-0.263211</td>\n      <td>0.335799</td>\n      <td>-0.959045</td>\n      <td>...</td>\n      <td>0.135620</td>\n      <td>-0.380019</td>\n      <td>0.334632</td>\n      <td>-0.384081</td>\n      <td>-0.555736</td>\n      <td>0.426563</td>\n      <td>0.237625</td>\n      <td>0.639073</td>\n      <td>-0.098954</td>\n      <td>0.587958</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.232624</td>\n      <td>0.700284</td>\n      <td>0.260850</td>\n      <td>0.293666</td>\n      <td>-0.051036</td>\n      <td>-0.153891</td>\n      <td>-0.266284</td>\n      <td>-0.240626</td>\n      <td>0.408849</td>\n      <td>-0.953547</td>\n      <td>...</td>\n      <td>0.241028</td>\n      <td>-0.360370</td>\n      <td>0.366388</td>\n      <td>-0.284664</td>\n      <td>-0.448081</td>\n      <td>0.471061</td>\n      <td>0.212841</td>\n      <td>0.721930</td>\n      <td>0.067219</td>\n      <td>0.642024</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.261392</td>\n      <td>0.286974</td>\n      <td>0.145569</td>\n      <td>0.205778</td>\n      <td>-0.128228</td>\n      <td>-0.277861</td>\n      <td>-0.341288</td>\n      <td>-0.291409</td>\n      <td>0.296473</td>\n      <td>-0.753489</td>\n      <td>...</td>\n      <td>0.078866</td>\n      <td>-0.124185</td>\n      <td>0.254482</td>\n      <td>0.005507</td>\n      <td>-0.426664</td>\n      <td>0.325082</td>\n      <td>0.253101</td>\n      <td>0.321117</td>\n      <td>0.064124</td>\n      <td>0.720249</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.248244</td>\n      <td>0.677931</td>\n      <td>0.501866</td>\n      <td>0.329943</td>\n      <td>-0.000823</td>\n      <td>-0.202213</td>\n      <td>-0.535481</td>\n      <td>-0.107309</td>\n      <td>0.520295</td>\n      <td>-0.815006</td>\n      <td>...</td>\n      <td>0.293317</td>\n      <td>-0.477410</td>\n      <td>0.389562</td>\n      <td>-0.311417</td>\n      <td>-0.178327</td>\n      <td>0.591610</td>\n      <td>0.041477</td>\n      <td>0.770275</td>\n      <td>0.053063</td>\n      <td>0.560986</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 64 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Binary classification\nimport numpy as np\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\n\nprint(processed_full_df['label'].unique())\n\nbinary_target = (processed_full_df['label'] != 0).astype(int).values\nunique, counts = np.unique(binary_target, return_counts=True)\nprint(\"Classes and their counts:\")\nfor cls, cnt in zip(unique, counts):\n    print(f\"Class {cls}: {cnt}\")\n\n\n# -------------------------Model Train----------------\nimport tensorflow as tf\nfrom transformer import BasicTransformer\nfrom classification import LastTokenClassificationHead\nfrom sklearn.model_selection import train_test_split\n\n\n\n# input data\nX_embed = embedded_df.values                   # shape: (num_samples, embed_dim)\nX_embed_seq = tf.expand_dims(X_embed, axis=1)  # shape: (batch_size, 1, embed_dim)\n\ninput_layer = Input(shape=(1, X_embed.shape[1]), name=\"record_input\")\n\n# Create transformer\ntransformer = BasicTransformer(\n    n_layers=2,\n    internal_size=128,\n    n_heads=4,\n    verbose=True  # See progress!\n)\n\n\nx = transformer.apply(input_layer, training=True)\n\n\n# Create head\nclassification_head = LastTokenClassificationHead()\n\n# Pool last token\nx = classification_head.apply(x)\n\n#  Add MLP head  \nfor i, layer_size in enumerate([128]):\n    x = Dense(layer_size, activation=\"relu\", name=f\"classification_mlp_{i}_{layer_size}\")(x)\n    x = Dropout(0.1)(x)\n\n#  output layer for binary classification\noutput_layer = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(x)\n\n# Build model  \nmodel = Model(inputs=input_layer, outputs=output_layer)\nmodel.summary()\n\n# Compile model \nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n    jit_compile=True\n)\n\n# split data\n\nX_np = X_embed_seq.numpy() if hasattr(X_embed_seq, 'numpy') else np.array(X_embed_seq)\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_np, binary_target, test_size=0.2, random_state=42, stratify=binary_target\n)\n\n# Define early stopping callback\nearly_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\n# Train the model\nmodel.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=50,\n    batch_size=32,\n    callbacks=[early_stop]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:13:16.126973Z","iopub.execute_input":"2025-07-19T05:13:16.127537Z","iopub.status.idle":"2025-07-19T05:26:25.637568Z","shell.execute_reply.started":"2025-07-19T05:13:16.127507Z","shell.execute_reply":"2025-07-19T05:26:25.636751Z"}},"outputs":[{"name":"stdout","text":"[0 1]\nClasses and their counts:\nClass 0: 93000\nClass 1: 164673\n[BasicTransformer] Applying Encoder Block 1/2\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[BasicTransformer] Applying Encoder Block 2/2\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[BasicTransformer] Final output shape: (None, 1, 64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ record_input (\u001b[38;5;33mInputLayer\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_0_transformer_encoder     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚       \u001b[38;5;34m149,504\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_1_transformer_encoder     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚       \u001b[38;5;34m149,504\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ slice_last (\u001b[38;5;33mLambda\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ classification_mlp_0_128        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m8,320\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mDense\u001b[0m)                         â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ binary_output (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ record_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_0_transformer_encoder     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">149,504</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_1_transformer_encoder     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">149,504</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ slice_last (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ classification_mlp_0_128        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m307,457\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,457</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m307,457\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,457</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.2079[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5ms/step - accuracy: 0.8942 - loss: 0.2079 - val_accuracy: 0.9175 - val_loss: 0.1659\nEpoch 2/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.1711 - val_accuracy: 0.9173 - val_loss: 0.1612\nEpoch 3/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.1624 - val_accuracy: 0.9223 - val_loss: 0.1551\nEpoch 4/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.1569 - val_accuracy: 0.9180 - val_loss: 0.1579\nEpoch 5/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.1552 - val_accuracy: 0.9201 - val_loss: 0.1613\nEpoch 6/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9230 - loss: 0.1531 - val_accuracy: 0.9288 - val_loss: 0.1488\nEpoch 7/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.1506 - val_accuracy: 0.9288 - val_loss: 0.1467\nEpoch 8/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9258 - loss: 0.1480 - val_accuracy: 0.9276 - val_loss: 0.1470\nEpoch 9/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.1501 - val_accuracy: 0.9280 - val_loss: 0.1432\nEpoch 10/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.1485 - val_accuracy: 0.9306 - val_loss: 0.1430\nEpoch 11/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.1478 - val_accuracy: 0.9299 - val_loss: 0.1413\nEpoch 12/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.1461 - val_accuracy: 0.9306 - val_loss: 0.1399\nEpoch 13/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.1451 - val_accuracy: 0.9257 - val_loss: 0.1447\nEpoch 14/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.1450 - val_accuracy: 0.9306 - val_loss: 0.1394\nEpoch 15/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.1445 - val_accuracy: 0.9306 - val_loss: 0.1395\nEpoch 16/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9288 - loss: 0.1439 - val_accuracy: 0.9303 - val_loss: 0.1384\nEpoch 17/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.1400 - val_accuracy: 0.9277 - val_loss: 0.1419\nEpoch 18/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.1406 - val_accuracy: 0.9342 - val_loss: 0.1402\nEpoch 19/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9306 - loss: 0.1407 - val_accuracy: 0.9349 - val_loss: 0.1330\nEpoch 20/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.1386 - val_accuracy: 0.9359 - val_loss: 0.1323\nEpoch 21/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.1398 - val_accuracy: 0.9355 - val_loss: 0.1319\nEpoch 22/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9312 - loss: 0.1378 - val_accuracy: 0.9285 - val_loss: 0.1388\nEpoch 23/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9335 - loss: 0.1355 - val_accuracy: 0.9278 - val_loss: 0.1405\nEpoch 24/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.1373 - val_accuracy: 0.9362 - val_loss: 0.1298\nEpoch 25/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.1350 - val_accuracy: 0.9355 - val_loss: 0.1307\nEpoch 26/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.1355 - val_accuracy: 0.9316 - val_loss: 0.1353\nEpoch 27/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.1351 - val_accuracy: 0.9338 - val_loss: 0.1331\nEpoch 28/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.1370 - val_accuracy: 0.9360 - val_loss: 0.1313\nEpoch 29/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.1346 - val_accuracy: 0.9303 - val_loss: 0.1371\nEpoch 29: early stopping\nRestoring model weights from the end of the best epoch: 24.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a4ab3917a10>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# evaluate the model\nresults = model.evaluate(X_val, y_val)\nprint(f\"Validation loss: {results[0]:.4f}, Validation accuracy: {results[1]:.4f}\")\n\n\nfrom sklearn.metrics import f1_score, confusion_matrix\nimport numpy as np\n\n# Predict probabilities\ny_pred_prob = model.predict(X_val)\ny_pred = (y_pred_prob >= 0.5).astype(int).flatten()\n\n# F1\nf1 = f1_score(y_val, y_pred)\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Confusion matrix\ncm = confusion_matrix(y_val, y_pred, labels=[0, 1])\nprint(\"Confusion Matrix:\\n\", cm)\n\nif cm.shape == (2, 2):\n    tn, fp, fn, tp = cm.ravel()\n    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n    print(f\"Detection Rate (Recall): {detection_rate:.4f}\")\n    print(f\"False Alarm Rate: {false_alarm_rate:.4f}\")\nelse:\n    print(\"Confusion matrix does not contain both classes!\")\n    print(\"Check your labels: y_val:\", np.unique(y_val), \" y_pred:\", np.unique(y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T05:26:43.329069Z","iopub.execute_input":"2025-07-19T05:26:43.330093Z","iopub.status.idle":"2025-07-19T05:26:52.029453Z","shell.execute_reply.started":"2025-07-19T05:26:43.330055Z","shell.execute_reply":"2025-07-19T05:26:52.028784Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1611/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1291\nValidation loss: 0.1298, Validation accuracy: 0.9362\n[EncoderBlock] Input shape: (32, 1, 64)\n[EncoderBlock] Output shape: (32, 1, 64)\n[EncoderBlock] Input shape: (32, 1, 64)\n[EncoderBlock] Output shape: (32, 1, 64)\n\u001b[1m1600/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m1611/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\nF1 Score: 0.9499\nConfusion Matrix:\n [[17094  1506]\n [ 1780 31155]]\nDetection Rate (Recall): 0.9460\nFalse Alarm Rate: 0.0810\n","output_type":"stream"}],"execution_count":8}]}