{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12493033,"sourceType":"datasetVersion","datasetId":7883909}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Tanveer2719/NIDS_Coursework.git\n%cd /kaggle/working/NIDS_Coursework/My_Code\n!ls /kaggle/input\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:54:41.716382Z","iopub.execute_input":"2025-08-27T12:54:41.716643Z","iopub.status.idle":"2025-08-27T12:54:42.794991Z","shell.execute_reply.started":"2025-08-27T12:54:41.716624Z","shell.execute_reply":"2025-08-27T12:54:42.794334Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'NIDS_Coursework'...\nremote: Enumerating objects: 262, done.\u001b[K\nremote: Counting objects: 100% (262/262), done.\u001b[K\nremote: Compressing objects: 100% (171/171), done.\u001b[K\nremote: Total 262 (delta 126), reused 221 (delta 85), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (262/262), 1.13 MiB | 21.81 MiB/s, done.\nResolving deltas: 100% (126/126), done.\n/kaggle/working/NIDS_Coursework/My_Code\nUNSW-NB15_combined.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport tensorflow as tf\n\ndef set_seed(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.keras.utils.set_random_seed(seed)\n    tf.config.experimental.enable_op_determinism()\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:54:42.796477Z","iopub.execute_input":"2025-08-27T12:54:42.796731Z","iopub.status.idle":"2025-08-27T12:54:56.920208Z","shell.execute_reply.started":"2025-08-27T12:54:42.796695Z","shell.execute_reply":"2025-08-27T12:54:56.919640Z"}},"outputs":[{"name":"stderr","text":"2025-08-27 12:54:44.414676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756299284.616094      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756299284.673231      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:55:46.041673Z","iopub.execute_input":"2025-08-27T12:55:46.042301Z","iopub.status.idle":"2025-08-27T12:55:46.048274Z","shell.execute_reply.started":"2025-08-27T12:55:46.042276Z","shell.execute_reply":"2025-08-27T12:55:46.047558Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['UNSW-NB15_combined.csv']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npath = \"/kaggle/input/UNSW-NB15_combined.csv\"\n\ndf = pd.read_csv(path)\n\nprint(df.shape)\ndf = df.drop(columns=['id', 'label'])\nprint(df.shape)\n\nprint(f\"🧾 Unique class labels: {df['attack_cat'].unique()}\")\ndf['label'] = df['attack_cat'].apply(lambda x: 0 if x == 'Normal' else 1)\n\nprint(f'Unique values for label {df[\"label\"].unique()}')\n\ndf = df.drop(columns=[\"attack_cat\"])\nprint(f'new shape{df.shape}')\n\n\n\n# --------------------------- perform preprocessing--------------\n\nfrom preprocess import Preprocess\n\n# separate the features and labels so that the labesl are not encoded\nlabels = df['label']\nfeatures = df.drop(columns=['label'])\n\npp = Preprocess()\nprocessed_features = pp.fit_transform_df_auto(df = features,n_categorical_levels=32, expected_categorical_format='onehot')\n\nprint(processed_features.shape)\n\n# concat the features and the labels\nprocessed_full_df = pd.concat([processed_features, labels], axis=1)\n\n# Filter out categorical one-hot encoded columns\nnumerical_columns = [col for col in processed_full_df \n                     if not (col.startswith(\"proto_\") or \n                             col.startswith(\"service_\") or \n                             col.startswith(\"state_\") or\n                             col == 'label')]\n\ntarget = processed_full_df['label']\nfeatures = processed_full_df.drop(columns=['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:56:00.754676Z","iopub.execute_input":"2025-08-27T12:56:00.754938Z","iopub.status.idle":"2025-08-27T12:56:03.847324Z","shell.execute_reply.started":"2025-08-27T12:56:00.754919Z","shell.execute_reply":"2025-08-27T12:56:03.846701Z"}},"outputs":[{"name":"stdout","text":"(257673, 45)\n(257673, 43)\n🧾 Unique class labels: ['Normal' 'Backdoor' 'Analysis' 'Fuzzers' 'Shellcode' 'Reconnaissance'\n 'Exploits' 'DoS' 'Worms' 'Generic']\nUnique values for label [0 1]\nnew shape(257673, 43)\nEncoding the 32 levels for proto\nEncoding the 13 levels for service\nEncoding the 11 levels for state\n(257673, 95)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nX = features.astype(\"float32\").values  # (257673, 95) as float32\ny = target.astype(\"int32\").values      # (257673,)\n\n\n# reshape for (samples, timesteps, features=1)\nX = np.expand_dims(X, axis=-1)  # (257673, 95, 1)\n\n# Split train, val, test\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp)\n\nprint(f\"X_train: {X_train.shape}\")\nprint(f\"y_train: {y_train.shape}\")\nprint(f\"X_val: {X_val.shape}\")\nprint(f\"y_val: {y_val.shape}\")\nprint(f\"X_test: {X_test.shape}\")\nprint(f\"y_test: {y_test.shape}\")\n\n\n\ninput_shape = (X_train.shape[1], X_train.shape[2])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:56:08.892350Z","iopub.execute_input":"2025-08-27T12:56:08.893301Z","iopub.status.idle":"2025-08-27T12:56:09.345629Z","shell.execute_reply.started":"2025-08-27T12:56:08.893273Z","shell.execute_reply":"2025-08-27T12:56:09.344839Z"}},"outputs":[{"name":"stdout","text":"X_train: (206138, 95, 1)\ny_train: (206138,)\nX_val: (41228, 95, 1)\ny_val: (41228,)\nX_test: (10307, 95, 1)\ny_test: (10307,)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\ndef evaluate_metrics(y_true, y_pred):\n    f1 = f1_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n\n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        numerator = tp * tn - fp * fn\n        denominator = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n        mcc = numerator / (denominator + 1e-10)\n        specificity = tn / (tn + fp + 1e-10)\n        balanced_acc = (recall + specificity) / 2\n    else:\n        mcc = 0\n        balanced_acc = 0\n        specificity = 0\n\n    return {\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'mcc': mcc,\n        'specificity': specificity,\n        'balanced_accuracy': balanced_acc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:56:09.346841Z","iopub.execute_input":"2025-08-27T12:56:09.347055Z","iopub.status.idle":"2025-08-27T12:56:09.352891Z","shell.execute_reply.started":"2025-08-27T12:56:09.347040Z","shell.execute_reply":"2025-08-27T12:56:09.352188Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers, losses, metrics\n\n# LSTM baseline model\nmodel = models.Sequential([\n    layers.LSTM(64, return_sequences=False, input_shape=input_shape),  # LSTM instead of GRU\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=20,\n    batch_size=256,\n    validation_data=(X_val, y_val),\n    verbose=1\n)\n\n# Predictions\ny_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n\n# Evaluate with your custom function\nnormal_results = evaluate_metrics(y_true=y_test, y_pred=y_pred)\nprint(f'Baseline LSTM results: {normal_results}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:56:09.353708Z","iopub.execute_input":"2025-08-27T12:56:09.353925Z","iopub.status.idle":"2025-08-27T12:58:19.014056Z","shell.execute_reply.started":"2025-08-27T12:56:09.353910Z","shell.execute_reply":"2025-08-27T12:58:19.013489Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1756299370.427852      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1756299370.428584      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:56:12.290467: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\nI0000 00:00:1756299374.760361     114 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m799/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6524 - loss: 0.6322","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:56:21.353923: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6529 - loss: 0.6314 - val_accuracy: 0.8452 - val_loss: 0.3885\nEpoch 2/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8667 - loss: 0.3190 - val_accuracy: 0.8876 - val_loss: 0.2582\nEpoch 3/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8844 - loss: 0.2639 - val_accuracy: 0.8860 - val_loss: 0.2611\nEpoch 4/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8895 - loss: 0.2495 - val_accuracy: 0.8870 - val_loss: 0.2543\nEpoch 5/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8910 - loss: 0.2451 - val_accuracy: 0.8931 - val_loss: 0.2295\nEpoch 6/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8950 - loss: 0.2345 - val_accuracy: 0.8993 - val_loss: 0.2224\nEpoch 7/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8966 - loss: 0.2271 - val_accuracy: 0.8912 - val_loss: 0.2353\nEpoch 8/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8966 - loss: 0.2257 - val_accuracy: 0.8802 - val_loss: 0.2792\nEpoch 9/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8974 - loss: 0.2259 - val_accuracy: 0.9013 - val_loss: 0.2160\nEpoch 10/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9003 - loss: 0.2150 - val_accuracy: 0.9003 - val_loss: 0.2231\nEpoch 11/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9005 - loss: 0.2140 - val_accuracy: 0.9013 - val_loss: 0.2114\nEpoch 12/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9010 - loss: 0.2050 - val_accuracy: 0.9011 - val_loss: 0.2011\nEpoch 13/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9038 - loss: 0.1960 - val_accuracy: 0.9051 - val_loss: 0.1926\nEpoch 14/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9069 - loss: 0.1855 - val_accuracy: 0.9106 - val_loss: 0.1775\nEpoch 15/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9098 - loss: 0.1808 - val_accuracy: 0.9129 - val_loss: 0.1745\nEpoch 16/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.1743 - val_accuracy: 0.9125 - val_loss: 0.1682\nEpoch 17/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9123 - loss: 0.1733 - val_accuracy: 0.9153 - val_loss: 0.1664\nEpoch 18/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9134 - loss: 0.1706 - val_accuracy: 0.8902 - val_loss: 0.2303\nEpoch 19/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8949 - loss: 0.2127 - val_accuracy: 0.9072 - val_loss: 0.1986\nEpoch 20/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9101 - loss: 0.1814 - val_accuracy: 0.9160 - val_loss: 0.1710\n\u001b[1m 24/323\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   ","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:58:17.825075: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nBaseline LSTM results: {'f1': 0.9315194835139496, 'precision': 0.9433374844333748, 'recall': 0.9199939274328223, 'mcc': 0.8148487010682461, 'specificity': 0.9021505376343844, 'balanced_accuracy': 0.9110722325336034}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Attack codes","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n@tf.function\ndef fgsm_attack_tf(model, inputs, labels, epsilon=0.05, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    with tf.GradientTape() as tape:\n        tape.watch(inputs)\n        predictions = model(inputs, training=False)\n        loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n        loss = tf.reduce_mean(loss)\n\n    gradients = tape.gradient(loss, inputs)\n    signed_grad = tf.sign(gradients)\n    x_adv = inputs + epsilon * signed_grad\n    x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n    return x_adv\n\n\n@tf.function\ndef pgd_attack_tf(model, inputs, labels, epsilon=0.05, alpha=0.01, num_iter=10, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    x_adv = tf.identity(inputs)\n\n    for _ in tf.range(num_iter):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            predictions = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n            loss = tf.reduce_mean(loss)\n\n        gradients = tape.gradient(loss, x_adv)\n        x_adv = x_adv + alpha * tf.sign(gradients)\n        x_adv = tf.clip_by_value(x_adv, inputs - epsilon, inputs + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n\n\n@tf.function\ndef mi_fgsm_attack(model, inputs, labels, epsilon=0.05, alpha=0.01, steps=40, decay=1.0, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    x_adv = tf.identity(inputs)\n    g = tf.zeros_like(inputs)\n\n    for _ in tf.range(steps):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            logits = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(labels, logits)\n            loss = tf.reduce_mean(loss)\n\n        grad = tape.gradient(loss, x_adv)\n        # Normalize gradient\n        grad_norm = tf.reduce_mean(tf.abs(grad), axis=list(range(1, len(grad.shape))), keepdims=True)\n        grad = grad / (grad_norm + 1e-8)\n\n        g = decay * g + grad\n        x_adv = x_adv + alpha * tf.sign(g)\n        x_adv = tf.clip_by_value(x_adv, inputs - epsilon, inputs + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:58:19.015860Z","iopub.execute_input":"2025-08-27T12:58:19.016476Z","iopub.status.idle":"2025-08-27T12:58:19.028470Z","shell.execute_reply.started":"2025-08-27T12:58:19.016444Z","shell.execute_reply":"2025-08-27T12:58:19.027720Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def evaluate_model(model, X, y,epsilon_list=[0.01, 0.03, 0.05, 0.07]):\n    import tensorflow as tf\n    import numpy as np\n\n    X_clean = X\n    x_clean_tf = tf.convert_to_tensor(X_clean, dtype=tf.float32)\n    y_tf = tf.convert_to_tensor(y, dtype=tf.float32)\n\n    # ---------------- Clean Evaluation ----------------\n    print(\"✅ Clean Evaluation:\")\n    y_pred_clean = (model.predict(x_clean_tf) > 0.5).astype(int).flatten()\n    clean_metrics = evaluate_metrics(y, y_pred_clean)\n    print(f\"  F1: {clean_metrics['f1']:.4f}, Precision: {clean_metrics['precision']:.4f}, Recall: {clean_metrics['recall']:.4f}, MCC: {clean_metrics.get('mcc', 'N/A')}, Specificity: {clean_metrics.get('specificity', 'N/A')}, Balanced Acc: {clean_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- FGSM Evaluation ----------------\n    print(\"\\nFGSM Attack Evaluation\")\n    fgsm_results = []\n    for eps in epsilon_list:\n        x_adv = fgsm_attack_tf(model, x_clean_tf, y_tf, epsilon=eps )\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        fgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- PGD Evaluation ----------------\n    print(\"\\nPGD Attack Evaluation:\")\n    pgd_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        x_adv = pgd_attack_tf(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, num_iter=10)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        pgd_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  PGD ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- MI-FGSM Evaluation ----------------\n    print(\"\\nMI-FGSM Attack Evaluation:\")\n    mifgsm_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        steps = 10   \n        decay = 1.0   \n\n        x_adv = mi_fgsm_attack(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, steps=steps, decay=decay)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        mifgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\" MI-FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    return fgsm_results, pgd_results, mifgsm_results\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:58:19.029233Z","iopub.execute_input":"2025-08-27T12:58:19.029773Z","iopub.status.idle":"2025-08-27T12:58:19.050168Z","shell.execute_reply.started":"2025-08-27T12:58:19.029755Z","shell.execute_reply":"2025-08-27T12:58:19.049356Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(\"Results: \")\nepsilons = [.01,.03,.05,.07]\nfgsm_results, pgd_results, mifgsm_results = evaluate_model(\n    model=model,\n    X=X_test,\n    y=y_test,\n    epsilon_list=epsilons,\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:58:19.051165Z","iopub.execute_input":"2025-08-27T12:58:19.051465Z","iopub.status.idle":"2025-08-27T12:58:59.031447Z","shell.execute_reply.started":"2025-08-27T12:58:19.051436Z","shell.execute_reply":"2025-08-27T12:58:59.030856Z"}},"outputs":[{"name":"stdout","text":"CNN Results: \n✅ Clean Evaluation:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  F1: 0.9315, Precision: 0.9433, Recall: 0.9200, MCC: 0.8148487010682461, Specificity: 0.9021505376343844, Balanced Acc: 0.9110722325336034\n\nFGSM Attack Evaluation\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.01 → F1: 0.8096, Precision: 0.8292, Recall: 0.7910, MCC: 0.49470735975771524, Specificity: 0.7115591397849271, Balanced Acc: 0.7512555073450216\n\u001b[1m 69/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:58:23.312968: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.03 → F1: 0.4563, Precision: 0.6077, Recall: 0.3653, MCC: -0.051551681195194016, Specificity: 0.5825268817204144, Balanced Acc: 0.4738958987317724\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.05 → F1: 0.3298, Precision: 0.4729, Recall: 0.2532, MCC: -0.24953053014296436, Specificity: 0.5002688172042876, Balanced Acc: 0.37674743425874013\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.07 → F1: 0.2853, Precision: 0.3705, Recall: 0.2320, MCC: -0.45669682210371954, Specificity: 0.3021505376344005, Balanced Acc: 0.26706130191269134\n\nPGD Attack Evaluation:\n\u001b[1m 68/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:58:30.282262: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.01 → F1: 0.7876, Precision: 0.8066, Recall: 0.7694, MCC: 0.43590526428415777, Specificity: 0.6733870967741754, Balanced Acc: 0.7213906790990963\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.03 → F1: 0.0897, Precision: 0.1822, Recall: 0.0595, MCC: -0.48873134437779553, Specificity: 0.5268817204300934, Balanced Acc: 0.29319643938614126\n\u001b[1m 68/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:58:38.202035: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.05 → F1: 0.0710, Precision: 0.1393, Recall: 0.0477, MCC: -0.550537994825748, Specificity: 0.4784946236559011, Balanced Acc: 0.2630821380007151\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.07 → F1: 0.0483, Precision: 0.0871, Recall: 0.0334, MCC: -0.6550658945892001, Specificity: 0.3798387096774091, Balanced Acc: 0.2066189145775842\n\nMI-FGSM Attack Evaluation:\n\u001b[1m 68/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:58:46.151039: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.01 → F1: 0.7921, Precision: 0.8115, Recall: 0.7736, MCC: 0.4482339813393614, Specificity: 0.6817204301075086, Balanced Acc: 0.7276827442779839\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.03 → F1: 0.0973, Precision: 0.1952, Recall: 0.0648, MCC: -0.4798426125121016, Specificity: 0.5266129032257922, Balanced Acc: 0.295718778924267\n\u001b[1m 66/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:58:54.135823: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.05 → F1: 0.0698, Precision: 0.1373, Recall: 0.0468, MCC: -0.5512297566776413, Specificity: 0.4795698924731054, Balanced Acc: 0.26316432987098415\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.07 → F1: 0.0491, Precision: 0.0800, Recall: 0.0354, MCC: -0.7302671130658097, Specificity: 0.2801075268817129, Balanced Acc: 0.15774011534612442\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Adversarial Training","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Model\n\nclass PGDAdversarialTrainerCNN(tf.keras.Model):\n    def __init__(self, base_model, epsilon_range=(0.01, 0.1), alpha=0.01, num_iter=7, clip_min=-1.5, clip_max=1.5):\n        super().__init__()\n        self.base_model = base_model\n        self.epsilon_range = epsilon_range\n        self.alpha = alpha\n        self.num_iter = num_iter\n        self.clip_min = clip_min\n        self.clip_max = clip_max\n        self.loss_fn = tf.keras.losses.BinaryCrossentropy()\n        self.metric = tf.keras.metrics.BinaryAccuracy()\n\n    def compile(self, optimizer, **kwargs):\n        super().compile(**kwargs)\n        self.optimizer = optimizer\n\n    def pgd_attack_batch(self, x, y):\n        x_adv = tf.identity(x)\n        y = tf.expand_dims(tf.cast(y, tf.float32), axis=-1)\n        epsilon = tf.random.uniform([], *self.epsilon_range)\n\n        for _ in range(self.num_iter):\n            with tf.GradientTape() as tape:\n                tape.watch(x_adv)\n                preds = self.base_model(x_adv, training=True)\n                loss = self.loss_fn(y, preds)\n\n            grad = tape.gradient(loss, x_adv)\n            x_adv = x_adv + self.alpha * tf.sign(grad)\n            # Project back to epsilon ball around original input\n            x_adv = tf.clip_by_value(x_adv, x - epsilon, x + epsilon)\n            x_adv = tf.clip_by_value(x_adv, self.clip_min, self.clip_max)\n\n        return x_adv\n\n    def train_step(self, data):\n        x, y = data\n        x_adv = self.pgd_attack_batch(x, y)\n\n        # Combine clean and adversarial samples\n        x_combined = tf.concat([x, x_adv], axis=0)\n        y_combined = tf.concat([y, y], axis=0)\n        y_combined = tf.expand_dims(tf.cast(y_combined, tf.float32), axis=-1)\n\n        with tf.GradientTape() as tape:\n            preds = self.base_model(x_combined, training=True)\n            loss = self.loss_fn(y_combined, preds)\n\n        grads = tape.gradient(loss, self.base_model.trainable_variables)\n        self.optimizer.apply_gradients(zip(grads, self.base_model.trainable_variables))\n        self.metric.update_state(y_combined, preds)\n\n        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n\n    def test_step(self, data):\n        x, y = data\n        y = tf.expand_dims(tf.cast(y, tf.float32), axis=-1)\n        preds = self.base_model(x, training=False)\n        loss = self.loss_fn(y, preds)\n        self.metric.update_state(y, preds)\n        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n\n    def call(self, inputs):\n        return self.base_model(inputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:58:59.032273Z","iopub.execute_input":"2025-08-27T12:58:59.032545Z","iopub.status.idle":"2025-08-27T12:58:59.042652Z","shell.execute_reply.started":"2025-08-27T12:58:59.032522Z","shell.execute_reply":"2025-08-27T12:58:59.042075Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Wrap your existing CNN\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(\n    monitor='val_loss',   # monitor validation loss\n    patience=3,           # stop if no improvement for 3 epochs\n    restore_best_weights=True\n)\n\n\nadv_model = PGDAdversarialTrainerCNN(\n    base_model=model,           \n    epsilon_range=(0.01, 0.05),\n    alpha=0.01,\n    num_iter=7,\n    clip_min=-1.5,\n    clip_max=1.5\n)\n\nadv_model.compile(optimizer=tf.keras.optimizers.Adam())\n\n# Train with adversarial training\nadv_model.fit(\n    x=X_train,\n    y=y_train,\n    validation_data=(X_val, y_val),\n    batch_size=256,\n    epochs=20,\n    callbacks=[early_stop] \n\n)\n\nprint(\"Advesarial training Results: \")\nepsilons = [.01,.03,.05,.07]\nfgsm_results, pgd_results, mifgsm_results = evaluate_model(\n    model=adv_model,\n    X=X_test,\n    y=y_test,\n    epsilon_list=epsilons,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:58:59.043347Z","iopub.execute_input":"2025-08-27T12:58:59.043558Z","iopub.status.idle":"2025-08-27T13:04:15.654392Z","shell.execute_reply.started":"2025-08-27T12:58:59.043541Z","shell.execute_reply":"2025-08-27T13:04:15.653760Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:58:59.394901: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m805/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7412 - loss: 0.4932","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:59:40.186812: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7413 - loss: 0.4932 - val_accuracy: 0.8714 - val_loss: 0.2320\nEpoch 2/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.8501 - loss: 0.3417 - val_accuracy: 0.8867 - val_loss: 0.1800\nEpoch 3/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.8736 - loss: 0.3083 - val_accuracy: 0.8878 - val_loss: 0.1378\nEpoch 4/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.8816 - loss: 0.2857 - val_accuracy: 0.8896 - val_loss: 0.1155\nEpoch 5/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.8852 - loss: 0.2755 - val_accuracy: 0.8897 - val_loss: 0.1143\nEpoch 6/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.8820 - loss: 0.3004 - val_accuracy: 0.8799 - val_loss: 0.1504\nEpoch 7/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.8808 - loss: 0.3012 - val_accuracy: 0.7386 - val_loss: 0.3209\nEpoch 8/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.7704 - loss: 0.3949 - val_accuracy: 0.8918 - val_loss: 0.1209\nAdvesarial training Results: \n✅ Clean Evaluation:\n\u001b[1m 24/323\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   ","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:03:36.902981: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  F1: 0.9224, Precision: 0.8573, Recall: 0.9983, MCC: 0.7749505136656071, Specificity: 0.7056451612903036, Balanced Acc: 0.8519876026582078\n\nFGSM Attack Evaluation\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.01 → F1: 0.9217, Precision: 0.8570, Recall: 0.9970, MCC: 0.7723828180180268, Specificity: 0.7053763440860026, Balanced Acc: 0.8511700302485576\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.03 → F1: 0.9204, Precision: 0.8565, Recall: 0.9947, MCC: 0.7680547502574361, Specificity: 0.7048387096774004, Balanced Acc: 0.8497626066984239\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.05 → F1: 0.9169, Precision: 0.8528, Recall: 0.9913, MCC: 0.7564798131224543, Specificity: 0.6970430107526694, Balanced Acc: 0.8441948012621705\n\u001b[1m 70/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:03:43.291042: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.07 → F1: 0.8594, Precision: 0.7854, Recall: 0.9487, MCC: 0.5606275361638698, Specificity: 0.54112903225805, Balanced Acc: 0.7449079198029281\n\nPGD Attack Evaluation:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.01 → F1: 0.9217, Precision: 0.8570, Recall: 0.9970, MCC: 0.7723828180180268, Specificity: 0.7053763440860026, Balanced Acc: 0.8511700302485576\n\u001b[1m 70/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:03:51.107158: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.03 → F1: 0.9204, Precision: 0.8565, Recall: 0.9947, MCC: 0.7680547502574361, Specificity: 0.7048387096774004, Balanced Acc: 0.8497626066984239\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.05 → F1: 0.9099, Precision: 0.8459, Recall: 0.9844, MCC: 0.7335792434025414, Specificity: 0.6825268817204118, Balanced Acc: 0.8334450106188214\n\u001b[1m 70/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:03:58.925020: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.07 → F1: 0.8320, Precision: 0.7526, Recall: 0.9302, MCC: 0.45828674141558534, Specificity: 0.4586021505376221, Balanced Acc: 0.6943838139966082\n\nMI-FGSM Attack Evaluation:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.01 → F1: 0.9217, Precision: 0.8570, Recall: 0.9970, MCC: 0.7723828180180268, Specificity: 0.7053763440860026, Balanced Acc: 0.8511700302485576\n\u001b[1m 68/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:04:06.810296: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.03 → F1: 0.9204, Precision: 0.8565, Recall: 0.9947, MCC: 0.7680547502574361, Specificity: 0.7048387096774004, Balanced Acc: 0.8497626066984239\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.05 → F1: 0.9123, Precision: 0.8483, Recall: 0.9868, MCC: 0.7415937559177095, Specificity: 0.6876344086021321, Balanced Acc: 0.8372132874952364\n\u001b[1m 68/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:04:14.772944: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.07 → F1: 0.8363, Precision: 0.7587, Recall: 0.9315, MCC: 0.47556905990537657, Specificity: 0.47553763440858937, Balanced Acc: 0.7035347197395915\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# generate adversarial values for gan training\n\n# experimental PGD code (GPU-optimized, batched)\ndef pgd_attack_tf_fast(model, x, y, epsilon=0.05, alpha=0.01, num_iter=10, clip_min=-1.5, clip_max=1.5):\n    x = tf.convert_to_tensor(x, dtype=tf.float32)\n    y = tf.reshape(tf.cast(y, tf.float32), (-1, 1))\n    x_orig = tf.identity(x)\n    x_adv = tf.identity(x)\n\n    for _ in range(num_iter):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            logits = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(y, logits)\n            loss = tf.reduce_mean(loss)\n\n        grad = tape.gradient(loss, x_adv)\n        signed_grad = tf.sign(grad)\n        x_adv = x_adv + alpha * signed_grad\n        x_adv = tf.clip_by_value(x_adv, x_orig - epsilon, x_orig + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n\ndef batch_pgd_attack(model, X, y, attack_fn, batch_size=1024, **kwargs):\n    adv_list = []\n    X = tf.convert_to_tensor(X, dtype=tf.float32)\n    y = tf.convert_to_tensor(y, dtype=tf.float32)\n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        y_batch = y[i:i+batch_size]\n        x_adv_batch = attack_fn(model, X_batch, y_batch, **kwargs)\n        adv_list.append(x_adv_batch)\n    return tf.concat(adv_list, axis=0)\n\n# Generate adversarial examples in batches to leverage GPU\nX_adv_train = batch_pgd_attack(model, X_train, y_train, pgd_attack_tf_fast, epsilon=0.05, batch_size=1024)\nprint(f\"X_adv_train shape: {X_adv_train.shape}\")\n\nX_adv_val = batch_pgd_attack(model, X_val, y_val, pgd_attack_tf_fast, epsilon=0.05, batch_size=1024)\nprint(f\"X_adv_val shape: {X_adv_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:04:15.655143Z","iopub.execute_input":"2025-08-27T13:04:15.655396Z","iopub.status.idle":"2025-08-27T13:05:22.176385Z","shell.execute_reply.started":"2025-08-27T13:04:15.655371Z","shell.execute_reply":"2025-08-27T13:05:22.175751Z"}},"outputs":[{"name":"stdout","text":"X_adv_train shape: (206138, 95, 1)\nX_adv_val shape: (41228, 95, 1)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# ------------------------------\n# Generator CNN (1D output)\n# ------------------------------\nclass GeneratorCNN(Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.bn1 = layers.BatchNormalization()\n        self.conv2 = layers.Conv1D(128, 3, padding='same', activation='relu')\n        self.bn2 = layers.BatchNormalization()\n        self.conv3 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.bn3 = layers.BatchNormalization()\n        # final output: 1 channel (same as clean input)\n        self.output_layer = layers.Conv1D(1, 3, padding='same', activation='linear')\n\n    def call(self, x, training=False):\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n        return self.output_layer(x)\n\n\n# ------------------------------\n# Discriminator CNN (1D input)\n# ------------------------------\nclass DiscriminatorCNN(Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.global_pool = layers.GlobalAveragePooling1D()\n        self.dense1 = layers.Dense(64, activation='relu')\n        self.output_layer = layers.Dense(1, activation='sigmoid')\n\n    def call(self, x, training=False):\n        x = self.conv1(x)\n        x = self.global_pool(x)\n        x = self.dense1(x)\n        return self.output_layer(x)\n\n\n# ------------------------------\n# GAN Purifier CNN\n# ------------------------------\nclass GANPurifierCNN(Model):\n    def __init__(self, generator, discriminator, lambda_adv=0.5):\n        super().__init__()\n        self.generator = generator\n        self.discriminator = discriminator\n        self.lambda_adv = lambda_adv\n        self.bce = tf.keras.losses.BinaryCrossentropy()\n        self.l1 = tf.keras.losses.MeanAbsoluteError()\n        self.d_optimizer = tf.keras.optimizers.Adam(1e-4)\n        self.g_optimizer = tf.keras.optimizers.Adam(1e-4)\n\n    def compile(self, **kwargs):\n        super().compile(**kwargs)\n\n    def train_step(self, data):\n        x_clean, x_adv = data\n        with tf.GradientTape(persistent=True) as tape:\n            x_fake = self.generator(x_adv, training=True)\n            real_pred = self.discriminator(x_clean, training=True)\n            fake_pred = self.discriminator(x_fake, training=True)\n\n            # Discriminator loss\n            d_loss = self.bce(tf.ones_like(real_pred), real_pred) + \\\n                     self.bce(tf.zeros_like(fake_pred), fake_pred)\n\n            # Generator loss (reconstruction + adversarial)\n            g_loss = self.l1(x_clean, x_fake) + \\\n                     self.lambda_adv * self.bce(tf.ones_like(fake_pred), fake_pred)\n\n            # Cosine similarity\n            x_clean_flat = tf.reshape(x_clean, (tf.shape(x_clean)[0], -1))\n            x_fake_flat = tf.reshape(x_fake, (tf.shape(x_fake)[0], -1))\n            cos_sim = -tf.reduce_mean(\n                tf.keras.losses.cosine_similarity(x_clean_flat, x_fake_flat)\n            )\n\n        # Compute gradients\n        d_grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n        g_grads = tape.gradient(g_loss, self.generator.trainable_variables)\n\n        # Apply gradients\n        self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))\n        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss,\n                \"reconstruction_loss\": self.l1(x_clean, x_fake),\n                \"cosine_similarity\": cos_sim}\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:05:22.178675Z","iopub.execute_input":"2025-08-27T13:05:22.179220Z","iopub.status.idle":"2025-08-27T13:05:22.190952Z","shell.execute_reply.started":"2025-08-27T13:05:22.179201Z","shell.execute_reply":"2025-08-27T13:05:22.190375Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# ------------------------------\n# Instantiate models\n# ------------------------------\ngenerator = GeneratorCNN()\ndiscriminator = DiscriminatorCNN()\n\n# Build models with dummy input (1 channel)\ndummy_input = tf.zeros((1, 95, 1))\ngenerator(dummy_input)\ndiscriminator(dummy_input)\n\ngan_cnn = GANPurifierCNN(generator, discriminator, lambda_adv=0.5)\ngan_cnn.compile()\n\n# ------------------------------\n# Prepare dataset\n# ------------------------------\nbatch_size = 512\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, X_adv_train))\ntrain_dataset = train_dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\nearly_stop = EarlyStopping(\n    monitor=\"cosine_similarity\",\n    mode=\"max\",              # higher cosine similarity is better\n    patience=10,\n    min_delta=1e-4,\n    restore_best_weights=True,\n    verbose=1\n)\n\n# ------------------------------\n# Train\n# ------------------------------\ngan_cnn.fit(train_dataset, epochs=100, callbacks=[early_stop])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:05:22.191700Z","iopub.execute_input":"2025-08-27T13:05:22.191879Z","iopub.status.idle":"2025-08-27T13:08:43.363344Z","shell.execute_reply.started":"2025-08-27T13:05:22.191866Z","shell.execute_reply":"2025-08-27T13:08:43.362783Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - cosine_similarity: 0.8812 - d_loss: 1.3756 - g_loss: 0.4489 - reconstruction_loss: 0.0991\nEpoch 2/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - cosine_similarity: 0.9840 - d_loss: 1.3821 - g_loss: 0.3787 - reconstruction_loss: 0.0307\nEpoch 3/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - cosine_similarity: 0.9895 - d_loss: 1.3819 - g_loss: 0.3728 - reconstruction_loss: 0.0248\nEpoch 4/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - cosine_similarity: 0.9917 - d_loss: 1.3814 - g_loss: 0.3701 - reconstruction_loss: 0.0221\nEpoch 5/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - cosine_similarity: 0.9928 - d_loss: 1.3805 - g_loss: 0.3689 - reconstruction_loss: 0.0207\nEpoch 6/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9936 - d_loss: 1.3778 - g_loss: 0.3685 - reconstruction_loss: 0.0197\nEpoch 7/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9941 - d_loss: 1.3706 - g_loss: 0.3698 - reconstruction_loss: 0.0192\nEpoch 8/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9944 - d_loss: 1.3577 - g_loss: 0.3729 - reconstruction_loss: 0.0189\nEpoch 9/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9944 - d_loss: 1.3349 - g_loss: 0.3791 - reconstruction_loss: 0.0190\nEpoch 10/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9945 - d_loss: 1.3110 - g_loss: 0.3852 - reconstruction_loss: 0.0187\nEpoch 11/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - cosine_similarity: 0.9944 - d_loss: 1.2764 - g_loss: 0.3954 - reconstruction_loss: 0.0188\nEpoch 12/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9942 - d_loss: 1.2424 - g_loss: 0.4060 - reconstruction_loss: 0.0190\nEpoch 13/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9940 - d_loss: 1.2078 - g_loss: 0.4167 - reconstruction_loss: 0.0190\nEpoch 14/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9940 - d_loss: 1.1795 - g_loss: 0.4263 - reconstruction_loss: 0.0188\nEpoch 15/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9917 - d_loss: 1.1337 - g_loss: 0.4465 - reconstruction_loss: 0.0215\nEpoch 16/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9935 - d_loss: 1.1150 - g_loss: 0.4490 - reconstruction_loss: 0.0195\nEpoch 17/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - cosine_similarity: 0.9934 - d_loss: 1.0822 - g_loss: 0.4622 - reconstruction_loss: 0.0197\nEpoch 18/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - cosine_similarity: 0.9928 - d_loss: 1.0257 - g_loss: 0.4869 - reconstruction_loss: 0.0212\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 8.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b8c96c19950>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Generate purified outputs\nx_purified_val = generator(X_adv_val, training=False)\n\n# Cast to float32 for evaluation\nx_purified_val = tf.cast(x_purified_val, tf.float32)\nX_val_cast = tf.cast(X_val, tf.float32)\n\n# L1 (Mean Absolute Error)\nl1_loss = tf.reduce_mean(tf.abs(X_val_cast - x_purified_val))\n\n# L2 (Mean Squared Error)\nl2_loss = tf.reduce_mean(tf.square(X_val_cast - x_purified_val))\n\n# Normalize along sequence dimension\nX_val_norm = tf.nn.l2_normalize(tf.squeeze(X_val_cast, axis=-1), axis=1)           \nx_purified_norm = tf.nn.l2_normalize(tf.squeeze(x_purified_val, axis=-1), axis=1)  \n\n# Cosine similarity\ncos_sim = tf.reduce_mean(tf.reduce_sum(X_val_norm * x_purified_norm, axis=1))\n\nprint(f\"🧪 Purifier Evaluation Metrics:\")\nprint(f\"✅ Cosine Similarity: {cos_sim:.6f}\")\nprint(f\"   ➤ L1 Loss (MAE): {l1_loss:.6f}\")\nprint(f\"   ➤ L2 Loss (MSE): {l2_loss:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:08:43.364227Z","iopub.execute_input":"2025-08-27T13:08:43.364870Z","iopub.status.idle":"2025-08-27T13:08:44.027734Z","shell.execute_reply.started":"2025-08-27T13:08:43.364850Z","shell.execute_reply":"2025-08-27T13:08:44.027121Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1756300123.499227      36 gpu_utils.cc:68] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n","output_type":"stream"},{"name":"stdout","text":"🧪 Purifier Evaluation Metrics:\n✅ Cosine Similarity: 0.994910\n   ➤ L1 Loss (MAE): 0.016329\n   ➤ L2 Loss (MSE): 0.001034\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## GAN+Adv Training evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, generator, adv_model, X, y, epsilon_list=[0.01, 0.03, 0.05, 0.07]):\n    import tensorflow as tf\n    import numpy as np\n\n    X_clean = X\n    x_clean_tf = tf.convert_to_tensor(X_clean, dtype=tf.float32)\n    y_tf = tf.convert_to_tensor(y, dtype=tf.float32)\n\n    # ----------- Clean Data Evaluation (no adversarial) -----------\n    print(\"✅ Clean Evaluation (GAN purified):\")\n    x_purified_clean = generator(x_clean_tf, training=False)\n    y_pred_clean_prob = adv_model.predict(x_purified_clean)\n    y_pred_clean = (y_pred_clean_prob > 0.5).astype(int).flatten()\n    clean_metrics = evaluate_metrics(y, y_pred_clean)\n    print(f\"Clean → F1: {clean_metrics['f1']:.4f}, Precision: {clean_metrics['precision']:.4f}, Recall: {clean_metrics['recall']:.4f}, MCC: {clean_metrics.get('mcc', 'N/A')}, Specificity: {clean_metrics.get('specificity', 'N/A')}, Balanced Acc: {clean_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ----------- FGSM Attack Evaluation -----------\n    print(\"\\nFGSM Attack Evaluation with GAN Purification\")\n    fgsm_results = []\n    for eps in epsilon_list:\n        x_adv = fgsm_attack_tf(model, x_clean_tf, y_tf, epsilon=eps )\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified)\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        fgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ----------- PGD Attack Evaluation -----------\n    print(\"\\nPGD Attack Evaluation with GAN Purification:\")\n    pgd_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        x_adv = pgd_attack_tf(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, num_iter=10)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified )\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        pgd_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  PGD ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n      # ----------- MI-FGSM Attack Evaluation -----------\n    print(\"\\nMI-FGSM Attack Evaluation with GAN Purification:\")\n    mifgsm_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        steps = 10\n        decay = 1.0\n\n        x_adv = mi_fgsm_attack(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, steps=steps, decay=decay)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified )\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        mifgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  MI-FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    return fgsm_results, pgd_results, mifgsm_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:08:44.028536Z","iopub.execute_input":"2025-08-27T13:08:44.029022Z","iopub.status.idle":"2025-08-27T13:08:44.039308Z","shell.execute_reply.started":"2025-08-27T13:08:44.028993Z","shell.execute_reply":"2025-08-27T13:08:44.038594Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"fgsm_full, pgd_full, mi_full = evaluate_model(model= model,generator=generator,adv_model= model, X = X_test, y = y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:08:44.040008Z","iopub.execute_input":"2025-08-27T13:08:44.040329Z","iopub.status.idle":"2025-08-27T13:09:11.756640Z","shell.execute_reply.started":"2025-08-27T13:08:44.040305Z","shell.execute_reply":"2025-08-27T13:09:11.755986Z"}},"outputs":[{"name":"stdout","text":"✅ Clean Evaluation (GAN purified):\n\u001b[1m 67/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:08:44.246461: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nClean → F1: 0.9204, Precision: 0.8542, Recall: 0.9977, MCC: 0.7685060772148689, Specificity: 0.6983870967741748, Balanced Acc: 0.8480549420412546\n\nFGSM Attack Evaluation with GAN Purification\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.01 → F1: 0.9200, Precision: 0.8540, Recall: 0.9971, MCC: 0.7672482569044973, Specificity: 0.6981182795698737, Balanced Acc: 0.8476169050802154\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.03 → F1: 0.9195, Precision: 0.8535, Recall: 0.9967, MCC: 0.7656555797237455, Specificity: 0.6970430107526694, Balanced Acc: 0.8468515494024467\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.05 → F1: 0.9167, Precision: 0.8505, Recall: 0.9941, MCC: 0.7563556514554237, Specificity: 0.6905913978494438, Balanced Acc: 0.8423353224255569\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.07 → F1: 0.9116, Precision: 0.8478, Recall: 0.9857, MCC: 0.7389686732915264, Specificity: 0.6865591397849278, Balanced Acc: 0.8361443034585789\n\nPGD Attack Evaluation with GAN Purification:\n\u001b[1m 70/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:08:51.783087: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.01 → F1: 0.9200, Precision: 0.8540, Recall: 0.9971, MCC: 0.7672482569044973, Specificity: 0.6981182795698737, Balanced Acc: 0.8476169050802154\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.03 → F1: 0.9194, Precision: 0.8534, Recall: 0.9965, MCC: 0.7651913194854297, Specificity: 0.6967741935483683, Balanced Acc: 0.846641233710574\n\u001b[1m 69/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:08:57.205422: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.05 → F1: 0.9159, Precision: 0.8496, Recall: 0.9933, MCC: 0.753629550335994, Specificity: 0.6887096774193363, Balanced Acc: 0.8410149267618923\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.07 → F1: 0.9088, Precision: 0.8430, Recall: 0.9857, MCC: 0.7301857556599881, Specificity: 0.6749999999999818, Balanced Acc: 0.830364733566106\n\nMI-FGSM Attack Evaluation with GAN Purification:\n\u001b[1m 67/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:09:02.667864: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.01 → F1: 0.9200, Precision: 0.8540, Recall: 0.9971, MCC: 0.7672482569044973, Specificity: 0.6981182795698737, Balanced Acc: 0.8476169050802154\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.03 → F1: 0.9195, Precision: 0.8537, Recall: 0.9964, MCC: 0.765527814692588, Specificity: 0.6975806451612716, Balanced Acc: 0.8469685524273034\n\u001b[1m 67/323\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 13:09:08.122753: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.05 → F1: 0.9165, Precision: 0.8500, Recall: 0.9944, MCC: 0.7558782604362322, Specificity: 0.6892473118279384, Balanced Acc: 0.8418150935942486\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.07 → F1: 0.9103, Precision: 0.8461, Recall: 0.9850, MCC: 0.734816532854913, Specificity: 0.6827956989247128, Balanced Acc: 0.8338830475798606\n","output_type":"stream"}],"execution_count":21}]}