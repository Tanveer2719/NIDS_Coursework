{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12493033,"sourceType":"datasetVersion","datasetId":7883909}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Tanveer2719/NIDS_Coursework.git\n%cd /kaggle/working/NIDS_Coursework/My_Code\n!ls /kaggle/input\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:22:38.773395Z","iopub.execute_input":"2025-08-27T12:22:38.773588Z","iopub.status.idle":"2025-08-27T12:22:39.825182Z","shell.execute_reply.started":"2025-08-27T12:22:38.773570Z","shell.execute_reply":"2025-08-27T12:22:39.824151Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'NIDS_Coursework'...\nremote: Enumerating objects: 262, done.\u001b[K\nremote: Counting objects: 100% (262/262), done.\u001b[K\nremote: Compressing objects: 100% (171/171), done.\u001b[K\nremote: Total 262 (delta 126), reused 221 (delta 85), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (262/262), 1.13 MiB | 9.55 MiB/s, done.\nResolving deltas: 100% (126/126), done.\n/kaggle/working/NIDS_Coursework/My_Code\nunsw-nb-15\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport tensorflow as tf\n\ndef set_seed(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.keras.utils.set_random_seed(seed)\n    tf.config.experimental.enable_op_determinism()\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:22:39.827326Z","iopub.execute_input":"2025-08-27T12:22:39.827554Z","iopub.status.idle":"2025-08-27T12:22:54.702441Z","shell.execute_reply.started":"2025-08-27T12:22:39.827532Z","shell.execute_reply":"2025-08-27T12:22:54.701572Z"}},"outputs":[{"name":"stderr","text":"2025-08-27 12:22:41.337903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756297361.531833      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756297361.593331      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npath = \"/kaggle/input/unsw-nb-15/UNSW-NB15_combined.csv\"\n\ndf = pd.read_csv(path)\n\nprint(df.shape)\ndf = df.drop(columns=['id', 'label'])\nprint(df.shape)\n\nprint(f\"🧾 Unique class labels: {df['attack_cat'].unique()}\")\ndf['label'] = df['attack_cat'].apply(lambda x: 0 if x == 'Normal' else 1)\n\nprint(f'Unique values for label {df[\"label\"].unique()}')\n\ndf = df.drop(columns=[\"attack_cat\"])\nprint(f'new shape{df.shape}')\n\n\n\n# --------------------------- perform preprocessing--------------\n\nfrom preprocess import Preprocess\n\n# separate the features and labels so that the labesl are not encoded\nlabels = df['label']\nfeatures = df.drop(columns=['label'])\n\npp = Preprocess()\nprocessed_features = pp.fit_transform_df_auto(df = features,n_categorical_levels=32, expected_categorical_format='onehot')\n\nprint(processed_features.shape)\n\n# concat the features and the labels\nprocessed_full_df = pd.concat([processed_features, labels], axis=1)\n\n# Filter out categorical one-hot encoded columns\nnumerical_columns = [col for col in processed_full_df \n                     if not (col.startswith(\"proto_\") or \n                             col.startswith(\"service_\") or \n                             col.startswith(\"state_\") or\n                             col == 'label')]\n\ntarget = processed_full_df['label']\nfeatures = processed_full_df.drop(columns=['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:22:54.703388Z","iopub.execute_input":"2025-08-27T12:22:54.703952Z","iopub.status.idle":"2025-08-27T12:22:58.046040Z","shell.execute_reply.started":"2025-08-27T12:22:54.703924Z","shell.execute_reply":"2025-08-27T12:22:58.045145Z"}},"outputs":[{"name":"stdout","text":"(257673, 45)\n(257673, 43)\n🧾 Unique class labels: ['Normal' 'Backdoor' 'Analysis' 'Fuzzers' 'Shellcode' 'Reconnaissance'\n 'Exploits' 'DoS' 'Worms' 'Generic']\nUnique values for label [0 1]\nnew shape(257673, 43)\nEncoding the 32 levels for proto\nEncoding the 13 levels for service\nEncoding the 11 levels for state\n(257673, 95)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nX = features.astype(\"float32\").values  # (257673, 95) as float32\ny = target.astype(\"int32\").values      # (257673,)\n\n\n# reshape for (samples, timesteps, features=1)\nX = np.expand_dims(X, axis=-1)  # (257673, 95, 1)\n\n# Split train, val, test\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp)\n\nprint(f\"X_train: {X_train.shape}\")\nprint(f\"y_train: {y_train.shape}\")\nprint(f\"X_val: {X_val.shape}\")\nprint(f\"y_val: {y_val.shape}\")\nprint(f\"X_test: {X_test.shape}\")\nprint(f\"y_test: {y_test.shape}\")\n\n\n\ninput_shape = (X_train.shape[1], X_train.shape[2])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:22:58.046916Z","iopub.execute_input":"2025-08-27T12:22:58.047125Z","iopub.status.idle":"2025-08-27T12:22:58.544032Z","shell.execute_reply.started":"2025-08-27T12:22:58.047108Z","shell.execute_reply":"2025-08-27T12:22:58.543067Z"}},"outputs":[{"name":"stdout","text":"X_train: (206138, 95, 1)\ny_train: (206138,)\nX_val: (41228, 95, 1)\ny_val: (41228,)\nX_test: (10307, 95, 1)\ny_test: (10307,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\ndef evaluate_metrics(y_true, y_pred):\n    f1 = f1_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n\n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        numerator = tp * tn - fp * fn\n        denominator = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n        mcc = numerator / (denominator + 1e-10)\n        specificity = tn / (tn + fp + 1e-10)\n        balanced_acc = (recall + specificity) / 2\n    else:\n        mcc = 0\n        balanced_acc = 0\n        specificity = 0\n\n    return {\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'mcc': mcc,\n        'specificity': specificity,\n        'balanced_accuracy': balanced_acc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:22:58.545310Z","iopub.execute_input":"2025-08-27T12:22:58.545637Z","iopub.status.idle":"2025-08-27T12:22:58.552540Z","shell.execute_reply.started":"2025-08-27T12:22:58.545595Z","shell.execute_reply":"2025-08-27T12:22:58.551576Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers, losses, metrics\n\n\nmodel = models.Sequential([\n    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n    layers.MaxPooling1D(pool_size=2),\n    layers.Conv1D(64, kernel_size=3, activation='relu'),\n    layers.GlobalMaxPooling1D(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n    \n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    \nmodel.fit(\n    X_train, y_train,\n    epochs=20,\n    batch_size=256,\n    validation_data=(X_val, y_val),\n    verbose=1\n)\n\ny_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n\nnormal_results = evaluate_metrics(y_true = y_test, y_pred = y_pred)\nprint(f'normal results: {normal_results}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:22:58.553407Z","iopub.execute_input":"2025-08-27T12:22:58.553625Z","iopub.status.idle":"2025-08-27T12:24:48.976747Z","shell.execute_reply.started":"2025-08-27T12:22:58.553609Z","shell.execute_reply":"2025-08-27T12:24:48.976041Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nI0000 00:00:1756297379.504588      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1756297379.505389      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:23:01.287071: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\nI0000 00:00:1756297383.546452     110 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8010 - loss: 0.3878","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:23:10.207740: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8011 - loss: 0.3877 - val_accuracy: 0.9039 - val_loss: 0.1905\nEpoch 2/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9098 - loss: 0.1854 - val_accuracy: 0.9173 - val_loss: 0.1679\nEpoch 3/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.1701 - val_accuracy: 0.9231 - val_loss: 0.1600\nEpoch 4/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.1646 - val_accuracy: 0.9251 - val_loss: 0.1564\nEpoch 5/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9225 - loss: 0.1608 - val_accuracy: 0.9270 - val_loss: 0.1536\nEpoch 6/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9239 - loss: 0.1579 - val_accuracy: 0.9279 - val_loss: 0.1513\nEpoch 7/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.1555 - val_accuracy: 0.9281 - val_loss: 0.1497\nEpoch 8/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.1534 - val_accuracy: 0.9287 - val_loss: 0.1480\nEpoch 9/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 0.1520 - val_accuracy: 0.9296 - val_loss: 0.1467\nEpoch 10/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.1507 - val_accuracy: 0.9304 - val_loss: 0.1457\nEpoch 11/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9278 - loss: 0.1494 - val_accuracy: 0.9309 - val_loss: 0.1447\nEpoch 12/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9282 - loss: 0.1487 - val_accuracy: 0.9316 - val_loss: 0.1437\nEpoch 13/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9285 - loss: 0.1479 - val_accuracy: 0.9317 - val_loss: 0.1429\nEpoch 14/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9289 - loss: 0.1471 - val_accuracy: 0.9313 - val_loss: 0.1430\nEpoch 15/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9295 - loss: 0.1463 - val_accuracy: 0.9317 - val_loss: 0.1420\nEpoch 16/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.1458 - val_accuracy: 0.9324 - val_loss: 0.1414\nEpoch 17/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.1453 - val_accuracy: 0.9320 - val_loss: 0.1412\nEpoch 18/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.1450 - val_accuracy: 0.9317 - val_loss: 0.1411\nEpoch 19/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9301 - loss: 0.1444 - val_accuracy: 0.9319 - val_loss: 0.1409\nEpoch 20/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9301 - loss: 0.1438 - val_accuracy: 0.9328 - val_loss: 0.1404\n\u001b[1m 31/323\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   ","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:24:47.983636: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nnormal results: {'f1': 0.9481302774427021, 'precision': 0.9417403025310769, 'recall': 0.9546075603461364, 'mcc': 0.85469167173334, 'specificity': 0.8954301075268576, 'balanced_accuracy': 0.925018833936497}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Attack codes","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n@tf.function\ndef fgsm_attack_tf(model, inputs, labels, epsilon=0.05, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    with tf.GradientTape() as tape:\n        tape.watch(inputs)\n        predictions = model(inputs, training=False)\n        loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n        loss = tf.reduce_mean(loss)\n\n    gradients = tape.gradient(loss, inputs)\n    signed_grad = tf.sign(gradients)\n    x_adv = inputs + epsilon * signed_grad\n    x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n    return x_adv\n\n\n@tf.function\ndef pgd_attack_tf(model, inputs, labels, epsilon=0.05, alpha=0.01, num_iter=10, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    x_adv = tf.identity(inputs)\n\n    for _ in tf.range(num_iter):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            predictions = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n            loss = tf.reduce_mean(loss)\n\n        gradients = tape.gradient(loss, x_adv)\n        x_adv = x_adv + alpha * tf.sign(gradients)\n        x_adv = tf.clip_by_value(x_adv, inputs - epsilon, inputs + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n\n\n@tf.function\ndef mi_fgsm_attack(model, inputs, labels, epsilon=0.05, alpha=0.01, steps=40, decay=1.0, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    x_adv = tf.identity(inputs)\n    g = tf.zeros_like(inputs)\n\n    for _ in tf.range(steps):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            logits = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(labels, logits)\n            loss = tf.reduce_mean(loss)\n\n        grad = tape.gradient(loss, x_adv)\n        # Normalize gradient\n        grad_norm = tf.reduce_mean(tf.abs(grad), axis=list(range(1, len(grad.shape))), keepdims=True)\n        grad = grad / (grad_norm + 1e-8)\n\n        g = decay * g + grad\n        x_adv = x_adv + alpha * tf.sign(g)\n        x_adv = tf.clip_by_value(x_adv, inputs - epsilon, inputs + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:24:48.979064Z","iopub.execute_input":"2025-08-27T12:24:48.979325Z","iopub.status.idle":"2025-08-27T12:24:48.992227Z","shell.execute_reply.started":"2025-08-27T12:24:48.979300Z","shell.execute_reply":"2025-08-27T12:24:48.991242Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def evaluate_model(model, X, y,epsilon_list=[0.01, 0.03, 0.05, 0.07]):\n    import tensorflow as tf\n    import numpy as np\n\n    X_clean = X\n    x_clean_tf = tf.convert_to_tensor(X_clean, dtype=tf.float32)\n    y_tf = tf.convert_to_tensor(y, dtype=tf.float32)\n\n    # ---------------- Clean Evaluation ----------------\n    print(\"✅ Clean Evaluation:\")\n    y_pred_clean = (model.predict(x_clean_tf) > 0.5).astype(int).flatten()\n    clean_metrics = evaluate_metrics(y, y_pred_clean)\n    print(f\"  F1: {clean_metrics['f1']:.4f}, Precision: {clean_metrics['precision']:.4f}, Recall: {clean_metrics['recall']:.4f}, MCC: {clean_metrics.get('mcc', 'N/A')}, Specificity: {clean_metrics.get('specificity', 'N/A')}, Balanced Acc: {clean_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- FGSM Evaluation ----------------\n    print(\"\\nFGSM Attack Evaluation\")\n    fgsm_results = []\n    for eps in epsilon_list:\n        x_adv = fgsm_attack_tf(model, x_clean_tf, y_tf, epsilon=eps )\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        fgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- PGD Evaluation ----------------\n    print(\"\\nPGD Attack Evaluation:\")\n    pgd_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        x_adv = pgd_attack_tf(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, num_iter=10)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        pgd_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  PGD ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- MI-FGSM Evaluation ----------------\n    print(\"\\nMI-FGSM Attack Evaluation:\")\n    mifgsm_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        steps = 10   \n        decay = 1.0   \n\n        x_adv = mi_fgsm_attack(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, steps=steps, decay=decay)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        mifgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\" MI-FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    return fgsm_results, pgd_results, mifgsm_results\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:24:48.993065Z","iopub.execute_input":"2025-08-27T12:24:48.993427Z","iopub.status.idle":"2025-08-27T12:24:49.012711Z","shell.execute_reply.started":"2025-08-27T12:24:48.993404Z","shell.execute_reply":"2025-08-27T12:24:49.011752Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(\"CNN Results: \")\nepsilons = [.01,.03,.05,.07]\nfgsm_results, pgd_results, mifgsm_results = evaluate_model(\n    model=model,\n    X=X_test,\n    y=y_test,\n    epsilon_list=epsilons,\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:24:49.013542Z","iopub.execute_input":"2025-08-27T12:24:49.013804Z","iopub.status.idle":"2025-08-27T12:25:07.255226Z","shell.execute_reply.started":"2025-08-27T12:24:49.013785Z","shell.execute_reply":"2025-08-27T12:25:07.254456Z"}},"outputs":[{"name":"stdout","text":"CNN Results: \n✅ Clean Evaluation:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  F1: 0.9481, Precision: 0.9417, Recall: 0.9546, MCC: 0.85469167173334, Specificity: 0.8954301075268576, Balanced Acc: 0.925018833936497\n\nFGSM Attack Evaluation\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.01 → F1: 0.8528, Precision: 0.8419, Recall: 0.8640, MCC: 0.5828981860283338, Specificity: 0.7126344086021313, Balanced Acc: 0.7883044519099923\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.03 → F1: 0.7007, Precision: 0.7606, Recall: 0.6496, MCC: 0.2773373014676086, Specificity: 0.6379032258064344, Balanced Acc: 0.6437580498244256\n\u001b[1m 92/323\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:24:53.403800: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.05 → F1: 0.5175, Precision: 0.5928, Recall: 0.4592, MCC: -0.09544739197268803, Specificity: 0.4413978494623537, Balanced Acc: 0.4503178711407715\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.07 → F1: 0.2628, Precision: 0.3220, Recall: 0.2220, MCC: -0.585983656670822, Specificity: 0.1723118279569846, Balanced Acc: 0.19713207915231953\n\nPGD Attack Evaluation:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.01 → F1: 0.8384, Precision: 0.8368, Recall: 0.8400, MCC: 0.550747204060085, Specificity: 0.7099462365591207, Balanced Acc: 0.7749670457123825\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.03 → F1: 0.5869, Precision: 0.6733, Recall: 0.5201, MCC: 0.0704524379306774, Specificity: 0.553225806451598, Balanced Acc: 0.5366705926139879\n\u001b[1m 89/323\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:24:59.214674: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.05 → F1: 0.0521, Precision: 0.0735, Recall: 0.0404, MCC: -0.8664922277601382, Specificity: 0.0983870967741909, Balanced Acc: 0.06938483425319535\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.07 → F1: 0.0004, Precision: 0.0005, Recall: 0.0003, MCC: -0.9993691119333873, Specificity: 0.00026881720430106806, Balanced Acc: 0.0002862227815948941\n\nMI-FGSM Attack Evaluation:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.01 → F1: 0.8386, Precision: 0.8364, Recall: 0.8407, MCC: 0.5507274270901635, Specificity: 0.7088709677419164, Balanced Acc: 0.7748089467523913\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.03 → F1: 0.5935, Precision: 0.6786, Recall: 0.5274, MCC: 0.08183761422998286, Specificity: 0.5577956989247161, Balanced Acc: 0.5425990791572115\n\u001b[1m 96/323\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:25:05.111936: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.05 → F1: 0.0658, Precision: 0.0912, Recall: 0.0515, MCC: -0.8565314287937115, Specificity: 0.09220430107526634, Balanced Acc: 0.0718346539534522\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.07 → F1: 0.0006, Precision: 0.0008, Recall: 0.0005, MCC: -0.9991589240215801, Specificity: 0.00026881720430106806, Balanced Acc: 0.00036212987131707414\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Adversarial Training","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Model\n\nclass PGDAdversarialTrainerCNN(tf.keras.Model):\n    def __init__(self, base_model, epsilon_range=(0.01, 0.1), alpha=0.01, num_iter=7, clip_min=-1.5, clip_max=1.5):\n        super().__init__()\n        self.base_model = base_model\n        self.epsilon_range = epsilon_range\n        self.alpha = alpha\n        self.num_iter = num_iter\n        self.clip_min = clip_min\n        self.clip_max = clip_max\n        self.loss_fn = tf.keras.losses.BinaryCrossentropy()\n        self.metric = tf.keras.metrics.BinaryAccuracy()\n\n    def compile(self, optimizer, **kwargs):\n        super().compile(**kwargs)\n        self.optimizer = optimizer\n\n    def pgd_attack_batch(self, x, y):\n        x_adv = tf.identity(x)\n        y = tf.expand_dims(tf.cast(y, tf.float32), axis=-1)\n        epsilon = tf.random.uniform([], *self.epsilon_range)\n\n        for _ in range(self.num_iter):\n            with tf.GradientTape() as tape:\n                tape.watch(x_adv)\n                preds = self.base_model(x_adv, training=True)\n                loss = self.loss_fn(y, preds)\n\n            grad = tape.gradient(loss, x_adv)\n            x_adv = x_adv + self.alpha * tf.sign(grad)\n            # Project back to epsilon ball around original input\n            x_adv = tf.clip_by_value(x_adv, x - epsilon, x + epsilon)\n            x_adv = tf.clip_by_value(x_adv, self.clip_min, self.clip_max)\n\n        return x_adv\n\n    def train_step(self, data):\n        x, y = data\n        x_adv = self.pgd_attack_batch(x, y)\n\n        # Combine clean and adversarial samples\n        x_combined = tf.concat([x, x_adv], axis=0)\n        y_combined = tf.concat([y, y], axis=0)\n        y_combined = tf.expand_dims(tf.cast(y_combined, tf.float32), axis=-1)\n\n        with tf.GradientTape() as tape:\n            preds = self.base_model(x_combined, training=True)\n            loss = self.loss_fn(y_combined, preds)\n\n        grads = tape.gradient(loss, self.base_model.trainable_variables)\n        self.optimizer.apply_gradients(zip(grads, self.base_model.trainable_variables))\n        self.metric.update_state(y_combined, preds)\n\n        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n\n    def test_step(self, data):\n        x, y = data\n        y = tf.expand_dims(tf.cast(y, tf.float32), axis=-1)\n        preds = self.base_model(x, training=False)\n        loss = self.loss_fn(y, preds)\n        self.metric.update_state(y, preds)\n        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n\n    def call(self, inputs):\n        return self.base_model(inputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:25:07.256148Z","iopub.execute_input":"2025-08-27T12:25:07.256491Z","iopub.status.idle":"2025-08-27T12:25:07.269089Z","shell.execute_reply.started":"2025-08-27T12:25:07.256468Z","shell.execute_reply":"2025-08-27T12:25:07.268207Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Wrap your existing CNN\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(\n    monitor='val_loss',   # monitor validation loss\n    patience=3,           # stop if no improvement for 3 epochs\n    restore_best_weights=True\n)\n\n\nadv_model = PGDAdversarialTrainerCNN(\n    base_model=model,           \n    epsilon_range=(0.01, 0.05),\n    alpha=0.01,\n    num_iter=7,\n    clip_min=-1.5,\n    clip_max=1.5\n)\n\nadv_model.compile(optimizer=tf.keras.optimizers.Adam())\n\n# Train with adversarial training\nadv_model.fit(\n    x=X_train,\n    y=y_train,\n    validation_data=(X_val, y_val),\n    batch_size=256,\n    epochs=20,\n    callbacks=[early_stop] \n\n)\n\nprint(\"Advesarial training Results: \")\nepsilons = [.01,.03,.05,.07]\nfgsm_results, pgd_results, mifgsm_results = evaluate_model(\n    model=adv_model,\n    X=X_test,\n    y=y_test,\n    epsilon_list=epsilons,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:25:07.270141Z","iopub.execute_input":"2025-08-27T12:25:07.270512Z","iopub.status.idle":"2025-08-27T12:26:42.915878Z","shell.execute_reply.started":"2025-08-27T12:25:07.270493Z","shell.execute_reply":"2025-08-27T12:26:42.915155Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m804/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8360 - loss: 0.2931","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:25:28.829164: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.8361 - loss: 0.2928 - val_accuracy: 0.9193 - val_loss: 0.0540\nEpoch 2/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8796 - loss: 0.2122 - val_accuracy: 0.9224 - val_loss: 0.0509\nEpoch 3/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8883 - loss: 0.1971 - val_accuracy: 0.9220 - val_loss: 0.0518\nEpoch 4/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8947 - loss: 0.1882 - val_accuracy: 0.9235 - val_loss: 0.0537\nEpoch 5/20\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8983 - loss: 0.1837 - val_accuracy: 0.9218 - val_loss: 0.0515\nAdvesarial training Results: \n✅ Clean Evaluation:\n\u001b[1m 31/323\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   ","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:26:25.925145: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  F1: 0.9371, Precision: 0.9640, Recall: 0.9116, MCC: 0.8362401430493449, Specificity: 0.9397849462365339, Balanced Acc: 0.9257145468999581\n\nFGSM Attack Evaluation\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.01 → F1: 0.9194, Precision: 0.9395, Recall: 0.9001, MCC: 0.7860307926669831, Specificity: 0.8973118279569651, Balanced Acc: 0.8987090489412881\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.03 → F1: 0.9031, Precision: 0.9177, Recall: 0.8890, MCC: 0.7396670913413304, Specificity: 0.8588709677419124, Balanced Acc: 0.8739474012840426\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.05 → F1: 0.8872, Precision: 0.8991, Recall: 0.8757, MCC: 0.695194698042402, Specificity: 0.8260752688171821, Balanced Acc: 0.8508697279261256\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.07 → F1: 0.8674, Precision: 0.8822, Recall: 0.8530, MCC: 0.6438878405360369, Specificity: 0.7983870967741721, Balanced Acc: 0.8257154855360158\n\nPGD Attack Evaluation:\n\u001b[1m 97/323\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:26:31.767631: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.01 → F1: 0.9178, Precision: 0.9375, Recall: 0.8989, MCC: 0.7815686748279156, Specificity: 0.8938172043010513, Balanced Acc: 0.8963544803955537\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.03 → F1: 0.8946, Precision: 0.9087, Recall: 0.8810, MCC: 0.716465490097438, Specificity: 0.8432795698924505, Balanced Acc: 0.862128626604036\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.05 → F1: 0.8520, Precision: 0.8582, Recall: 0.8459, MCC: 0.5951707176720954, Specificity: 0.7524193548386895, Balanced Acc: 0.799163981351332\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.07 → F1: 0.7325, Precision: 0.7723, Recall: 0.6967, MCC: 0.3236355423211975, Specificity: 0.636290322580628, Balanced Acc: 0.6664827960253983\n\nMI-FGSM Attack Evaluation:\n\u001b[1m 94/323\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:26:37.798718: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.01 → F1: 0.9174, Precision: 0.9373, Recall: 0.8983, MCC: 0.7805970611700731, Specificity: 0.8935483870967501, Balanced Acc: 0.8959164434345144\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.03 → F1: 0.8941, Precision: 0.9084, Recall: 0.8802, MCC: 0.7150772783317139, Specificity: 0.8427419354838483, Balanced Acc: 0.861480273951124\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.05 → F1: 0.8509, Precision: 0.8543, Recall: 0.8476, MCC: 0.5899052191896242, Specificity: 0.7440860215053563, Balanced Acc: 0.7958322926716094\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n MI-FGSM ε=0.07 → F1: 0.7436, Precision: 0.7809, Recall: 0.7097, MCC: 0.3475277305189424, Specificity: 0.6473118279569718, Balanced Acc: 0.6785215584296777\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# generate adversarial values for gan training\n\n# experimental PGD code (GPU-optimized, batched)\ndef pgd_attack_tf_fast(model, x, y, epsilon=0.05, alpha=0.01, num_iter=10, clip_min=-1.5, clip_max=1.5):\n    x = tf.convert_to_tensor(x, dtype=tf.float32)\n    y = tf.reshape(tf.cast(y, tf.float32), (-1, 1))\n    x_orig = tf.identity(x)\n    x_adv = tf.identity(x)\n\n    for _ in range(num_iter):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            logits = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(y, logits)\n            loss = tf.reduce_mean(loss)\n\n        grad = tape.gradient(loss, x_adv)\n        signed_grad = tf.sign(grad)\n        x_adv = x_adv + alpha * signed_grad\n        x_adv = tf.clip_by_value(x_adv, x_orig - epsilon, x_orig + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n\ndef batch_pgd_attack(model, X, y, attack_fn, batch_size=1024, **kwargs):\n    adv_list = []\n    X = tf.convert_to_tensor(X, dtype=tf.float32)\n    y = tf.convert_to_tensor(y, dtype=tf.float32)\n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        y_batch = y[i:i+batch_size]\n        x_adv_batch = attack_fn(model, X_batch, y_batch, **kwargs)\n        adv_list.append(x_adv_batch)\n    return tf.concat(adv_list, axis=0)\n\n# Generate adversarial examples in batches to leverage GPU\nX_adv_train = batch_pgd_attack(model, X_train, y_train, pgd_attack_tf_fast, epsilon=0.05, batch_size=1024)\nprint(f\"X_adv_train shape: {X_adv_train.shape}\")\n\nX_adv_val = batch_pgd_attack(model, X_val, y_val, pgd_attack_tf_fast, epsilon=0.05, batch_size=1024)\nprint(f\"X_adv_val shape: {X_adv_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:26:42.916757Z","iopub.execute_input":"2025-08-27T12:26:42.917049Z","iopub.status.idle":"2025-08-27T12:27:36.940593Z","shell.execute_reply.started":"2025-08-27T12:26:42.917027Z","shell.execute_reply":"2025-08-27T12:27:36.939863Z"}},"outputs":[{"name":"stdout","text":"X_adv_train shape: (206138, 95, 1)\nX_adv_val shape: (41228, 95, 1)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# ------------------------------\n# Generator CNN (1D output)\n# ------------------------------\nclass GeneratorCNN(Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.bn1 = layers.BatchNormalization()\n        self.conv2 = layers.Conv1D(128, 3, padding='same', activation='relu')\n        self.bn2 = layers.BatchNormalization()\n        self.conv3 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.bn3 = layers.BatchNormalization()\n        # final output: 1 channel (same as clean input)\n        self.output_layer = layers.Conv1D(1, 3, padding='same', activation='linear')\n\n    def call(self, x, training=False):\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n        return self.output_layer(x)\n\n\n# ------------------------------\n# Discriminator CNN (1D input)\n# ------------------------------\nclass DiscriminatorCNN(Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.global_pool = layers.GlobalAveragePooling1D()\n        self.dense1 = layers.Dense(64, activation='relu')\n        self.output_layer = layers.Dense(1, activation='sigmoid')\n\n    def call(self, x, training=False):\n        x = self.conv1(x)\n        x = self.global_pool(x)\n        x = self.dense1(x)\n        return self.output_layer(x)\n\n\n# ------------------------------\n# GAN Purifier CNN\n# ------------------------------\nclass GANPurifierCNN(Model):\n    def __init__(self, generator, discriminator, lambda_adv=0.5):\n        super().__init__()\n        self.generator = generator\n        self.discriminator = discriminator\n        self.lambda_adv = lambda_adv\n        self.bce = tf.keras.losses.BinaryCrossentropy()\n        self.l1 = tf.keras.losses.MeanAbsoluteError()\n        self.d_optimizer = tf.keras.optimizers.Adam(1e-4)\n        self.g_optimizer = tf.keras.optimizers.Adam(1e-4)\n\n    def compile(self, **kwargs):\n        super().compile(**kwargs)\n\n    def train_step(self, data):\n        x_clean, x_adv = data\n        with tf.GradientTape(persistent=True) as tape:\n            x_fake = self.generator(x_adv, training=True)\n            real_pred = self.discriminator(x_clean, training=True)\n            fake_pred = self.discriminator(x_fake, training=True)\n\n            # Discriminator loss\n            d_loss = self.bce(tf.ones_like(real_pred), real_pred) + \\\n                     self.bce(tf.zeros_like(fake_pred), fake_pred)\n\n            # Generator loss (reconstruction + adversarial)\n            g_loss = self.l1(x_clean, x_fake) + \\\n                     self.lambda_adv * self.bce(tf.ones_like(fake_pred), fake_pred)\n\n            # Cosine similarity\n            x_clean_flat = tf.reshape(x_clean, (tf.shape(x_clean)[0], -1))\n            x_fake_flat = tf.reshape(x_fake, (tf.shape(x_fake)[0], -1))\n            cos_sim = -tf.reduce_mean(\n                tf.keras.losses.cosine_similarity(x_clean_flat, x_fake_flat)\n            )\n\n        # Compute gradients\n        d_grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n        g_grads = tape.gradient(g_loss, self.generator.trainable_variables)\n\n        # Apply gradients\n        self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))\n        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss,\n                \"reconstruction_loss\": self.l1(x_clean, x_fake),\n                \"cosine_similarity\": cos_sim}\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:37:00.988297Z","iopub.execute_input":"2025-08-27T12:37:00.988617Z","iopub.status.idle":"2025-08-27T12:37:01.004668Z","shell.execute_reply.started":"2025-08-27T12:37:00.988594Z","shell.execute_reply":"2025-08-27T12:37:01.003890Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# ------------------------------\n# Instantiate models\n# ------------------------------\ngenerator = GeneratorCNN()\ndiscriminator = DiscriminatorCNN()\n\n# Build models with dummy input (1 channel)\ndummy_input = tf.zeros((1, 95, 1))\ngenerator(dummy_input)\ndiscriminator(dummy_input)\n\ngan_cnn = GANPurifierCNN(generator, discriminator, lambda_adv=0.5)\ngan_cnn.compile()\n\n# ------------------------------\n# Prepare dataset\n# ------------------------------\nbatch_size = 512\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, X_adv_train))\ntrain_dataset = train_dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\nearly_stop = EarlyStopping(\n    monitor=\"cosine_similarity\",\n    mode=\"max\",              # higher cosine similarity is better\n    patience=10,\n    min_delta=1e-4,\n    restore_best_weights=True,\n    verbose=1\n)\n\n# ------------------------------\n# Train\n# ------------------------------\ngan_cnn.fit(train_dataset, epochs=100, callbacks=[early_stop])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:37:04.861419Z","iopub.execute_input":"2025-08-27T12:37:04.862019Z","iopub.status.idle":"2025-08-27T12:39:33.614658Z","shell.execute_reply.started":"2025-08-27T12:37:04.861997Z","shell.execute_reply":"2025-08-27T12:39:33.613935Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - cosine_similarity: 0.8775 - d_loss: 1.3781 - g_loss: 0.4535 - reconstruction_loss: 0.1047\nEpoch 2/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - cosine_similarity: 0.9831 - d_loss: 1.3806 - g_loss: 0.3840 - reconstruction_loss: 0.0358\nEpoch 3/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - cosine_similarity: 0.9889 - d_loss: 1.3795 - g_loss: 0.3767 - reconstruction_loss: 0.0283\nEpoch 4/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9913 - d_loss: 1.3780 - g_loss: 0.3736 - reconstruction_loss: 0.0248\nEpoch 5/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - cosine_similarity: 0.9924 - d_loss: 1.3734 - g_loss: 0.3732 - reconstruction_loss: 0.0233\nEpoch 6/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - cosine_similarity: 0.9932 - d_loss: 1.3640 - g_loss: 0.3742 - reconstruction_loss: 0.0218\nEpoch 7/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9938 - d_loss: 1.3469 - g_loss: 0.3777 - reconstruction_loss: 0.0208\nEpoch 8/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9939 - d_loss: 1.3163 - g_loss: 0.3862 - reconstruction_loss: 0.0209\nEpoch 9/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9941 - d_loss: 1.2899 - g_loss: 0.3927 - reconstruction_loss: 0.0199\nEpoch 10/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9940 - d_loss: 1.2539 - g_loss: 0.4036 - reconstruction_loss: 0.0200\nEpoch 11/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9939 - d_loss: 1.2255 - g_loss: 0.4121 - reconstruction_loss: 0.0198\nEpoch 12/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - cosine_similarity: 0.9937 - d_loss: 1.1905 - g_loss: 0.4240 - reconstruction_loss: 0.0202\nEpoch 13/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9935 - d_loss: 1.1618 - g_loss: 0.4343 - reconstruction_loss: 0.0203\nEpoch 14/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9934 - d_loss: 1.1336 - g_loss: 0.4447 - reconstruction_loss: 0.0204\nEpoch 15/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9933 - d_loss: 1.1068 - g_loss: 0.4534 - reconstruction_loss: 0.0204\nEpoch 16/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9895 - d_loss: 1.0609 - g_loss: 0.4802 - reconstruction_loss: 0.0236\nEpoch 17/100\n\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - cosine_similarity: 0.9917 - d_loss: 1.0518 - g_loss: 0.4817 - reconstruction_loss: 0.0235\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 7.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fcf283a3dd0>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Generate purified outputs\nx_purified_val = generator(X_adv_val, training=False)\n\n# Cast to float32 for evaluation\nx_purified_val = tf.cast(x_purified_val, tf.float32)\nX_val_cast = tf.cast(X_val, tf.float32)\n\n# L1 (Mean Absolute Error)\nl1_loss = tf.reduce_mean(tf.abs(X_val_cast - x_purified_val))\n\n# L2 (Mean Squared Error)\nl2_loss = tf.reduce_mean(tf.square(X_val_cast - x_purified_val))\n\n# Normalize along sequence dimension\nX_val_norm = tf.nn.l2_normalize(tf.squeeze(X_val_cast, axis=-1), axis=1)           \nx_purified_norm = tf.nn.l2_normalize(tf.squeeze(x_purified_val, axis=-1), axis=1)  \n\n# Cosine similarity\ncos_sim = tf.reduce_mean(tf.reduce_sum(X_val_norm * x_purified_norm, axis=1))\n\nprint(f\"🧪 Purifier Evaluation Metrics:\")\nprint(f\"✅ Cosine Similarity: {cos_sim:.6f}\")\nprint(f\"   ➤ L1 Loss (MAE): {l1_loss:.6f}\")\nprint(f\"   ➤ L2 Loss (MSE): {l2_loss:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:41:41.416816Z","iopub.execute_input":"2025-08-27T12:41:41.417116Z","iopub.status.idle":"2025-08-27T12:41:41.784304Z","shell.execute_reply.started":"2025-08-27T12:41:41.417093Z","shell.execute_reply":"2025-08-27T12:41:41.783549Z"}},"outputs":[{"name":"stdout","text":"🧪 Purifier Evaluation Metrics:\n✅ Cosine Similarity: 0.994087\n   ➤ L1 Loss (MAE): 0.019915\n   ➤ L2 Loss (MSE): 0.001275\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## GAN+Adv Training evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, generator, adv_model, X, y, epsilon_list=[0.01, 0.03, 0.05, 0.07]):\n    import tensorflow as tf\n    import numpy as np\n\n    X_clean = X\n    x_clean_tf = tf.convert_to_tensor(X_clean, dtype=tf.float32)\n    y_tf = tf.convert_to_tensor(y, dtype=tf.float32)\n\n    # ----------- Clean Data Evaluation (no adversarial) -----------\n    print(\"✅ Clean Evaluation (GAN purified):\")\n    x_purified_clean = generator(x_clean_tf, training=False)\n    y_pred_clean_prob = adv_model.predict(x_purified_clean)\n    y_pred_clean = (y_pred_clean_prob > 0.5).astype(int).flatten()\n    clean_metrics = evaluate_metrics(y, y_pred_clean)\n    print(f\"Clean → F1: {clean_metrics['f1']:.4f}, Precision: {clean_metrics['precision']:.4f}, Recall: {clean_metrics['recall']:.4f}, MCC: {clean_metrics.get('mcc', 'N/A')}, Specificity: {clean_metrics.get('specificity', 'N/A')}, Balanced Acc: {clean_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ----------- FGSM Attack Evaluation -----------\n    print(\"\\nFGSM Attack Evaluation with GAN Purification\")\n    fgsm_results = []\n    for eps in epsilon_list:\n        x_adv = fgsm_attack_tf(model, x_clean_tf, y_tf, epsilon=eps )\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified)\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        fgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ----------- PGD Attack Evaluation -----------\n    print(\"\\nPGD Attack Evaluation with GAN Purification:\")\n    pgd_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        x_adv = pgd_attack_tf(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, num_iter=10)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified )\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        pgd_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  PGD ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n      # ----------- MI-FGSM Attack Evaluation -----------\n    print(\"\\nMI-FGSM Attack Evaluation with GAN Purification:\")\n    mifgsm_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        steps = 10\n        decay = 1.0\n\n        x_adv = mi_fgsm_attack(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, steps=steps, decay=decay)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified )\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        mifgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  MI-FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    return fgsm_results, pgd_results, mifgsm_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:44:57.073095Z","iopub.execute_input":"2025-08-27T12:44:57.073840Z","iopub.status.idle":"2025-08-27T12:44:57.087149Z","shell.execute_reply.started":"2025-08-27T12:44:57.073813Z","shell.execute_reply":"2025-08-27T12:44:57.086027Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"fgsm_full, pgd_full, mi_full = evaluate_model(model= model,generator=generator,adv_model= model, X = X_test, y = y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T12:45:26.552117Z","iopub.execute_input":"2025-08-27T12:45:26.552745Z","iopub.status.idle":"2025-08-27T12:45:40.325770Z","shell.execute_reply.started":"2025-08-27T12:45:26.552720Z","shell.execute_reply":"2025-08-27T12:45:40.325014Z"}},"outputs":[{"name":"stdout","text":"✅ Clean Evaluation (GAN purified):\n\u001b[1m 96/323\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:45:26.730904: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nClean → F1: 0.9298, Precision: 0.9318, Recall: 0.9277, MCC: 0.8062223390551224, Specificity: 0.8798387096773957, Balanced Acc: 0.9037875801309402\n\nFGSM Attack Evaluation with GAN Purification\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.01 → F1: 0.9261, Precision: 0.9262, Recall: 0.9261, MCC: 0.7953748202800953, Specificity: 0.869354838709654, Balanced Acc: 0.8977106666601253\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.03 → F1: 0.9161, Precision: 0.9126, Recall: 0.9197, MCC: 0.76610626082655, Specificity: 0.8440860215053536, Balanced Acc: 0.8818881602896436\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.05 → F1: 0.9018, Precision: 0.9010, Recall: 0.9025, MCC: 0.7274677480030807, Specificity: 0.8244623655913756, Balanced Acc: 0.8634988311940482\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  FGSM ε=0.07 → F1: 0.8946, Precision: 0.8748, Recall: 0.9153, MCC: 0.6972005849821395, Specificity: 0.7680107526881514, Balanced Acc: 0.8416492202790993\n\nPGD Attack Evaluation with GAN Purification:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.01 → F1: 0.9259, Precision: 0.9263, Recall: 0.9255, MCC: 0.7948045427921508, Specificity: 0.8696236559139551, Balanced Acc: 0.8975414469033871\n\u001b[1m 95/323\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:45:32.502222: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.03 → F1: 0.9165, Precision: 0.9175, Recall: 0.9154, MCC: 0.7690695250433675, Specificity: 0.8543010752687942, Balanced Acc: 0.8848702886591429\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.05 → F1: 0.9004, Precision: 0.8965, Recall: 0.9044, MCC: 0.7219142436038858, Specificity: 0.8150537634408382, Balanced Acc: 0.8597054151954457\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  PGD ε=0.07 → F1: 0.8638, Precision: 0.8632, Recall: 0.8643, MCC: 0.6220970351943982, Specificity: 0.7575268817204097, Balanced Acc: 0.8109025026485759\n\nMI-FGSM Attack Evaluation with GAN Purification:\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.01 → F1: 0.9242, Precision: 0.9262, Recall: 0.9223, MCC: 0.7908818063132403, Specificity: 0.8698924731182561, Balanced Acc: 0.8960818066213718\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.03 → F1: 0.9146, Precision: 0.9144, Recall: 0.9148, MCC: 0.7633534660727405, Specificity: 0.8483870967741707, Balanced Acc: 0.8816096710529424\n\u001b[1m 96/323\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 12:45:38.420751: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.05 → F1: 0.8986, Precision: 0.8967, Recall: 0.9004, MCC: 0.7179533782623362, Specificity: 0.8163978494623436, Balanced Acc: 0.8584038738734217\n\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n  MI-FGSM ε=0.07 → F1: 0.8580, Precision: 0.8566, Recall: 0.8594, MCC: 0.6053669760198643, Specificity: 0.7451612903225606, Balanced Acc: 0.8022906800785417\n","output_type":"stream"}],"execution_count":24}]}