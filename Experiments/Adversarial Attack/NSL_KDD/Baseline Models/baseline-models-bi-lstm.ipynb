{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":394223,"sourceType":"datasetVersion","datasetId":174616}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Tanveer2719/NIDS_Coursework.git\n%cd /kaggle/working/NIDS_Coursework/My_Code\n!ls /kaggle/input\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:27:23.667889Z","iopub.execute_input":"2025-08-27T14:27:23.668082Z","iopub.status.idle":"2025-08-27T14:27:24.948196Z","shell.execute_reply.started":"2025-08-27T14:27:23.668065Z","shell.execute_reply":"2025-08-27T14:27:24.947441Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'NIDS_Coursework'...\nremote: Enumerating objects: 262, done.\u001b[K\nremote: Counting objects: 100% (262/262), done.\u001b[K\nremote: Compressing objects: 100% (171/171), done.\u001b[K\nremote: Total 262 (delta 126), reused 221 (delta 85), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (262/262), 1.13 MiB | 9.71 MiB/s, done.\nResolving deltas: 100% (126/126), done.\n/kaggle/working/NIDS_Coursework/My_Code\nnslkdd\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport tensorflow as tf\n\ndef set_seed(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.keras.utils.set_random_seed(seed)\n    tf.config.experimental.enable_op_determinism()\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:27:24.950497Z","iopub.execute_input":"2025-08-27T14:27:24.950820Z","iopub.status.idle":"2025-08-27T14:27:44.376461Z","shell.execute_reply.started":"2025-08-27T14:27:24.950791Z","shell.execute_reply":"2025-08-27T14:27:44.375876Z"}},"outputs":[{"name":"stderr","text":"2025-08-27 14:27:27.911429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756304848.245348      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756304848.342728      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nurl_train = \"/kaggle/input/nslkdd/KDDTrain+.txt\"\nurl_test = \"/kaggle/input/nslkdd/KDDTest+.txt\"\ncolumns = [\n    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n    'dst_host_srv_rerror_rate', 'attack', 'level'\n]\n\ntrain_df = pd.read_csv(url_train, names=columns)\ntest_df = pd.read_csv(url_test, names=columns)\n\n\n# Drop the \"type\" column (not needed)\ntrain_df.drop(columns=['level'], inplace=True)\ntest_df.drop(columns=['level'], inplace=True)\n\n# Strip whitespace from class labels\nfor df in [train_df, test_df]:\n    df['attack'] = df['attack'].str.strip()\n\n\n\n# Combine train and test\nfull_df = pd.concat([train_df, test_df], ignore_index=True)\n\nfull_df['label'] = full_df['attack'].apply(lambda x: 0 if x == 'normal' else 1)\nfull_df = full_df.drop(columns=['attack'])\n\nprint(f'full_df.shape : {full_df.shape}')\n\n\n\n\n# --------------------------- perform preprocessing--------------\n\nfrom preprocess import Preprocess\n\n# separate the features and labels so that the labesl are not encoded\nlabels = full_df['label']\nfeatures = full_df.drop(columns=['label'])\n\npp = Preprocess()\nprocessed_features = pp.fit_transform_df_auto(df = features,n_categorical_levels=32, expected_categorical_format='onehot')\n\nprint(processed_features.shape)\n\n# concat the features and the labels\nprocessed_full_df = pd.concat([processed_features, labels], axis=1)\n\n# Filter out categorical one-hot encoded columns\nnumerical_columns = [col for col in processed_full_df \n                     if not (col.startswith(\"proto_\") or \n                             col.startswith(\"service_\") or \n                             col.startswith(\"state_\") or\n                             col == 'label')]\n\ntarget = processed_full_df['label']\nfeatures = processed_full_df.drop(columns=['label'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:27:44.377085Z","iopub.execute_input":"2025-08-27T14:27:44.377464Z","iopub.status.idle":"2025-08-27T14:27:46.154856Z","shell.execute_reply.started":"2025-08-27T14:27:44.377448Z","shell.execute_reply":"2025-08-27T14:27:46.154096Z"}},"outputs":[{"name":"stdout","text":"full_df.shape : (148517, 42)\nEncoding the 3 levels for protocol_type\nEncoding the 32 levels for service\nEncoding the 11 levels for flag\n(148517, 84)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nX = features.astype(\"float32\").values  # (257673, 95) as float32\ny = target.astype(\"int32\").values      # (257673,)\n\n\n# reshape for (samples, timesteps, features=1)\nX = np.expand_dims(X, axis=-1)  # (257673, 95, 1)\n\n# Split train, val, test\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp)\n\nprint(f\"X_train: {X_train.shape}\")\nprint(f\"y_train: {y_train.shape}\")\nprint(f\"X_val: {X_val.shape}\")\nprint(f\"y_val: {y_val.shape}\")\nprint(f\"X_test: {X_test.shape}\")\nprint(f\"y_test: {y_test.shape}\")\n\n\n\ninput_shape = (X_train.shape[1], X_train.shape[2])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:27:46.155661Z","iopub.execute_input":"2025-08-27T14:27:46.155869Z","iopub.status.idle":"2025-08-27T14:27:46.502978Z","shell.execute_reply.started":"2025-08-27T14:27:46.155846Z","shell.execute_reply":"2025-08-27T14:27:46.502385Z"}},"outputs":[{"name":"stdout","text":"X_train: (118813, 84, 1)\ny_train: (118813,)\nX_val: (23763, 84, 1)\ny_val: (23763,)\nX_test: (5941, 84, 1)\ny_test: (5941,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\ndef evaluate_metrics(y_true, y_pred):\n    f1 = f1_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n\n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        numerator = tp * tn - fp * fn\n        denominator = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n        mcc = numerator / (denominator + 1e-10)\n        specificity = tn / (tn + fp + 1e-10)\n        balanced_acc = (recall + specificity) / 2\n    else:\n        mcc = 0\n        balanced_acc = 0\n        specificity = 0\n\n    return {\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'mcc': mcc,\n        'specificity': specificity,\n        'balanced_accuracy': balanced_acc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:27:46.503844Z","iopub.execute_input":"2025-08-27T14:27:46.504204Z","iopub.status.idle":"2025-08-27T14:27:46.510012Z","shell.execute_reply.started":"2025-08-27T14:27:46.504183Z","shell.execute_reply":"2025-08-27T14:27:46.509289Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\n# Bidirectional LSTM model\nmodel = models.Sequential([\n    layers.Bidirectional(layers.LSTM(64, return_sequences=False), input_shape=(95,1)),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory_bi_lstm = model.fit(\n    X_train, y_train,\n    epochs=20,\n    batch_size=256,\n    validation_data=(X_val, y_val),\n    verbose=1\n)\n\n# Predictions\ny_pred_bi_lstm = (model.predict(X_test) > 0.5).astype(\"int32\")\n\n# Evaluate\nbi_lstm_results = evaluate_metrics(y_true=y_test, y_pred=y_pred_bi_lstm)\nprint(f\"Bidirectional LSTM results: {bi_lstm_results}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:27:46.510795Z","iopub.execute_input":"2025-08-27T14:27:46.511084Z","iopub.status.idle":"2025-08-27T14:29:46.535548Z","shell.execute_reply.started":"2025-08-27T14:27:46.511067Z","shell.execute_reply":"2025-08-27T14:29:46.534610Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1756304868.037291      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1756304868.038109      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:27:50.070178: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\nI0000 00:00:1756304873.805881     112 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m464/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8321 - loss: 0.4216","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:27:59.973515: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.8322 - loss: 0.4212 - val_accuracy: 0.9054 - val_loss: 0.2422\nEpoch 2/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9175 - loss: 0.2149 - val_accuracy: 0.9325 - val_loss: 0.1798\nEpoch 3/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9355 - loss: 0.1769 - val_accuracy: 0.9380 - val_loss: 0.1589\nEpoch 4/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9384 - loss: 0.1569 - val_accuracy: 0.9360 - val_loss: 0.1572\nEpoch 5/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9484 - loss: 0.1292 - val_accuracy: 0.9475 - val_loss: 0.1268\nEpoch 6/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.1146 - val_accuracy: 0.9639 - val_loss: 0.1051\nEpoch 7/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9611 - loss: 0.1021 - val_accuracy: 0.9643 - val_loss: 0.1011\nEpoch 8/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: 0.0944 - val_accuracy: 0.9674 - val_loss: 0.0884\nEpoch 9/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9641 - loss: 0.0956 - val_accuracy: 0.9721 - val_loss: 0.0785\nEpoch 10/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9704 - loss: 0.0806 - val_accuracy: 0.9746 - val_loss: 0.0716\nEpoch 11/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9724 - loss: 0.0756 - val_accuracy: 0.9697 - val_loss: 0.0808\nEpoch 12/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0723 - val_accuracy: 0.9742 - val_loss: 0.0755\nEpoch 13/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9745 - loss: 0.0696 - val_accuracy: 0.9750 - val_loss: 0.0712\nEpoch 14/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9759 - loss: 0.0669 - val_accuracy: 0.9774 - val_loss: 0.0663\nEpoch 15/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0626 - val_accuracy: 0.9791 - val_loss: 0.0591\nEpoch 16/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9790 - loss: 0.0592 - val_accuracy: 0.9805 - val_loss: 0.0577\nEpoch 17/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9796 - loss: 0.0576 - val_accuracy: 0.9824 - val_loss: 0.0540\nEpoch 18/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9806 - loss: 0.0548 - val_accuracy: 0.9798 - val_loss: 0.0587\nEpoch 19/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9820 - loss: 0.0513 - val_accuracy: 0.9832 - val_loss: 0.0541\nEpoch 20/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0508 - val_accuracy: 0.9832 - val_loss: 0.0492\n","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:29:45.196083: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\nBidirectional LSTM results: {'f1': 0.9833596076370642, 'precision': 0.9849122807017544, 'recall': 0.9818118223154949, 'mcc': 0.9679745377873209, 'specificity': 0.9860480207657045, 'balanced_accuracy': 0.9839299215405997}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Attack codes","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n@tf.function\ndef fgsm_attack_tf(model, inputs, labels, epsilon=0.05, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    with tf.GradientTape() as tape:\n        tape.watch(inputs)\n        predictions = model(inputs, training=False)\n        loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n        loss = tf.reduce_mean(loss)\n\n    gradients = tape.gradient(loss, inputs)\n    signed_grad = tf.sign(gradients)\n    x_adv = inputs + epsilon * signed_grad\n    x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n    return x_adv\n\n\n@tf.function\ndef pgd_attack_tf(model, inputs, labels, epsilon=0.05, alpha=0.01, num_iter=10, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    x_adv = tf.identity(inputs)\n\n    for _ in tf.range(num_iter):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            predictions = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n            loss = tf.reduce_mean(loss)\n\n        gradients = tape.gradient(loss, x_adv)\n        x_adv = x_adv + alpha * tf.sign(gradients)\n        x_adv = tf.clip_by_value(x_adv, inputs - epsilon, inputs + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n\n\n@tf.function\ndef mi_fgsm_attack(model, inputs, labels, epsilon=0.05, alpha=0.01, steps=40, decay=1.0, clip_min=-1.5, clip_max=1.5):\n    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n    labels = tf.reshape(tf.convert_to_tensor(labels, dtype=tf.float32), (-1, 1))\n\n    x_adv = tf.identity(inputs)\n    g = tf.zeros_like(inputs)\n\n    for _ in tf.range(steps):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            logits = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(labels, logits)\n            loss = tf.reduce_mean(loss)\n\n        grad = tape.gradient(loss, x_adv)\n        # Normalize gradient\n        grad_norm = tf.reduce_mean(tf.abs(grad), axis=list(range(1, len(grad.shape))), keepdims=True)\n        grad = grad / (grad_norm + 1e-8)\n\n        g = decay * g + grad\n        x_adv = x_adv + alpha * tf.sign(g)\n        x_adv = tf.clip_by_value(x_adv, inputs - epsilon, inputs + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:29:46.539593Z","iopub.execute_input":"2025-08-27T14:29:46.540478Z","iopub.status.idle":"2025-08-27T14:29:46.561072Z","shell.execute_reply.started":"2025-08-27T14:29:46.540440Z","shell.execute_reply":"2025-08-27T14:29:46.560197Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def evaluate_model(model, X, y,epsilon_list=[0.01, 0.03, 0.05, 0.07]):\n    import tensorflow as tf\n    import numpy as np\n\n    X_clean = X\n    x_clean_tf = tf.convert_to_tensor(X_clean, dtype=tf.float32)\n    y_tf = tf.convert_to_tensor(y, dtype=tf.float32)\n\n    # ---------------- Clean Evaluation ----------------\n    print(\"✅ Clean Evaluation:\")\n    y_pred_clean = (model.predict(x_clean_tf) > 0.5).astype(int).flatten()\n    clean_metrics = evaluate_metrics(y, y_pred_clean)\n    print(f\"  F1: {clean_metrics['f1']:.4f}, Precision: {clean_metrics['precision']:.4f}, Recall: {clean_metrics['recall']:.4f}, MCC: {clean_metrics.get('mcc', 'N/A')}, Specificity: {clean_metrics.get('specificity', 'N/A')}, Balanced Acc: {clean_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- FGSM Evaluation ----------------\n    print(\"\\nFGSM Attack Evaluation\")\n    fgsm_results = []\n    for eps in epsilon_list:\n        x_adv = fgsm_attack_tf(model, x_clean_tf, y_tf, epsilon=eps )\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        fgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- PGD Evaluation ----------------\n    print(\"\\nPGD Attack Evaluation:\")\n    pgd_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        x_adv = pgd_attack_tf(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, num_iter=10)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        pgd_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  PGD ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ---------------- MI-FGSM Evaluation ----------------\n    print(\"\\nMI-FGSM Attack Evaluation:\")\n    mifgsm_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        steps = 10   \n        decay = 1.0   \n\n        x_adv = mi_fgsm_attack(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, steps=steps, decay=decay)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        y_pred_adv = (model.predict(x_adv_tf) > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred_adv)\n        mifgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\" MI-FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    return fgsm_results, pgd_results, mifgsm_results\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:29:46.562339Z","iopub.execute_input":"2025-08-27T14:29:46.562713Z","iopub.status.idle":"2025-08-27T14:29:46.592575Z","shell.execute_reply.started":"2025-08-27T14:29:46.562682Z","shell.execute_reply":"2025-08-27T14:29:46.591598Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(\"CNN Results: \")\nepsilons = [.01,.03,.05,.07]\nfgsm_results, pgd_results, mifgsm_results = evaluate_model(\n    model=model,\n    X=X_test,\n    y=y_test,\n    epsilon_list=epsilons,\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:29:46.593472Z","iopub.execute_input":"2025-08-27T14:29:46.593719Z","iopub.status.idle":"2025-08-27T14:30:22.805024Z","shell.execute_reply.started":"2025-08-27T14:29:46.593702Z","shell.execute_reply":"2025-08-27T14:30:22.804244Z"}},"outputs":[{"name":"stdout","text":"CNN Results: \n✅ Clean Evaluation:\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  F1: 0.9834, Precision: 0.9849, Recall: 0.9818, MCC: 0.9679745377873209, Specificity: 0.9860480207657045, Balanced Acc: 0.9839299215405997\n\nFGSM Attack Evaluation\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  FGSM ε=0.01 → F1: 0.8948, Precision: 0.8850, Recall: 0.9049, MCC: 0.7953825767349914, Specificity: 0.890979883192703, Balanced Acc: 0.8979208614984151\n\u001b[1m 46/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:29:50.725661: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  FGSM ε=0.03 → F1: 0.6634, Precision: 0.5479, Recall: 0.8409, MCC: 0.2241431039620976, Specificity: 0.35626216742373923, Balanced Acc: 0.5985578063421599\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  FGSM ε=0.05 → F1: 0.6489, Precision: 0.5819, Recall: 0.7335, MCC: 0.2500860476810722, Specificity: 0.5110317975340521, Balanced Acc: 0.6222525199632485\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  FGSM ε=0.07 → F1: 0.6204, Precision: 0.5745, Recall: 0.6744, MCC: 0.21267598788308995, Specificity: 0.5366645035690936, Balanced Acc: 0.6055130842434485\n\nPGD Attack Evaluation:\n\u001b[1m 48/186\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:29:57.644154: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.01 → F1: 0.8436, Precision: 0.8284, Recall: 0.8594, MCC: 0.693750452514361, Specificity: 0.834847501622296, Balanced Acc: 0.8471194486075804\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.03 → F1: 0.5635, Precision: 0.4722, Recall: 0.6985, MCC: -0.028362158253871866, Specificity: 0.2757949383517107, Balanced Acc: 0.4871454579831306\n\u001b[1m 49/186\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:30:04.549445: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.05 → F1: 0.4043, Precision: 0.3519, Recall: 0.4750, MCC: -0.35239033650710483, Specificity: 0.18851395197922816, Balanced Acc: 0.33175260383151683\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.07 → F1: 0.2134, Precision: 0.2017, Recall: 0.2267, MCC: -0.6071990403182418, Specificity: 0.1677482154445111, Balanced Acc: 0.1972004456026333\n\nMI-FGSM Attack Evaluation:\n\u001b[1m 49/186\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:30:11.583776: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n MI-FGSM ε=0.01 → F1: 0.8526, Precision: 0.8416, Recall: 0.8639, MCC: 0.7126107699108889, Specificity: 0.849123945489914, Balanced Acc: 0.8565311927519524\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n MI-FGSM ε=0.03 → F1: 0.5533, Precision: 0.4560, Recall: 0.7034, MCC: -0.08567722277150489, Specificity: 0.22160934458143344, Balanced Acc: 0.4625010696324446\n\u001b[1m 46/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:30:18.552315: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n MI-FGSM ε=0.05 → F1: 0.4109, Precision: 0.3473, Recall: 0.5030, MCC: -0.40669590685762, Specificity: 0.12297209604152748, Balanced Acc: 0.31297258177382425\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n MI-FGSM ε=0.07 → F1: 0.1944, Precision: 0.1752, Recall: 0.2183, MCC: -0.7491274581734098, Specificity: 0.047047371836468295, Balanced Acc: 0.13265275202526458\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Adversarial Training","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Model\n\nclass PGDAdversarialTrainerCNN(tf.keras.Model):\n    def __init__(self, base_model, epsilon_range=(0.01, 0.1), alpha=0.01, num_iter=7, clip_min=-1.5, clip_max=1.5):\n        super().__init__()\n        self.base_model = base_model\n        self.epsilon_range = epsilon_range\n        self.alpha = alpha\n        self.num_iter = num_iter\n        self.clip_min = clip_min\n        self.clip_max = clip_max\n        self.loss_fn = tf.keras.losses.BinaryCrossentropy()\n        self.metric = tf.keras.metrics.BinaryAccuracy()\n\n    def compile(self, optimizer, **kwargs):\n        super().compile(**kwargs)\n        self.optimizer = optimizer\n\n    def pgd_attack_batch(self, x, y):\n        x_adv = tf.identity(x)\n        y = tf.expand_dims(tf.cast(y, tf.float32), axis=-1)\n        epsilon = tf.random.uniform([], *self.epsilon_range)\n\n        for _ in range(self.num_iter):\n            with tf.GradientTape() as tape:\n                tape.watch(x_adv)\n                preds = self.base_model(x_adv, training=True)\n                loss = self.loss_fn(y, preds)\n\n            grad = tape.gradient(loss, x_adv)\n            x_adv = x_adv + self.alpha * tf.sign(grad)\n            # Project back to epsilon ball around original input\n            x_adv = tf.clip_by_value(x_adv, x - epsilon, x + epsilon)\n            x_adv = tf.clip_by_value(x_adv, self.clip_min, self.clip_max)\n\n        return x_adv\n\n    def train_step(self, data):\n        x, y = data\n        x_adv = self.pgd_attack_batch(x, y)\n\n        # Combine clean and adversarial samples\n        x_combined = tf.concat([x, x_adv], axis=0)\n        y_combined = tf.concat([y, y], axis=0)\n        y_combined = tf.expand_dims(tf.cast(y_combined, tf.float32), axis=-1)\n\n        with tf.GradientTape() as tape:\n            preds = self.base_model(x_combined, training=True)\n            loss = self.loss_fn(y_combined, preds)\n\n        grads = tape.gradient(loss, self.base_model.trainable_variables)\n        self.optimizer.apply_gradients(zip(grads, self.base_model.trainable_variables))\n        self.metric.update_state(y_combined, preds)\n\n        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n\n    def test_step(self, data):\n        x, y = data\n        y = tf.expand_dims(tf.cast(y, tf.float32), axis=-1)\n        preds = self.base_model(x, training=False)\n        loss = self.loss_fn(y, preds)\n        self.metric.update_state(y, preds)\n        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n\n    def call(self, inputs):\n        return self.base_model(inputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:30:22.805818Z","iopub.execute_input":"2025-08-27T14:30:22.806104Z","iopub.status.idle":"2025-08-27T14:30:22.817687Z","shell.execute_reply.started":"2025-08-27T14:30:22.806086Z","shell.execute_reply":"2025-08-27T14:30:22.816836Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Wrap your existing CNN\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(\n    monitor='val_loss',   # monitor validation loss\n    patience=3,           # stop if no improvement for 3 epochs\n    restore_best_weights=True\n)\n\n\nadv_model = PGDAdversarialTrainerCNN(\n    base_model=model,           \n    epsilon_range=(0.01, 0.05),\n    alpha=0.01,\n    num_iter=7,\n    clip_min=-1.5,\n    clip_max=1.5\n)\n\nadv_model.compile(optimizer=tf.keras.optimizers.Adam())\n\n# Train with adversarial training\nadv_model.fit(\n    x=X_train,\n    y=y_train,\n    validation_data=(X_val, y_val),\n    batch_size=256,\n    epochs=20,\n    callbacks=[early_stop] \n\n)\n\nprint(\"Advesarial training Results: \")\nepsilons = [.01,.03,.05,.07]\nfgsm_results, pgd_results, mifgsm_results = evaluate_model(\n    model=adv_model,\n    X=X_test,\n    y=y_test,\n    epsilon_list=epsilons,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:30:22.818446Z","iopub.execute_input":"2025-08-27T14:30:22.818972Z","iopub.status.idle":"2025-08-27T14:42:59.179813Z","shell.execute_reply.started":"2025-08-27T14:30:22.818949Z","shell.execute_reply":"2025-08-27T14:42:59.179183Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m464/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8360 - loss: 0.3123","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:31:10.320764: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 78ms/step - accuracy: 0.8361 - loss: 0.3116 - val_accuracy: 0.9241 - val_loss: 0.1983\nEpoch 2/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9116 - loss: 0.1972 - val_accuracy: 0.9660 - val_loss: 0.0751\nEpoch 3/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9451 - loss: 0.1386 - val_accuracy: 0.9672 - val_loss: 0.0550\nEpoch 4/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9556 - loss: 0.1191 - val_accuracy: 0.9699 - val_loss: 0.0489\nEpoch 5/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 76ms/step - accuracy: 0.9603 - loss: 0.1049 - val_accuracy: 0.9758 - val_loss: 0.0368\nEpoch 6/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9649 - loss: 0.0936 - val_accuracy: 0.9803 - val_loss: 0.0339\nEpoch 7/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 75ms/step - accuracy: 0.9675 - loss: 0.0854 - val_accuracy: 0.9824 - val_loss: 0.0314\nEpoch 8/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9704 - loss: 0.0808 - val_accuracy: 0.9832 - val_loss: 0.0273\nEpoch 9/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9731 - loss: 0.0748 - val_accuracy: 0.9850 - val_loss: 0.0233\nEpoch 10/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9752 - loss: 0.0707 - val_accuracy: 0.9851 - val_loss: 0.0231\nEpoch 11/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9769 - loss: 0.0664 - val_accuracy: 0.9858 - val_loss: 0.0205\nEpoch 12/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9781 - loss: 0.0623 - val_accuracy: 0.9864 - val_loss: 0.0195\nEpoch 13/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9791 - loss: 0.0599 - val_accuracy: 0.9867 - val_loss: 0.0192\nEpoch 14/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9802 - loss: 0.0572 - val_accuracy: 0.9868 - val_loss: 0.0177\nEpoch 15/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9809 - loss: 0.0543 - val_accuracy: 0.9859 - val_loss: 0.0198\nEpoch 16/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9816 - loss: 0.0518 - val_accuracy: 0.9866 - val_loss: 0.0194\nEpoch 17/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9827 - loss: 0.0501 - val_accuracy: 0.9879 - val_loss: 0.0171\nEpoch 18/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 76ms/step - accuracy: 0.9832 - loss: 0.0478 - val_accuracy: 0.9880 - val_loss: 0.0182\nEpoch 19/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9838 - loss: 0.0463 - val_accuracy: 0.9878 - val_loss: 0.0171\nEpoch 20/20\n\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.9844 - loss: 0.0445 - val_accuracy: 0.9883 - val_loss: 0.0153\nAdvesarial training Results: \n✅ Clean Evaluation:\n","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:42:23.346059: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n  F1: 0.9890, Precision: 0.9885, Recall: 0.9895, MCC: 0.9787628323905042, Specificity: 0.9892926670992541, Balanced Acc: 0.9893997438329429\n\nFGSM Attack Evaluation\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  FGSM ε=0.01 → F1: 0.9872, Precision: 0.9867, Recall: 0.9878, MCC: 0.9753917722331293, Specificity: 0.9876703439324793, Balanced Acc: 0.9877141506301081\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  FGSM ε=0.03 → F1: 0.9839, Precision: 0.9832, Recall: 0.9846, MCC: 0.9689875357469794, Specificity: 0.9844256975989297, Balanced Acc: 0.9845178505483281\n\u001b[1m 44/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:42:28.432089: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  FGSM ε=0.05 → F1: 0.9775, Precision: 0.9763, Recall: 0.9787, MCC: 0.9565182099961307, Specificity: 0.9779364049318306, Balanced Acc: 0.9783001367086576\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  FGSM ε=0.07 → F1: 0.9662, Precision: 0.9625, Recall: 0.9699, MCC: 0.9346428771104298, Specificity: 0.9649578195976325, Balanced Acc: 0.9674386859443216\n\nPGD Attack Evaluation:\n\u001b[1m 45/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:42:33.905043: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  PGD ε=0.01 → F1: 0.9872, Precision: 0.9867, Recall: 0.9878, MCC: 0.9753917722331293, Specificity: 0.9876703439324793, Balanced Acc: 0.9877141506301081\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.03 → F1: 0.9825, Precision: 0.9818, Recall: 0.9832, MCC: 0.966290720672714, Specificity: 0.9831278390655099, Balanced Acc: 0.9831693759860602\n\u001b[1m 49/186\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:42:40.835857: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.05 → F1: 0.9747, Precision: 0.9735, Recall: 0.9759, MCC: 0.9511247744708912, Specificity: 0.9753406878649911, Balanced Acc: 0.975603187584122\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  PGD ε=0.07 → F1: 0.9354, Precision: 0.9362, Recall: 0.9346, MCC: 0.8755965945856612, Specificity: 0.940947436729366, Balanced Acc: 0.9377699757973518\n\nMI-FGSM Attack Evaluation:\n\u001b[1m 44/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:42:47.839929: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n MI-FGSM ε=0.01 → F1: 0.9872, Precision: 0.9867, Recall: 0.9878, MCC: 0.9753917722331293, Specificity: 0.9876703439324793, Balanced Acc: 0.9877141506301081\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n MI-FGSM ε=0.03 → F1: 0.9825, Precision: 0.9818, Recall: 0.9832, MCC: 0.966290720672714, Specificity: 0.9831278390655099, Balanced Acc: 0.9831693759860602\n\u001b[1m 48/186\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:42:54.830641: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n MI-FGSM ε=0.05 → F1: 0.9757, Precision: 0.9749, Recall: 0.9766, MCC: 0.9531448274541383, Specificity: 0.9766385463984109, Balanced Acc: 0.9766018894986108\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n MI-FGSM ε=0.07 → F1: 0.9469, Precision: 0.9462, Recall: 0.9475, MCC: 0.8975219362789499, Specificity: 0.9500324464633046, Balanced Acc: 0.9487832746482315\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# generate adversarial values for gan training\n\n# experimental PGD code (GPU-optimized, batched)\ndef pgd_attack_tf_fast(model, x, y, epsilon=0.05, alpha=0.01, num_iter=10, clip_min=-1.5, clip_max=1.5):\n    x = tf.convert_to_tensor(x, dtype=tf.float32)\n    y = tf.reshape(tf.cast(y, tf.float32), (-1, 1))\n    x_orig = tf.identity(x)\n    x_adv = tf.identity(x)\n\n    for _ in range(num_iter):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            logits = model(x_adv, training=False)\n            loss = tf.keras.losses.binary_crossentropy(y, logits)\n            loss = tf.reduce_mean(loss)\n\n        grad = tape.gradient(loss, x_adv)\n        signed_grad = tf.sign(grad)\n        x_adv = x_adv + alpha * signed_grad\n        x_adv = tf.clip_by_value(x_adv, x_orig - epsilon, x_orig + epsilon)\n        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n    return x_adv\n\ndef batch_pgd_attack(model, X, y, attack_fn, batch_size=1024, **kwargs):\n    adv_list = []\n    X = tf.convert_to_tensor(X, dtype=tf.float32)\n    y = tf.convert_to_tensor(y, dtype=tf.float32)\n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        y_batch = y[i:i+batch_size]\n        x_adv_batch = attack_fn(model, X_batch, y_batch, **kwargs)\n        adv_list.append(x_adv_batch)\n    return tf.concat(adv_list, axis=0)\n\n# Generate adversarial examples in batches to leverage GPU\nX_adv_train = batch_pgd_attack(model, X_train, y_train, pgd_attack_tf_fast, epsilon=0.05, batch_size=1024)\nprint(f\"X_adv_train shape: {X_adv_train.shape}\")\n\nX_adv_val = batch_pgd_attack(model, X_val, y_val, pgd_attack_tf_fast, epsilon=0.05, batch_size=1024)\nprint(f\"X_adv_val shape: {X_adv_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:42:59.180602Z","iopub.execute_input":"2025-08-27T14:42:59.180894Z","iopub.status.idle":"2025-08-27T14:44:11.341850Z","shell.execute_reply.started":"2025-08-27T14:42:59.180874Z","shell.execute_reply":"2025-08-27T14:44:11.341089Z"}},"outputs":[{"name":"stdout","text":"X_adv_train shape: (118813, 84, 1)\nX_adv_val shape: (23763, 84, 1)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# ------------------------------\n# Generator CNN (1D output)\n# ------------------------------\nclass GeneratorCNN(Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.bn1 = layers.BatchNormalization()\n        self.conv2 = layers.Conv1D(128, 3, padding='same', activation='relu')\n        self.bn2 = layers.BatchNormalization()\n        self.conv3 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.bn3 = layers.BatchNormalization()\n        # final output: 1 channel (same as clean input)\n        self.output_layer = layers.Conv1D(1, 3, padding='same', activation='linear')\n\n    def call(self, x, training=False):\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n        return self.output_layer(x)\n\n\n# ------------------------------\n# Discriminator CNN (1D input)\n# ------------------------------\nclass DiscriminatorCNN(Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = layers.Conv1D(64, 3, padding='same', activation='relu')\n        self.global_pool = layers.GlobalAveragePooling1D()\n        self.dense1 = layers.Dense(64, activation='relu')\n        self.output_layer = layers.Dense(1, activation='sigmoid')\n\n    def call(self, x, training=False):\n        x = self.conv1(x)\n        x = self.global_pool(x)\n        x = self.dense1(x)\n        return self.output_layer(x)\n\n\n# ------------------------------\n# GAN Purifier CNN\n# ------------------------------\nclass GANPurifierCNN(Model):\n    def __init__(self, generator, discriminator, lambda_adv=0.5):\n        super().__init__()\n        self.generator = generator\n        self.discriminator = discriminator\n        self.lambda_adv = lambda_adv\n        self.bce = tf.keras.losses.BinaryCrossentropy()\n        self.l1 = tf.keras.losses.MeanAbsoluteError()\n        self.d_optimizer = tf.keras.optimizers.Adam(1e-4)\n        self.g_optimizer = tf.keras.optimizers.Adam(1e-4)\n\n    def compile(self, **kwargs):\n        super().compile(**kwargs)\n\n    def train_step(self, data):\n        x_clean, x_adv = data\n        with tf.GradientTape(persistent=True) as tape:\n            x_fake = self.generator(x_adv, training=True)\n            real_pred = self.discriminator(x_clean, training=True)\n            fake_pred = self.discriminator(x_fake, training=True)\n\n            # Discriminator loss\n            d_loss = self.bce(tf.ones_like(real_pred), real_pred) + \\\n                     self.bce(tf.zeros_like(fake_pred), fake_pred)\n\n            # Generator loss (reconstruction + adversarial)\n            g_loss = self.l1(x_clean, x_fake) + \\\n                     self.lambda_adv * self.bce(tf.ones_like(fake_pred), fake_pred)\n\n            # Cosine similarity\n            x_clean_flat = tf.reshape(x_clean, (tf.shape(x_clean)[0], -1))\n            x_fake_flat = tf.reshape(x_fake, (tf.shape(x_fake)[0], -1))\n            cos_sim = -tf.reduce_mean(\n                tf.keras.losses.cosine_similarity(x_clean_flat, x_fake_flat)\n            )\n\n        # Compute gradients\n        d_grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n        g_grads = tape.gradient(g_loss, self.generator.trainable_variables)\n\n        # Apply gradients\n        self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))\n        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss,\n                \"reconstruction_loss\": self.l1(x_clean, x_fake),\n                \"cosine_similarity\": cos_sim}\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:44:11.342835Z","iopub.execute_input":"2025-08-27T14:44:11.343124Z","iopub.status.idle":"2025-08-27T14:44:11.356094Z","shell.execute_reply.started":"2025-08-27T14:44:11.343105Z","shell.execute_reply":"2025-08-27T14:44:11.355548Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ------------------------------\n# Instantiate models\n# ------------------------------\ngenerator = GeneratorCNN()\ndiscriminator = DiscriminatorCNN()\n\n# Build models with dummy input (1 channel)\ndummy_input = tf.zeros((1, 95, 1))\ngenerator(dummy_input)\ndiscriminator(dummy_input)\n\ngan_cnn = GANPurifierCNN(generator, discriminator, lambda_adv=0.5)\ngan_cnn.compile()\n\n# ------------------------------\n# Prepare dataset\n# ------------------------------\nbatch_size = 512\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, X_adv_train))\ntrain_dataset = train_dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\nearly_stop = EarlyStopping(\n    monitor=\"cosine_similarity\",\n    mode=\"max\",              # higher cosine similarity is better\n    patience=10,\n    min_delta=1e-4,\n    restore_best_weights=True,\n    verbose=1\n)\n\n# ------------------------------\n# Train\n# ------------------------------\ngan_cnn.fit(train_dataset, epochs=100, callbacks=[early_stop])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:44:11.356900Z","iopub.execute_input":"2025-08-27T14:44:11.357142Z","iopub.status.idle":"2025-08-27T14:47:16.747246Z","shell.execute_reply.started":"2025-08-27T14:44:11.357120Z","shell.execute_reply":"2025-08-27T14:47:16.746623Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - cosine_similarity: 0.8517 - d_loss: 1.3775 - g_loss: 0.4628 - reconstruction_loss: 0.1136\nEpoch 2/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9717 - d_loss: 1.3800 - g_loss: 0.3909 - reconstruction_loss: 0.0424\nEpoch 3/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9814 - d_loss: 1.3791 - g_loss: 0.3819 - reconstruction_loss: 0.0333\nEpoch 4/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9855 - d_loss: 1.3782 - g_loss: 0.3776 - reconstruction_loss: 0.0288\nEpoch 5/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - cosine_similarity: 0.9877 - d_loss: 1.3772 - g_loss: 0.3756 - reconstruction_loss: 0.0266\nEpoch 6/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - cosine_similarity: 0.9890 - d_loss: 1.3759 - g_loss: 0.3745 - reconstruction_loss: 0.0252\nEpoch 7/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9897 - d_loss: 1.3727 - g_loss: 0.3748 - reconstruction_loss: 0.0247\nEpoch 8/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9906 - d_loss: 1.3672 - g_loss: 0.3748 - reconstruction_loss: 0.0234\nEpoch 9/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9909 - d_loss: 1.3542 - g_loss: 0.3786 - reconstruction_loss: 0.0238\nEpoch 10/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9915 - d_loss: 1.3393 - g_loss: 0.3815 - reconstruction_loss: 0.0228\nEpoch 11/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9916 - d_loss: 1.3192 - g_loss: 0.3865 - reconstruction_loss: 0.0226\nEpoch 12/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9920 - d_loss: 1.3032 - g_loss: 0.3898 - reconstruction_loss: 0.0213\nEpoch 13/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9917 - d_loss: 1.2742 - g_loss: 0.3986 - reconstruction_loss: 0.0218\nEpoch 14/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9918 - d_loss: 1.2499 - g_loss: 0.4054 - reconstruction_loss: 0.0215\nEpoch 15/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9919 - d_loss: 1.2252 - g_loss: 0.4125 - reconstruction_loss: 0.0212\nEpoch 16/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9919 - d_loss: 1.2004 - g_loss: 0.4199 - reconstruction_loss: 0.0209\nEpoch 17/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9916 - d_loss: 1.1762 - g_loss: 0.4289 - reconstruction_loss: 0.0212\nEpoch 18/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9920 - d_loss: 1.1604 - g_loss: 0.4332 - reconstruction_loss: 0.0204\nEpoch 19/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9919 - d_loss: 1.1391 - g_loss: 0.4402 - reconstruction_loss: 0.0204\nEpoch 20/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9912 - d_loss: 1.0922 - g_loss: 0.4598 - reconstruction_loss: 0.0220\nEpoch 21/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9918 - d_loss: 1.0964 - g_loss: 0.4548 - reconstruction_loss: 0.0202\nEpoch 22/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9921 - d_loss: 1.0833 - g_loss: 0.4606 - reconstruction_loss: 0.0195\nEpoch 23/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9919 - d_loss: 1.0452 - g_loss: 0.4763 - reconstruction_loss: 0.0203\nEpoch 24/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9915 - d_loss: 1.0284 - g_loss: 0.4836 - reconstruction_loss: 0.0205\nEpoch 25/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9915 - d_loss: 0.9960 - g_loss: 0.4980 - reconstruction_loss: 0.0209\nEpoch 26/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9916 - d_loss: 0.9949 - g_loss: 0.4977 - reconstruction_loss: 0.0202\nEpoch 27/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9917 - d_loss: 0.9546 - g_loss: 0.5165 - reconstruction_loss: 0.0204\nEpoch 28/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9908 - d_loss: 0.9344 - g_loss: 0.5290 - reconstruction_loss: 0.0216\nEpoch 29/100\n\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - cosine_similarity: 0.9913 - d_loss: 0.9068 - g_loss: 0.5405 - reconstruction_loss: 0.0209\nEpoch 29: early stopping\nRestoring model weights from the end of the best epoch: 19.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b0e941314d0>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Generate purified outputs\nx_purified_val = generator(X_adv_val, training=False)\n\n# Cast to float32 for evaluation\nx_purified_val = tf.cast(x_purified_val, tf.float32)\nX_val_cast = tf.cast(X_val, tf.float32)\n\n# L1 (Mean Absolute Error)\nl1_loss = tf.reduce_mean(tf.abs(X_val_cast - x_purified_val))\n\n# L2 (Mean Squared Error)\nl2_loss = tf.reduce_mean(tf.square(X_val_cast - x_purified_val))\n\n# Normalize along sequence dimension\nX_val_norm = tf.nn.l2_normalize(tf.squeeze(X_val_cast, axis=-1), axis=1)           \nx_purified_norm = tf.nn.l2_normalize(tf.squeeze(x_purified_val, axis=-1), axis=1)  \n\n# Cosine similarity\ncos_sim = tf.reduce_mean(tf.reduce_sum(X_val_norm * x_purified_norm, axis=1))\n\nprint(f\"🧪 Purifier Evaluation Metrics:\")\nprint(f\"✅ Cosine Similarity: {cos_sim:.6f}\")\nprint(f\"   ➤ L1 Loss (MAE): {l1_loss:.6f}\")\nprint(f\"   ➤ L2 Loss (MSE): {l2_loss:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:47:16.748069Z","iopub.execute_input":"2025-08-27T14:47:16.748335Z","iopub.status.idle":"2025-08-27T14:47:17.100466Z","shell.execute_reply.started":"2025-08-27T14:47:16.748312Z","shell.execute_reply":"2025-08-27T14:47:17.099829Z"}},"outputs":[{"name":"stdout","text":"🧪 Purifier Evaluation Metrics:\n✅ Cosine Similarity: 0.991643\n   ➤ L1 Loss (MAE): 0.021814\n   ➤ L2 Loss (MSE): 0.001656\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## GAN+Adv Training evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, generator, adv_model, X, y, epsilon_list=[0.01, 0.03, 0.05, 0.07]):\n    import tensorflow as tf\n    import numpy as np\n\n    X_clean = X\n    x_clean_tf = tf.convert_to_tensor(X_clean, dtype=tf.float32)\n    y_tf = tf.convert_to_tensor(y, dtype=tf.float32)\n\n    # ----------- Clean Data Evaluation (no adversarial) -----------\n    print(\"✅ Clean Evaluation (GAN purified):\")\n    x_purified_clean = generator(x_clean_tf, training=False)\n    y_pred_clean_prob = adv_model.predict(x_purified_clean)\n    y_pred_clean = (y_pred_clean_prob > 0.5).astype(int).flatten()\n    clean_metrics = evaluate_metrics(y, y_pred_clean)\n    print(f\"Clean → F1: {clean_metrics['f1']:.4f}, Precision: {clean_metrics['precision']:.4f}, Recall: {clean_metrics['recall']:.4f}, MCC: {clean_metrics.get('mcc', 'N/A')}, Specificity: {clean_metrics.get('specificity', 'N/A')}, Balanced Acc: {clean_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ----------- FGSM Attack Evaluation -----------\n    print(\"\\nFGSM Attack Evaluation with GAN Purification\")\n    fgsm_results = []\n    for eps in epsilon_list:\n        x_adv = fgsm_attack_tf(model, x_clean_tf, y_tf, epsilon=eps )\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified)\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        fgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    # ----------- PGD Attack Evaluation -----------\n    print(\"\\nPGD Attack Evaluation with GAN Purification:\")\n    pgd_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        x_adv = pgd_attack_tf(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, num_iter=10)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified )\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        pgd_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  PGD ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n      # ----------- MI-FGSM Attack Evaluation -----------\n    print(\"\\nMI-FGSM Attack Evaluation with GAN Purification:\")\n    mifgsm_results = []\n    for eps in epsilon_list:\n        alpha = eps * 0.2\n        steps = 10\n        decay = 1.0\n\n        x_adv = mi_fgsm_attack(model, x_clean_tf, y_tf, epsilon=eps, alpha=alpha, steps=steps, decay=decay)\n        x_adv_tf = tf.convert_to_tensor(x_adv.numpy(), dtype=tf.float32)\n        x_purified = generator(x_adv_tf, training=False)\n        y_pred_prob = adv_model.predict(x_purified )\n        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n\n        adv_metrics = evaluate_metrics(y, y_pred)\n        mifgsm_results.append({'epsilon': eps, 'adversarial': adv_metrics})\n\n        print(f\"  MI-FGSM ε={eps:.2f} → F1: {adv_metrics['f1']:.4f}, Precision: {adv_metrics['precision']:.4f}, Recall: {adv_metrics['recall']:.4f}, MCC: {adv_metrics.get('mcc', 'N/A')}, Specificity: {adv_metrics.get('specificity', 'N/A')}, Balanced Acc: {adv_metrics.get('balanced_accuracy', 'N/A')}\")\n\n    return fgsm_results, pgd_results, mifgsm_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:47:17.101366Z","iopub.execute_input":"2025-08-27T14:47:17.101687Z","iopub.status.idle":"2025-08-27T14:47:17.113311Z","shell.execute_reply.started":"2025-08-27T14:47:17.101660Z","shell.execute_reply":"2025-08-27T14:47:17.112703Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"fgsm_full, pgd_full, mi_full = evaluate_model(model= model,generator=generator,adv_model= model, X = X_test, y = y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T14:47:17.114268Z","iopub.execute_input":"2025-08-27T14:47:17.114437Z","iopub.status.idle":"2025-08-27T14:47:41.807155Z","shell.execute_reply.started":"2025-08-27T14:47:17.114424Z","shell.execute_reply":"2025-08-27T14:47:41.806278Z"}},"outputs":[{"name":"stdout","text":"✅ Clean Evaluation (GAN purified):\n\u001b[1m 46/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:47:17.257732: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nClean → F1: 0.9869, Precision: 0.9881, Recall: 0.9857, MCC: 0.9747165766461235, Specificity: 0.9889682024658991, Balanced Acc: 0.9873137619534812\n\nFGSM Attack Evaluation with GAN Purification\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  FGSM ε=0.01 → F1: 0.9848, Precision: 0.9846, Recall: 0.9850, MCC: 0.9706711045559225, Specificity: 0.9857235561323495, Balanced Acc: 0.9853416661389275\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  FGSM ε=0.03 → F1: 0.9792, Precision: 0.9797, Recall: 0.9787, MCC: 0.9598818497283655, Specificity: 0.9811810512653802, Balanced Acc: 0.9799224598754324\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  FGSM ε=0.05 → F1: 0.9724, Precision: 0.9727, Recall: 0.9720, MCC: 0.9467341219330121, Specificity: 0.9746917585982812, Balanced Acc: 0.9733549733879828\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  FGSM ε=0.07 → F1: 0.9605, Precision: 0.9647, Recall: 0.9563, MCC: 0.9241571456650681, Specificity: 0.9675535366644722, Balanced Acc: 0.9619159778460521\n\nPGD Attack Evaluation with GAN Purification:\n\u001b[1m 47/186\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:47:23.707196: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.01 → F1: 0.9844, Precision: 0.9839, Recall: 0.9850, MCC: 0.9699980759813296, Specificity: 0.9850746268656396, Balanced Acc: 0.9850172015055725\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  PGD ε=0.03 → F1: 0.9757, Precision: 0.9749, Recall: 0.9766, MCC: 0.9531448274541383, Specificity: 0.9766385463984109, Balanced Acc: 0.9766018894986108\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n  PGD ε=0.05 → F1: 0.9696, Precision: 0.9686, Recall: 0.9706, MCC: 0.9413477352119551, Specificity: 0.9707981829980217, Balanced Acc: 0.9707086402922952\n\u001b[1m 46/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:47:31.049410: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  PGD ε=0.07 → F1: 0.9613, Precision: 0.9631, Recall: 0.9594, MCC: 0.9254927738468393, Specificity: 0.9659312134976974, Balanced Acc: 0.9626787931776699\n\nMI-FGSM Attack Evaluation with GAN Purification:\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  MI-FGSM ε=0.01 → F1: 0.9848, Precision: 0.9846, Recall: 0.9850, MCC: 0.9706711045559225, Specificity: 0.9857235561323495, Balanced Acc: 0.9853416661389275\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  MI-FGSM ε=0.03 → F1: 0.9778, Precision: 0.9776, Recall: 0.9780, MCC: 0.9571865288009188, Specificity: 0.9792342634652504, Balanced Acc: 0.9785992933275884\n\u001b[1m 44/186\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step","output_type":"stream"},{"name":"stderr","text":"2025-08-27 14:47:38.477554: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  MI-FGSM ε=0.05 → F1: 0.9722, Precision: 0.9707, Recall: 0.9738, MCC: 0.9464085950920117, Specificity: 0.9727449707981515, Balanced Acc: 0.9732560111073654\n\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n  MI-FGSM ε=0.07 → F1: 0.9570, Precision: 0.9605, Recall: 0.9535, MCC: 0.9174069815261596, Specificity: 0.9636599610642127, Balanced Acc: 0.9585700994548065\n","output_type":"stream"}],"execution_count":17}]}