{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12493033,"sourceType":"datasetVersion","datasetId":7883909}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Tanveer2719/NIDS_Coursework.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:08:53.254202Z","iopub.execute_input":"2025-07-19T04:08:53.254937Z","iopub.status.idle":"2025-07-19T04:08:53.984939Z","shell.execute_reply.started":"2025-07-19T04:08:53.254908Z","shell.execute_reply":"2025-07-19T04:08:53.983986Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'NIDS_Coursework'...\nremote: Enumerating objects: 141, done.\u001b[K\nremote: Counting objects: 100% (141/141), done.\u001b[K\nremote: Compressing objects: 100% (92/92), done.\u001b[K\nremote: Total 141 (delta 54), reused 133 (delta 46), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (141/141), 168.67 KiB | 3.37 MiB/s, done.\nResolving deltas: 100% (54/54), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/NIDS_Coursework/My_Code\n!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:08:53.986513Z","iopub.execute_input":"2025-07-19T04:08:53.986866Z","iopub.status.idle":"2025-07-19T04:08:54.109333Z","shell.execute_reply.started":"2025-07-19T04:08:53.986842Z","shell.execute_reply":"2025-07-19T04:08:54.108496Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/NIDS_Coursework/My_Code\nclassification.py    main.ipynb     record_level_embedding.py\nfeatureSelection.py  preprocess.py  transformer.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%rm -r __pycache__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:08:54.110360Z","iopub.execute_input":"2025-07-19T04:08:54.110667Z","iopub.status.idle":"2025-07-19T04:08:54.230955Z","shell.execute_reply.started":"2025-07-19T04:08:54.110635Z","shell.execute_reply":"2025-07-19T04:08:54.230069Z"}},"outputs":[{"name":"stdout","text":"rm: cannot remove '__pycache__': No such file or directory\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!git pull origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:08:54.233159Z","iopub.execute_input":"2025-07-19T04:08:54.233446Z","iopub.status.idle":"2025-07-19T04:08:54.593765Z","shell.execute_reply.started":"2025-07-19T04:08:54.233416Z","shell.execute_reply":"2025-07-19T04:08:54.592832Z"}},"outputs":[{"name":"stdout","text":"From https://github.com/Tanveer2719/NIDS_Coursework\n * branch            main       -> FETCH_HEAD\nAlready up to date.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npath = \"/kaggle/input/unsw-nb-15/UNSW-NB15_combined.csv\"\n\ndf = pd.read_csv(path)\n\nprint(df.shape)\ndf = df.drop(columns=['id', 'label'])\nprint(df.shape)\n\nprint(f\"ğŸ§¾ Unique class labels: {df['attack_cat'].unique()}\")\ndf['label'] = df['attack_cat'].apply(lambda x: 0 if x == 'Normal' else 1)\n\nprint(f'Unique values for label {df[\"label\"].unique()}')\n\ndf = df.drop(columns=[\"attack_cat\"])\nprint(f'new shape{df.shape}')\n\nprint(df.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:08:54.594913Z","iopub.execute_input":"2025-07-19T04:08:54.595256Z","iopub.status.idle":"2025-07-19T04:08:58.303048Z","shell.execute_reply.started":"2025-07-19T04:08:54.595217Z","shell.execute_reply":"2025-07-19T04:08:58.302145Z"}},"outputs":[{"name":"stdout","text":"(257673, 45)\n(257673, 43)\nğŸ§¾ Unique class labels: ['Normal' 'Backdoor' 'Analysis' 'Fuzzers' 'Shellcode' 'Reconnaissance'\n 'Exploits' 'DoS' 'Worms' 'Generic']\nUnique values for label [0 1]\nnew shape(257673, 43)\ndur                  float64\nproto                 object\nservice               object\nstate                 object\nspkts                  int64\ndpkts                  int64\nsbytes                 int64\ndbytes                 int64\nrate                 float64\nsttl                   int64\ndttl                   int64\nsload                float64\ndload                float64\nsloss                  int64\ndloss                  int64\nsinpkt               float64\ndinpkt               float64\nsjit                 float64\ndjit                 float64\nswin                   int64\nstcpb                  int64\ndtcpb                  int64\ndwin                   int64\ntcprtt               float64\nsynack               float64\nackdat               float64\nsmean                  int64\ndmean                  int64\ntrans_depth            int64\nresponse_body_len      int64\nct_srv_src             int64\nct_state_ttl           int64\nct_dst_ltm             int64\nct_src_dport_ltm       int64\nct_dst_sport_ltm       int64\nct_dst_src_ltm         int64\nis_ftp_login           int64\nct_ftp_cmd             int64\nct_flw_http_mthd       int64\nct_src_ltm             int64\nct_srv_dst             int64\nis_sm_ips_ports        int64\nlabel                  int64\ndtype: object\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# perform preprocessing\n\nfrom preprocess import Preprocess\n\n# separate the features and labels so that the labesl are not encoded\nlabels = df['label']\nfeatures = df.drop(columns=['label'])\n\npp = Preprocess()\nprocessed_features = pp.fit_transform_df_auto(df = features,n_categorical_levels=32, expected_categorical_format='onehot')\n\nprint(processed_features.shape)\nprocessed_features.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:08:58.303991Z","iopub.execute_input":"2025-07-19T04:08:58.304297Z","iopub.status.idle":"2025-07-19T04:09:00.422320Z","shell.execute_reply.started":"2025-07-19T04:08:58.304261Z","shell.execute_reply":"2025-07-19T04:09:00.421356Z"}},"outputs":[{"name":"stdout","text":"Encoding the 32 levels for proto\nEncoding the 13 levels for service\nEncoding the 11 levels for state\n(257673, 95)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n0  0.027889  0.193225  0.172921  0.331292  0.312312  0.312595  0.997874   \n1  0.121803  0.284598  0.393619  0.398471  0.645181  0.316704  0.747160   \n2  0.234590  0.224248  0.304405  0.353884  0.574953  0.196832  0.747160   \n3  0.239956  0.267974  0.275582  0.388675  0.402879  0.194440  0.747160   \n4  0.090294  0.248312  0.209072  0.378428  0.339064  0.256038  0.999294   \n\n       dttl     sload     dload  ...  state_2  state_3  state_4  state_5  \\\n0  1.000000  0.424562  0.534539  ...    False    False    False    False   \n1  0.998579  0.401347  0.775718  ...    False    False    False    False   \n2  0.998579  0.326962  0.650937  ...    False    False    False    False   \n3  0.998579  0.351625  0.479722  ...    False    False    False    False   \n4  0.998579  0.402218  0.489854  ...    False    False    False    False   \n\n   state_6  state_7  state_8  state_9  state_10  state_11  \n0    False    False    False    False     False     False  \n1    False    False    False    False     False     False  \n2    False    False    False    False     False     False  \n3    False    False    False    False     False     False  \n4    False    False    False    False     False     False  \n\n[5 rows x 95 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dur</th>\n      <th>spkts</th>\n      <th>dpkts</th>\n      <th>sbytes</th>\n      <th>dbytes</th>\n      <th>rate</th>\n      <th>sttl</th>\n      <th>dttl</th>\n      <th>sload</th>\n      <th>dload</th>\n      <th>...</th>\n      <th>state_2</th>\n      <th>state_3</th>\n      <th>state_4</th>\n      <th>state_5</th>\n      <th>state_6</th>\n      <th>state_7</th>\n      <th>state_8</th>\n      <th>state_9</th>\n      <th>state_10</th>\n      <th>state_11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.027889</td>\n      <td>0.193225</td>\n      <td>0.172921</td>\n      <td>0.331292</td>\n      <td>0.312312</td>\n      <td>0.312595</td>\n      <td>0.997874</td>\n      <td>1.000000</td>\n      <td>0.424562</td>\n      <td>0.534539</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.121803</td>\n      <td>0.284598</td>\n      <td>0.393619</td>\n      <td>0.398471</td>\n      <td>0.645181</td>\n      <td>0.316704</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.401347</td>\n      <td>0.775718</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.234590</td>\n      <td>0.224248</td>\n      <td>0.304405</td>\n      <td>0.353884</td>\n      <td>0.574953</td>\n      <td>0.196832</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.326962</td>\n      <td>0.650937</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.239956</td>\n      <td>0.267974</td>\n      <td>0.275582</td>\n      <td>0.388675</td>\n      <td>0.402879</td>\n      <td>0.194440</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.351625</td>\n      <td>0.479722</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.090294</td>\n      <td>0.248312</td>\n      <td>0.209072</td>\n      <td>0.378428</td>\n      <td>0.339064</td>\n      <td>0.256038</td>\n      <td>0.999294</td>\n      <td>0.998579</td>\n      <td>0.402218</td>\n      <td>0.489854</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 95 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# concat the features and the labels\nprocessed_full_df = pd.concat([processed_features, labels], axis=1)\nprocessed_full_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:09:00.423308Z","iopub.execute_input":"2025-07-19T04:09:00.423749Z","iopub.status.idle":"2025-07-19T04:09:00.464831Z","shell.execute_reply.started":"2025-07-19T04:09:00.423720Z","shell.execute_reply":"2025-07-19T04:09:00.464029Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n0  0.027889  0.193225  0.172921  0.331292  0.312312  0.312595  0.997874   \n1  0.121803  0.284598  0.393619  0.398471  0.645181  0.316704  0.747160   \n2  0.234590  0.224248  0.304405  0.353884  0.574953  0.196832  0.747160   \n3  0.239956  0.267974  0.275582  0.388675  0.402879  0.194440  0.747160   \n4  0.090294  0.248312  0.209072  0.378428  0.339064  0.256038  0.999294   \n\n       dttl     sload     dload  ...  state_3  state_4  state_5  state_6  \\\n0  1.000000  0.424562  0.534539  ...    False    False    False    False   \n1  0.998579  0.401347  0.775718  ...    False    False    False    False   \n2  0.998579  0.326962  0.650937  ...    False    False    False    False   \n3  0.998579  0.351625  0.479722  ...    False    False    False    False   \n4  0.998579  0.402218  0.489854  ...    False    False    False    False   \n\n   state_7  state_8  state_9  state_10  state_11  label  \n0    False    False    False     False     False      0  \n1    False    False    False     False     False      0  \n2    False    False    False     False     False      0  \n3    False    False    False     False     False      0  \n4    False    False    False     False     False      0  \n\n[5 rows x 96 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dur</th>\n      <th>spkts</th>\n      <th>dpkts</th>\n      <th>sbytes</th>\n      <th>dbytes</th>\n      <th>rate</th>\n      <th>sttl</th>\n      <th>dttl</th>\n      <th>sload</th>\n      <th>dload</th>\n      <th>...</th>\n      <th>state_3</th>\n      <th>state_4</th>\n      <th>state_5</th>\n      <th>state_6</th>\n      <th>state_7</th>\n      <th>state_8</th>\n      <th>state_9</th>\n      <th>state_10</th>\n      <th>state_11</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.027889</td>\n      <td>0.193225</td>\n      <td>0.172921</td>\n      <td>0.331292</td>\n      <td>0.312312</td>\n      <td>0.312595</td>\n      <td>0.997874</td>\n      <td>1.000000</td>\n      <td>0.424562</td>\n      <td>0.534539</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.121803</td>\n      <td>0.284598</td>\n      <td>0.393619</td>\n      <td>0.398471</td>\n      <td>0.645181</td>\n      <td>0.316704</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.401347</td>\n      <td>0.775718</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.234590</td>\n      <td>0.224248</td>\n      <td>0.304405</td>\n      <td>0.353884</td>\n      <td>0.574953</td>\n      <td>0.196832</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.326962</td>\n      <td>0.650937</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.239956</td>\n      <td>0.267974</td>\n      <td>0.275582</td>\n      <td>0.388675</td>\n      <td>0.402879</td>\n      <td>0.194440</td>\n      <td>0.747160</td>\n      <td>0.998579</td>\n      <td>0.351625</td>\n      <td>0.479722</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.090294</td>\n      <td>0.248312</td>\n      <td>0.209072</td>\n      <td>0.378428</td>\n      <td>0.339064</td>\n      <td>0.256038</td>\n      <td>0.999294</td>\n      <td>0.998579</td>\n      <td>0.402218</td>\n      <td>0.489854</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 96 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from featureSelection import AutoencoderFeatureSelector\n\nselector = AutoencoderFeatureSelector(encoding_dim=40)\n\n# To get compressed features (autoencoder bottleneck layer)\n# encoded_feature_names, X_encoded, y = selector.select_features(processed_full_df, target_column='label')\n\n# To get top 50 original features based on encoder weights\ntop_feats, X_top, y = selector.select_features(processed_full_df, target_column='label', top_k_features=50)\n\ntop_feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:09:00.465804Z","iopub.execute_input":"2025-07-19T04:09:00.466100Z","iopub.status.idle":"2025-07-19T04:18:15.058415Z","shell.execute_reply.started":"2025-07-19T04:09:00.466070Z","shell.execute_reply":"2025-07-19T04:18:15.057836Z"}},"outputs":[{"name":"stderr","text":"2025-07-19 04:09:02.496959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752898142.683279      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752898142.738934      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ§¹ Input features shape: (257673, 95), Target shape: (257673,)\nğŸš« Skipping normalization (already preprocessed)...\nğŸ”§ Building autoencoder (input_dim = 95, encoding_dim = 40)...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752898157.182304      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1752898157.183028      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m12,288\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ encoded_layer (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             â”‚         \u001b[38;5;34m5,160\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m5,248\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m)             â”‚        \u001b[38;5;34m12,255\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ encoded_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,160</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,255</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,951\u001b[0m (136.53 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,951</span> (136.53 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,951\u001b[0m (136.53 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,951</span> (136.53 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752898160.778934     116 service.cc:148] XLA service 0x79fb0c012b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752898160.779896     116 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752898160.779915     116 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752898161.025409     116 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  77/3221\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0586  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752898161.928631     116 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 2.8058e-04\nEpoch 2/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.3537e-04 - val_loss: 1.4984e-04\nEpoch 3/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.3131e-04 - val_loss: 9.9560e-05\nEpoch 4/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 8.7315e-05 - val_loss: 7.3194e-05\nEpoch 5/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 6.2979e-05 - val_loss: 5.2789e-05\nEpoch 6/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 4.8811e-05 - val_loss: 4.1822e-05\nEpoch 7/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 4.0923e-05 - val_loss: 4.2618e-05\nEpoch 8/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.7603e-05 - val_loss: 3.5709e-05\nEpoch 9/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.4805e-05 - val_loss: 3.5746e-05\nEpoch 10/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0791e-05 - val_loss: 3.5584e-05\nEpoch 11/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.1344e-05 - val_loss: 4.2996e-05\nEpoch 12/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8606e-05 - val_loss: 2.8872e-05\nEpoch 13/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6326e-05 - val_loss: 3.3366e-05\nEpoch 14/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6390e-05 - val_loss: 2.7341e-05\nEpoch 15/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6066e-05 - val_loss: 2.9719e-05\nEpoch 16/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.3312e-05 - val_loss: 2.9813e-05\nEpoch 17/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.4565e-05 - val_loss: 2.7487e-05\nEpoch 18/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.4726e-05 - val_loss: 2.6466e-05\nEpoch 19/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.2829e-05 - val_loss: 2.4096e-05\nEpoch 20/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.2510e-05 - val_loss: 1.8449e-05\nEpoch 21/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.1173e-05 - val_loss: 2.1179e-05\nEpoch 22/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.1163e-05 - val_loss: 2.1991e-05\nEpoch 23/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.0164e-05 - val_loss: 2.2520e-05\nEpoch 24/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.0313e-05 - val_loss: 2.4595e-05\nEpoch 25/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.8586e-05 - val_loss: 2.5233e-05\nEpoch 26/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.8745e-05 - val_loss: 2.5477e-05\nEpoch 27/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.9562e-05 - val_loss: 1.6441e-05\nEpoch 28/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.8283e-05 - val_loss: 1.7563e-05\nEpoch 29/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.8767e-05 - val_loss: 1.7122e-05\nEpoch 30/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.7688e-05 - val_loss: 1.5576e-05\nEpoch 31/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.6408e-05 - val_loss: 1.4484e-05\nEpoch 32/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.7541e-05 - val_loss: 1.5843e-05\nEpoch 33/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.5815e-05 - val_loss: 1.2879e-05\nEpoch 34/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.6373e-05 - val_loss: 1.3702e-05\nEpoch 35/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.6193e-05 - val_loss: 1.7447e-05\nEpoch 36/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.6333e-05 - val_loss: 2.2929e-05\nEpoch 37/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.5378e-05 - val_loss: 2.2712e-05\nEpoch 38/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.5622e-05 - val_loss: 1.3262e-05\nEpoch 39/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.5499e-05 - val_loss: 1.2639e-05\nEpoch 40/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.5298e-05 - val_loss: 1.2837e-05\nEpoch 41/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.4914e-05 - val_loss: 1.1390e-05\nEpoch 42/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.4587e-05 - val_loss: 1.2352e-05\nEpoch 43/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.4952e-05 - val_loss: 1.7676e-05\nEpoch 44/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.4930e-05 - val_loss: 1.4247e-05\nEpoch 45/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.3957e-05 - val_loss: 1.1078e-05\nEpoch 46/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2636e-05 - val_loss: 1.1257e-05\nEpoch 47/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 1.2941e-05 - val_loss: 2.8616e-05\nEpoch 48/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.3118e-05 - val_loss: 1.5965e-05\nEpoch 49/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.1860e-05 - val_loss: 1.4759e-05\nEpoch 50/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.3441e-05 - val_loss: 1.0779e-05\nEpoch 51/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2749e-05 - val_loss: 1.2333e-05\nEpoch 52/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2613e-05 - val_loss: 1.2377e-05\nEpoch 53/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2751e-05 - val_loss: 1.5464e-05\nEpoch 54/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1678e-05 - val_loss: 1.4284e-05\nEpoch 55/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2525e-05 - val_loss: 1.8424e-05\nEpoch 56/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1535e-05 - val_loss: 1.5976e-05\nEpoch 57/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1617e-05 - val_loss: 8.2768e-06\nEpoch 58/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1680e-05 - val_loss: 9.8663e-06\nEpoch 59/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1455e-05 - val_loss: 1.2982e-05\nEpoch 60/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1587e-05 - val_loss: 9.8640e-06\nEpoch 61/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.0549e-05 - val_loss: 1.3256e-05\nEpoch 62/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1912e-05 - val_loss: 1.0150e-05\nEpoch 63/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1133e-05 - val_loss: 1.3777e-05\nEpoch 64/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1524e-05 - val_loss: 9.7207e-06\nEpoch 65/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.1019e-05 - val_loss: 1.0587e-05\nEpoch 66/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.0971e-05 - val_loss: 1.4054e-05\nEpoch 67/100\n\u001b[1m3221/3221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.0525e-05 - val_loss: 1.1118e-05\nEpoch 67: early stopping\nRestoring model weights from the end of the best epoch: 57.\n\nâœ… Autoencoder training complete. Encoding data...\n\u001b[1m8053/8053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n\nğŸ“Š Feature importances from encoder (top 10):\n  1. proto_21: 3.2774\n  2. proto_2: 3.2516\n  3. proto_29: 3.2379\n  4. proto_28: 3.2237\n  5. proto_31: 3.0300\n  6. proto_26: 3.0162\n  7. proto_32: 3.0148\n  8. proto_17: 2.9985\n  9. proto_23: 2.9828\n  10. service_2: 2.9602\n\nâœ… Selected Top-50 original features based on encoder importances.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['proto_21',\n 'proto_2',\n 'proto_29',\n 'proto_28',\n 'proto_31',\n 'proto_26',\n 'proto_32',\n 'proto_17',\n 'proto_23',\n 'service_2',\n 'proto_14',\n 'proto_16',\n 'service_12',\n 'proto_20',\n 'proto_18',\n 'proto_24',\n 'state_6',\n 'proto_15',\n 'service_11',\n 'proto_11',\n 'proto_9',\n 'proto_10',\n 'service_13',\n 'proto_7',\n 'proto_30',\n 'state_5',\n 'service_9',\n 'service_7',\n 'is_sm_ips_ports',\n 'proto_27',\n 'proto_22',\n 'proto_12',\n 'proto_13',\n 'sloss',\n 'proto_19',\n 'ackdat',\n 'service_8',\n 'dpkts',\n 'dwin',\n 'spkts',\n 'synack',\n 'service_5',\n 'proto_6',\n 'proto_4',\n 'dloss',\n 'is_ftp_login',\n 'dttl',\n 'ct_flw_http_mthd',\n 'ct_state_ttl',\n 'sinpkt']"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"columns_to_keep = top_feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:18:15.059148Z","iopub.execute_input":"2025-07-19T04:18:15.059697Z","iopub.status.idle":"2025-07-19T04:18:15.063277Z","shell.execute_reply.started":"2025-07-19T04:18:15.059676Z","shell.execute_reply":"2025-07-19T04:18:15.062579Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df_selected = processed_full_df[columns_to_keep].copy()\ndf_selected.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:18:15.065606Z","iopub.execute_input":"2025-07-19T04:18:15.065805Z","iopub.status.idle":"2025-07-19T04:18:15.097929Z","shell.execute_reply.started":"2025-07-19T04:18:15.065791Z","shell.execute_reply":"2025-07-19T04:18:15.097297Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(257673, 50)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"df_selected.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:18:15.098593Z","iopub.execute_input":"2025-07-19T04:18:15.098772Z","iopub.status.idle":"2025-07-19T04:18:15.105270Z","shell.execute_reply.started":"2025-07-19T04:18:15.098759Z","shell.execute_reply":"2025-07-19T04:18:15.104702Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"proto_21               bool\nproto_2                bool\nproto_29               bool\nproto_28               bool\nproto_31               bool\nproto_26               bool\nproto_32               bool\nproto_17               bool\nproto_23               bool\nservice_2              bool\nproto_14               bool\nproto_16               bool\nservice_12             bool\nproto_20               bool\nproto_18               bool\nproto_24               bool\nstate_6                bool\nproto_15               bool\nservice_11             bool\nproto_11               bool\nproto_9                bool\nproto_10               bool\nservice_13             bool\nproto_7                bool\nproto_30               bool\nstate_5                bool\nservice_9              bool\nservice_7              bool\nis_sm_ips_ports     float64\nproto_27               bool\nproto_22               bool\nproto_12               bool\nproto_13               bool\nsloss               float64\nproto_19               bool\nackdat              float64\nservice_8              bool\ndpkts               float64\ndwin                float64\nspkts               float64\nsynack              float64\nservice_5              bool\nproto_6                bool\nproto_4                bool\ndloss               float64\nis_ftp_login        float64\ndttl                float64\nct_flw_http_mthd    float64\nct_state_ttl        float64\nsinpkt              float64\ndtype: object"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"numerical_columns = [col for col in columns_to_keep \n                     if not (col.startswith(\"proto_\") or \n                             col.startswith(\"service_\") or \n                             col.startswith(\"state_\"))]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:18:15.106089Z","iopub.execute_input":"2025-07-19T04:18:15.106919Z","iopub.status.idle":"2025-07-19T04:18:15.115127Z","shell.execute_reply.started":"2025-07-19T04:18:15.106891Z","shell.execute_reply":"2025-07-19T04:18:15.114579Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from record_level_embedding import RecordLevelEmbedder\n\nembedder = RecordLevelEmbedder(selected_df = df_selected, numerical_columns = numerical_columns, embed_dimension= 64)\n\nembedded_df = embedder.transform_to_df()\n\nembedded_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:18:15.115949Z","iopub.execute_input":"2025-07-19T04:18:15.116205Z","iopub.status.idle":"2025-07-19T04:18:33.725615Z","shell.execute_reply.started":"2025-07-19T04:18:15.116165Z","shell.execute_reply":"2025-07-19T04:18:33.724952Z"}},"outputs":[{"name":"stdout","text":"[INFO] Initializing RecordLevelEmbedder...\n[INFO] Detecting categorical blocks...\n[INFO] Detected 3 categorical blocks:\n   - proto: 27 columns\n   - service: 8 columns\n   - state: 2 columns\n[INFO] Embedder initialized with embedding dimension 64.\n[INFO] Building Keras embedding model...\n   - Adding numerical input: is_sm_ips_ports\n   - Adding numerical input: sloss\n   - Adding numerical input: ackdat\n   - Adding numerical input: dpkts\n   - Adding numerical input: dwin\n   - Adding numerical input: spkts\n   - Adding numerical input: synack\n   - Adding numerical input: dloss\n   - Adding numerical input: is_ftp_login\n   - Adding numerical input: dttl\n   - Adding numerical input: ct_flw_http_mthd\n   - Adding numerical input: ct_state_ttl\n   - Adding numerical input: sinpkt\n   - Adding categorical block input: proto (27 columns)\n   - Adding categorical block input: service (8 columns)\n   - Adding categorical block input: state (2 columns)\n[INFO] Concatenating 16 inputs and applying Dense projection to dimension 64.\n[INFO] Projection complete. Output embedding shape: (64,)\n[INFO] Model build complete.\n[INFO] Preparing inputs for embedding. Number of rows: 257673\n   - Prepared numerical input: is_sm_ips_ports\n   - Prepared numerical input: sloss\n   - Prepared numerical input: ackdat\n   - Prepared numerical input: dpkts\n   - Prepared numerical input: dwin\n   - Prepared numerical input: spkts\n   - Prepared numerical input: synack\n   - Prepared numerical input: dloss\n   - Prepared numerical input: is_ftp_login\n   - Prepared numerical input: dttl\n   - Prepared numerical input: ct_flw_http_mthd\n   - Prepared numerical input: ct_state_ttl\n   - Prepared numerical input: sinpkt\n   - Prepared categorical block input: proto\n   - Prepared categorical block input: service\n   - Prepared categorical block input: state\n[INFO] Performing embedding inference...\n\u001b[1m8053/8053\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n[INFO] Embedding complete. Output shape: (257673, 64)\n[INFO] Embedding DataFrame ready.\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n0 -0.133523  0.225222  0.314113  0.181442 -0.015446 -0.155780 -0.350083   \n1 -0.243253  0.261145  0.419577  0.186948 -0.027285 -0.072425 -0.307995   \n2 -0.222710  0.249139  0.420708  0.239597 -0.043783 -0.123580 -0.331820   \n3 -0.304725  0.213599  0.468104  0.300333  0.002506 -0.100246 -0.225437   \n4 -0.176236  0.197553  0.407351  0.203850 -0.016887 -0.112404 -0.296417   \n\n    embed_7   embed_8   embed_9  ...  embed_54  embed_55  embed_56  embed_57  \\\n0  0.169681  0.396281 -0.101996  ...  0.158478  0.160546 -0.215638 -0.245130   \n1  0.247811  0.419245 -0.167111  ...  0.141347  0.148349 -0.156413 -0.294571   \n2  0.236480  0.421185 -0.136183  ...  0.166336  0.153981 -0.201262 -0.314124   \n3  0.174049  0.491740 -0.128044  ...  0.135983  0.188145 -0.145956 -0.375446   \n4  0.251118  0.380544 -0.181026  ...  0.161730  0.180895 -0.210305 -0.303275   \n\n   embed_58  embed_59  embed_60  embed_61  embed_62  embed_63  \n0  0.198993  0.329484  0.378549  0.372550  0.048838  0.243953  \n1  0.300025  0.505661  0.396157  0.280961 -0.019553  0.269522  \n2  0.286887  0.507230  0.403490  0.317734 -0.025989  0.233260  \n3  0.291373  0.400195  0.440007  0.378852 -0.027192  0.137819  \n4  0.245013  0.433772  0.369498  0.344984 -0.023950  0.215005  \n\n[5 rows x 64 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embed_0</th>\n      <th>embed_1</th>\n      <th>embed_2</th>\n      <th>embed_3</th>\n      <th>embed_4</th>\n      <th>embed_5</th>\n      <th>embed_6</th>\n      <th>embed_7</th>\n      <th>embed_8</th>\n      <th>embed_9</th>\n      <th>...</th>\n      <th>embed_54</th>\n      <th>embed_55</th>\n      <th>embed_56</th>\n      <th>embed_57</th>\n      <th>embed_58</th>\n      <th>embed_59</th>\n      <th>embed_60</th>\n      <th>embed_61</th>\n      <th>embed_62</th>\n      <th>embed_63</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.133523</td>\n      <td>0.225222</td>\n      <td>0.314113</td>\n      <td>0.181442</td>\n      <td>-0.015446</td>\n      <td>-0.155780</td>\n      <td>-0.350083</td>\n      <td>0.169681</td>\n      <td>0.396281</td>\n      <td>-0.101996</td>\n      <td>...</td>\n      <td>0.158478</td>\n      <td>0.160546</td>\n      <td>-0.215638</td>\n      <td>-0.245130</td>\n      <td>0.198993</td>\n      <td>0.329484</td>\n      <td>0.378549</td>\n      <td>0.372550</td>\n      <td>0.048838</td>\n      <td>0.243953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.243253</td>\n      <td>0.261145</td>\n      <td>0.419577</td>\n      <td>0.186948</td>\n      <td>-0.027285</td>\n      <td>-0.072425</td>\n      <td>-0.307995</td>\n      <td>0.247811</td>\n      <td>0.419245</td>\n      <td>-0.167111</td>\n      <td>...</td>\n      <td>0.141347</td>\n      <td>0.148349</td>\n      <td>-0.156413</td>\n      <td>-0.294571</td>\n      <td>0.300025</td>\n      <td>0.505661</td>\n      <td>0.396157</td>\n      <td>0.280961</td>\n      <td>-0.019553</td>\n      <td>0.269522</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.222710</td>\n      <td>0.249139</td>\n      <td>0.420708</td>\n      <td>0.239597</td>\n      <td>-0.043783</td>\n      <td>-0.123580</td>\n      <td>-0.331820</td>\n      <td>0.236480</td>\n      <td>0.421185</td>\n      <td>-0.136183</td>\n      <td>...</td>\n      <td>0.166336</td>\n      <td>0.153981</td>\n      <td>-0.201262</td>\n      <td>-0.314124</td>\n      <td>0.286887</td>\n      <td>0.507230</td>\n      <td>0.403490</td>\n      <td>0.317734</td>\n      <td>-0.025989</td>\n      <td>0.233260</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.304725</td>\n      <td>0.213599</td>\n      <td>0.468104</td>\n      <td>0.300333</td>\n      <td>0.002506</td>\n      <td>-0.100246</td>\n      <td>-0.225437</td>\n      <td>0.174049</td>\n      <td>0.491740</td>\n      <td>-0.128044</td>\n      <td>...</td>\n      <td>0.135983</td>\n      <td>0.188145</td>\n      <td>-0.145956</td>\n      <td>-0.375446</td>\n      <td>0.291373</td>\n      <td>0.400195</td>\n      <td>0.440007</td>\n      <td>0.378852</td>\n      <td>-0.027192</td>\n      <td>0.137819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.176236</td>\n      <td>0.197553</td>\n      <td>0.407351</td>\n      <td>0.203850</td>\n      <td>-0.016887</td>\n      <td>-0.112404</td>\n      <td>-0.296417</td>\n      <td>0.251118</td>\n      <td>0.380544</td>\n      <td>-0.181026</td>\n      <td>...</td>\n      <td>0.161730</td>\n      <td>0.180895</td>\n      <td>-0.210305</td>\n      <td>-0.303275</td>\n      <td>0.245013</td>\n      <td>0.433772</td>\n      <td>0.369498</td>\n      <td>0.344984</td>\n      <td>-0.023950</td>\n      <td>0.215005</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 64 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Binary classification\nimport numpy as np\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\n\n\nprint(processed_full_df['label'].unique())\n\nbinary_target = (processed_full_df['label'] != 0).astype(int).values\nunique, counts = np.unique(binary_target, return_counts=True)\nprint(\"Classes and their counts:\")\nfor cls, cnt in zip(unique, counts):\n    print(f\"Class {cls}: {cnt}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:18:33.726316Z","iopub.execute_input":"2025-07-19T04:18:33.726568Z","iopub.status.idle":"2025-07-19T04:18:33.735881Z","shell.execute_reply.started":"2025-07-19T04:18:33.726525Z","shell.execute_reply":"2025-07-19T04:18:33.735056Z"}},"outputs":[{"name":"stdout","text":"[0 1]\nClasses and their counts:\nClass 0: 93000\nClass 1: 164673\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom transformer import BasicTransformer\nfrom classification import LastTokenClassificationHead\nfrom sklearn.model_selection import train_test_split\nimport numpy as np  # Just in case\n\n# Input data\nX_embed = embedded_df.values                   # shape: (num_samples, embed_dim)\nX_embed_seq = tf.expand_dims(X_embed, axis=1)  # shape: (batch_size, 1, embed_dim)\n\ninput_layer = Input(shape=(1, X_embed.shape[1]), name=\"record_input\")\n\n# Transformer block\ntransformer = BasicTransformer(\n    n_layers=2,\n    internal_size=128,\n    n_heads=4,\n    verbose=True  # See progress!\n)\n\nx = transformer.apply(input_layer, training=True)\n\n# Classification head\nclassification_head = LastTokenClassificationHead()\nx = classification_head.apply(x)\n\n# MLP head\nfor i, layer_size in enumerate([128]):\n    x = Dense(layer_size, activation=\"relu\", name=f\"classification_mlp_{i}_{layer_size}\")(x)\n    x = Dropout(0.1)(x)\n\n# Output layer for binary classification\noutput_layer = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(x)\n\n# Build the model\nmodel = Model(inputs=input_layer, outputs=output_layer)\nmodel.summary()\n\n# Compile the model\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n    jit_compile=True\n)\n\n# Prepare data\nX_np = X_embed_seq.numpy() if hasattr(X_embed_seq, 'numpy') else np.array(X_embed_seq)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_np, binary_target, test_size=0.2, random_state=42, stratify=binary_target\n)\n\n# Define early stopping callback\nearly_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\n# Train the model\nmodel.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=50,\n    batch_size=32,\n    callbacks=[early_stop]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:18:33.736734Z","iopub.execute_input":"2025-07-19T04:18:33.736942Z","iopub.status.idle":"2025-07-19T04:25:38.418867Z","shell.execute_reply.started":"2025-07-19T04:18:33.736926Z","shell.execute_reply":"2025-07-19T04:25:38.418245Z"}},"outputs":[{"name":"stdout","text":"[BasicTransformer] Applying Encoder Block 1/2\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[BasicTransformer] Applying Encoder Block 2/2\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[BasicTransformer] Final output shape: (None, 1, 64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ record_input (\u001b[38;5;33mInputLayer\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_0_transformer_encoder     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚       \u001b[38;5;34m149,504\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_1_transformer_encoder     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚       \u001b[38;5;34m149,504\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ slice_last (\u001b[38;5;33mLambda\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ classification_mlp_0_128        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m8,320\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mDense\u001b[0m)                         â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ binary_output (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ record_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_0_transformer_encoder     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">149,504</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block_1_transformer_encoder     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">149,504</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ slice_last (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ classification_mlp_0_128        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m307,457\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,457</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m307,457\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,457</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.2469[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.8804 - loss: 0.2469 - val_accuracy: 0.8921 - val_loss: 0.2142\nEpoch 2/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.2163 - val_accuracy: 0.8924 - val_loss: 0.2131\nEpoch 3/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.2072 - val_accuracy: 0.8933 - val_loss: 0.2155\nEpoch 4/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2040 - val_accuracy: 0.8954 - val_loss: 0.1966\nEpoch 5/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.1968 - val_accuracy: 0.8997 - val_loss: 0.1823\nEpoch 6/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8953 - loss: 0.1919 - val_accuracy: 0.8895 - val_loss: 0.2049\nEpoch 7/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.1978 - val_accuracy: 0.8962 - val_loss: 0.1885\nEpoch 8/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.1907 - val_accuracy: 0.8939 - val_loss: 0.1812\nEpoch 9/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.1850 - val_accuracy: 0.9011 - val_loss: 0.1842\nEpoch 10/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.1855 - val_accuracy: 0.8958 - val_loss: 0.1949\nEpoch 11/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.1858 - val_accuracy: 0.8995 - val_loss: 0.1791\nEpoch 12/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.1829 - val_accuracy: 0.9002 - val_loss: 0.1797\nEpoch 13/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.1818 - val_accuracy: 0.9000 - val_loss: 0.1860\nEpoch 14/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.1810 - val_accuracy: 0.9001 - val_loss: 0.1857\nEpoch 15/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 0.1806 - val_accuracy: 0.9020 - val_loss: 0.1823\nEpoch 16/50\n\u001b[1m6442/6442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.1796 - val_accuracy: 0.8985 - val_loss: 0.2002\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79fbd7d19e50>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# evaluate the model\nresults = model.evaluate(X_val, y_val)\nprint(f\"Validation loss: {results[0]:.4f}, Validation accuracy: {results[1]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:25:38.419604Z","iopub.execute_input":"2025-07-19T04:25:38.419830Z","iopub.status.idle":"2025-07-19T04:25:42.017875Z","shell.execute_reply.started":"2025-07-19T04:25:38.419804Z","shell.execute_reply":"2025-07-19T04:25:42.017099Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1611/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.1774\nValidation loss: 0.1791, Validation accuracy: 0.8995\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from sklearn.metrics import f1_score, confusion_matrix\nimport numpy as np\n\n# Predict probabilities\ny_pred_prob = model.predict(X_val)\ny_pred = (y_pred_prob >= 0.5).astype(int).flatten()\n\n# F1\nf1 = f1_score(y_val, y_pred)\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Confusion matrix\ncm = confusion_matrix(y_val, y_pred, labels=[0, 1])\nprint(\"Confusion Matrix:\\n\", cm)\n\nif cm.shape == (2, 2):\n    tn, fp, fn, tp = cm.ravel()\n    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n    print(f\"Detection Rate (Recall): {detection_rate:.4f}\")\n    print(f\"False Alarm Rate: {false_alarm_rate:.4f}\")\nelse:\n    print(\"Confusion matrix does not contain both classes!\")\n    print(\"Check your labels: y_val:\", np.unique(y_val), \" y_pred:\", np.unique(y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T04:25:42.018842Z","iopub.execute_input":"2025-07-19T04:25:42.019123Z","iopub.status.idle":"2025-07-19T04:25:46.855787Z","shell.execute_reply.started":"2025-07-19T04:25:42.019098Z","shell.execute_reply":"2025-07-19T04:25:46.854885Z"}},"outputs":[{"name":"stdout","text":"[EncoderBlock] Input shape: (32, 1, 64)\n[EncoderBlock] Output shape: (32, 1, 64)\n[EncoderBlock] Input shape: (32, 1, 64)\n[EncoderBlock] Output shape: (32, 1, 64)\n\u001b[1m1595/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n[EncoderBlock] Input shape: (None, 1, 64)\n[EncoderBlock] Output shape: (None, 1, 64)\n\u001b[1m1611/1611\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\nF1 Score: 0.9260\nConfusion Matrix:\n [[13935  4665]\n [  515 32420]]\nDetection Rate (Recall): 0.9844\nFalse Alarm Rate: 0.2508\n","output_type":"stream"}],"execution_count":17}]}